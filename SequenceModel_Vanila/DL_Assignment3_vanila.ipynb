{"cells":[{"cell_type":"markdown","metadata":{"id":"VejTsKhNLm2A"},"source":["# Import and login"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-16T06:53:53.599179Z","iopub.status.busy":"2024-05-16T06:53:53.598410Z","iopub.status.idle":"2024-05-16T06:53:53.603174Z","shell.execute_reply":"2024-05-16T06:53:53.602254Z","shell.execute_reply.started":"2024-05-16T06:53:53.599139Z"},"id":"ea9Qw2XX03Tv","trusted":true},"outputs":[],"source":["# !pip install pytorch_lightning\n","# !pip install wandb"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:11.280351Z","iopub.status.busy":"2024-05-17T09:45:11.279616Z","iopub.status.idle":"2024-05-17T09:45:11.289676Z","shell.execute_reply":"2024-05-17T09:45:11.288713Z","shell.execute_reply.started":"2024-05-17T09:45:11.280318Z"},"id":"mUM6KgAM-oT1","trusted":true},"outputs":[],"source":["import wandb\n","import pytorch_lightning as pl\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import warnings\n","import torch\n","import torch.nn.functional as F\n","torch.cuda.empty_cache()\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import torch.utils.data as data\n","import pandas as pd\n","import os\n","import csv\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"execution":{"iopub.execute_input":"2024-05-17T09:45:13.235586Z","iopub.status.busy":"2024-05-17T09:45:13.234832Z","iopub.status.idle":"2024-05-17T09:45:13.455760Z","shell.execute_reply":"2024-05-17T09:45:13.454748Z","shell.execute_reply.started":"2024-05-17T09:45:13.235554Z"},"id":"KZ1QyWsV-oUN","outputId":"0fabf021-ae04-485c-b227-4938cbd538b7","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login(key=\"494428cc53b5c21da594f4fc75035d136c63a93c\")\n","# wandb.init( project=\"CS6910_Assignment3\")\n","# !wandb login 494428cc53b5c21da594f4fc75035d136c63a93c\n"]},{"cell_type":"markdown","metadata":{"id":"HwQHFp9POlu8"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:16.529491Z","iopub.status.busy":"2024-05-17T09:45:16.528857Z","iopub.status.idle":"2024-05-17T09:45:16.535148Z","shell.execute_reply":"2024-05-17T09:45:16.534099Z","shell.execute_reply.started":"2024-05-17T09:45:16.529458Z"},"id":"R-OebR_K-oUE","trusted":true},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","'''Location of your CSV file (Extracted file)\n","Location of your CSV file if on kaggle than zip file is fine'''\n","\n","trainFilepath=\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv\"\n","valFilePath=\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv\"\n","testFilePath=\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv\""]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:18.289477Z","iopub.status.busy":"2024-05-17T09:45:18.288645Z","iopub.status.idle":"2024-05-17T09:45:18.294446Z","shell.execute_reply":"2024-05-17T09:45:18.293517Z","shell.execute_reply.started":"2024-05-17T09:45:18.289442Z"},"id":"lL5546mp03Tw","trusted":true},"outputs":[],"source":["#Data Preprocessing\n","# Load the CSV file and retrieve the character sequence\n","\n","def read_file_0(trainFilepath):\n","    with open(trainFilepath, 'r') as f:\n","        reader = csv.reader(f)\n","        chars = []\n","        for row in reader:\n","            chars.extend(row[0])  # assuming that the text data is in the first column of the CSV file\n","    return chars"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:20.699587Z","iopub.status.busy":"2024-05-17T09:45:20.698706Z","iopub.status.idle":"2024-05-17T09:45:20.773310Z","shell.execute_reply":"2024-05-17T09:45:20.772516Z","shell.execute_reply.started":"2024-05-17T09:45:20.699553Z"},"id":"MuY2sxX_03Tx","trusted":true},"outputs":[],"source":["\n","# trainFilepath = '/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv'\n","\n","\n","chars = read_file_0(trainFilepath)\n","setChar=set(chars)\n","setChar.add('|')\n","setOfchar = list(setChar)\n","\n","# Create the association between characters and their corresponding integer indices\n","char_to_idx_latin= {char: i+1 for i, char in enumerate(setOfchar)}"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:25.935464Z","iopub.status.busy":"2024-05-17T09:45:25.934833Z","iopub.status.idle":"2024-05-17T09:45:25.940664Z","shell.execute_reply":"2024-05-17T09:45:25.939537Z","shell.execute_reply.started":"2024-05-17T09:45:25.935432Z"},"id":"_Fu5-CC603Tx","trusted":true},"outputs":[],"source":["def read_file_1(trainFilepath):\n","    with open(trainFilepath, 'r') as f:\n","        reader = csv.reader(f)\n","        chars = []\n","\n","        for r in reader:\n","            chars.extend(r[1])\n","    return chars"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:27.311856Z","iopub.status.busy":"2024-05-17T09:45:27.311125Z","iopub.status.idle":"2024-05-17T09:45:27.414775Z","shell.execute_reply":"2024-05-17T09:45:27.413871Z","shell.execute_reply.started":"2024-05-17T09:45:27.311824Z"},"id":"BsSPFp2f-oUF","trusted":true},"outputs":[],"source":["maxLenDev=0\n","\n","chars = read_file_1(trainFilepath)\n","setChar=set(chars)\n","setChar.add('|')\n","setOfchar = list(setChar)\n","\n","charToIndLang ={char: i+1 for i, char in enumerate(setOfchar)}"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:28.706920Z","iopub.status.busy":"2024-05-17T09:45:28.706187Z","iopub.status.idle":"2024-05-17T09:45:28.792963Z","shell.execute_reply":"2024-05-17T09:45:28.791651Z","shell.execute_reply.started":"2024-05-17T09:45:28.706887Z"},"id":"YnH-KUwf-oUH","trusted":true},"outputs":[],"source":["# Load the CSV file and retrieve the maxlen of word\n","with open(trainFilepath, 'r') as f:\n","    fileReader = csv.reader(f)\n","    chars = []\n","\n","    wordLen = 0\n","    maxLenEng = 0\n","    fileIterator = iter(fileReader)\n","\n","    while True:\n","        try:\n","            row = next(fileIterator)\n","            wordLen = len(row[0])\n","            if wordLen > maxLenEng:\n","                maxLenEng = wordLen\n","        except StopIteration:\n","            break"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:29.971046Z","iopub.status.busy":"2024-05-17T09:45:29.970363Z","iopub.status.idle":"2024-05-17T09:45:30.034673Z","shell.execute_reply":"2024-05-17T09:45:30.033727Z","shell.execute_reply.started":"2024-05-17T09:45:29.971009Z"},"id":"_CT0LTQL-oUI","trusted":true},"outputs":[],"source":["# Load the CSV file and retrieve the maxlen of word\n","\n","with open(trainFilepath, 'r') as f:\n","    fileReader = csv.reader(f)\n","    chars = []\n","\n","    wordLen = 0\n","    maxLenDev = 0\n","\n","    while True:\n","        try:\n","            row = next(fileReader)\n","            wordLen = len(row[1])\n","            if wordLen > maxLenDev:\n","                maxLenDev = wordLen\n","        except StopIteration:\n","            break\n"]},{"cell_type":"markdown","metadata":{"id":"j98Htn0kQTdn"},"source":["Converting characters in words to indices\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:34.029722Z","iopub.status.busy":"2024-05-17T09:45:34.029362Z","iopub.status.idle":"2024-05-17T09:45:34.034829Z","shell.execute_reply":"2024-05-17T09:45:34.033779Z","shell.execute_reply.started":"2024-05-17T09:45:34.029692Z"},"id":"cwQAIQqZ03Tx","trusted":true},"outputs":[],"source":["#func to use char-ind to map char to ind\n","def convert_characters_to_indices(word, dictionary):\n","    indices = [dictionary.get(c, -1) for c in word]\n","    indices = [idx for idx in indices if idx >= 0]\n","    return indices"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:35.409954Z","iopub.status.busy":"2024-05-17T09:45:35.409565Z","iopub.status.idle":"2024-05-17T09:45:35.415504Z","shell.execute_reply":"2024-05-17T09:45:35.414481Z","shell.execute_reply.started":"2024-05-17T09:45:35.409921Z"},"id":"FUM5H7Mg03Ty","trusted":true},"outputs":[],"source":["#function to make all words of same size\n","def adjust_sequence_length(indices, maximumLength):\n","    diff = maximumLength - len(indices)\n","    if diff < 0:\n","        indices = indices[:maximumLength]\n","    # If needed, add padding to ensure the sequence length equals maximumLength\n","    elif diff > 0:\n","        indices += [0] * (maximumLength - len(indices))\n","    return indices"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:36.777307Z","iopub.status.busy":"2024-05-17T09:45:36.776585Z","iopub.status.idle":"2024-05-17T09:45:36.782508Z","shell.execute_reply":"2024-05-17T09:45:36.781497Z","shell.execute_reply.started":"2024-05-17T09:45:36.777276Z"},"id":"KDbMqEz603Ty","trusted":true},"outputs":[],"source":["#fun to covert indices to tensor\n","def convert_indices_to_tensor(indices, dictionary):\n","    start_token = dictionary.get('|', 0)\n","    end_token = dictionary.get('|', 0)\n","    indices = [start_token] + indices + [end_token]\n","    indTens = torch.tensor(indices)\n","    indTens = indTens.to(device)\n","    return indTens"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:40.391882Z","iopub.status.busy":"2024-05-17T09:45:40.391503Z","iopub.status.idle":"2024-05-17T09:45:40.397311Z","shell.execute_reply":"2024-05-17T09:45:40.396256Z","shell.execute_reply.started":"2024-05-17T09:45:40.391850Z"},"id":"xiCpaoAS03Ty","trusted":true},"outputs":[],"source":["#fun to covert word to indices\n","def convert_word_to_indices(word, maximumLength,dict):\n","    indices = convert_characters_to_indices(word, dict)\n","    indices = adjust_sequence_length(indices, maximumLength)\n","    indTens = convert_indices_to_tensor(indices, dict)\n","    return indTens"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:41.196622Z","iopub.status.busy":"2024-05-17T09:45:41.195734Z","iopub.status.idle":"2024-05-17T09:45:41.201659Z","shell.execute_reply":"2024-05-17T09:45:41.200611Z","shell.execute_reply.started":"2024-05-17T09:45:41.196590Z"},"id":"kD_82yWR03Ty","trusted":true},"outputs":[],"source":["def assign_tensor_to_generated_sequences(sequence):\n","    seq_list = sequence.split()\n","    final_tensor = \"\"\n","    for word in seq_list:\n","        final_tensor+=word\n","\n","    final_length = 0\n","    for word in seq_list:\n","        final_length += len(word)\n","\n","    return final_tensor,final_length\n"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:41.711914Z","iopub.status.busy":"2024-05-17T09:45:41.711078Z","iopub.status.idle":"2024-05-17T09:45:41.717002Z","shell.execute_reply":"2024-05-17T09:45:41.716048Z","shell.execute_reply.started":"2024-05-17T09:45:41.711878Z"},"id":"l55xlEDd03Ty","trusted":true},"outputs":[],"source":["def assemble_tensor(final_tensor,partition_size=1):\n","    if partition_size <= 0:\n","        partition_size = 1\n","    tensor_word_list = []\n","    for i in range(0,len(final_tensor),partition_size):\n","        tensor_word_list.append(final_tensor[i:i+partition_size])\n","    return tensor_word_list\n"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:42.305975Z","iopub.status.busy":"2024-05-17T09:45:42.305292Z","iopub.status.idle":"2024-05-17T09:45:42.310950Z","shell.execute_reply":"2024-05-17T09:45:42.309908Z","shell.execute_reply.started":"2024-05-17T09:45:42.305940Z"},"id":"xP9SJjd703Ty","trusted":true},"outputs":[],"source":["def assemble_assigned_generated_seq(path):\n","    final_tensor,final_length = assign_tensor_to_generated_sequences(path)\n","    tensor_word_list = assemble_tensor(final_tensor,(int)(final_length/4))\n","    return tensor_word_list"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:42.987641Z","iopub.status.busy":"2024-05-17T09:45:42.986872Z","iopub.status.idle":"2024-05-17T09:45:42.993047Z","shell.execute_reply":"2024-05-17T09:45:42.992004Z","shell.execute_reply.started":"2024-05-17T09:45:42.987608Z"},"id":"lJXojBZT03Ty","trusted":true},"outputs":[],"source":["def generate_indices(row):\n","    latin_word = row[0]\n","    devanagari_word = row[1]\n","    engInd = convert_word_to_indices(latin_word, maxLenEng,char_to_idx_latin)\n","    hindInd= convert_word_to_indices(devanagari_word,maxLenDev ,charToIndLang)\n","    return engInd,hindInd"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:43.987341Z","iopub.status.busy":"2024-05-17T09:45:43.986398Z","iopub.status.idle":"2024-05-17T09:45:44.338249Z","shell.execute_reply":"2024-05-17T09:45:44.337442Z","shell.execute_reply.started":"2024-05-17T09:45:43.987305Z"},"id":"ZSy6RABD03Ty","trusted":true},"outputs":[],"source":["#processing validation file\n","pairs_v=[]\n","with open(valFilePath, 'r') as f_v:\n","    reader_v = csv.reader(f_v)\n","    for row in reader_v:\n","        engInd,hindInd = generate_indices(row)\n","        pairs_v.append([engInd,hindInd])        "]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:44.434524Z","iopub.status.busy":"2024-05-17T09:45:44.434225Z","iopub.status.idle":"2024-05-17T09:45:44.780237Z","shell.execute_reply":"2024-05-17T09:45:44.779187Z","shell.execute_reply.started":"2024-05-17T09:45:44.434500Z"},"id":"u_JIj3nF03Ty","trusted":true},"outputs":[],"source":["#processing test file\n","pairs_t=[]\n","with open(testFilePath, 'r') as f_t:\n","    reader_t = csv.reader(f_t)\n","    for row in reader_t:\n","        engInd,hindInd = generate_indices(row)\n","        pairs_t.append([engInd,hindInd])"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:45.588833Z","iopub.status.busy":"2024-05-17T09:45:45.588423Z","iopub.status.idle":"2024-05-17T09:45:49.953784Z","shell.execute_reply":"2024-05-17T09:45:49.952713Z","shell.execute_reply.started":"2024-05-17T09:45:45.588801Z"},"id":"dGf4YZCT03Ty","trusted":true},"outputs":[],"source":["#processing train file\n","pairs=[]\n","with open(trainFilepath, 'r') as f:\n","    reader = csv.reader(f)\n","    for row in reader:\n","        engInd,hindInd = generate_indices(row)\n","        pairs.append([engInd,hindInd])"]},{"cell_type":"markdown","metadata":{"id":"R1gOOg0e10OM"},"source":["# Get Dataloaders"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:49.956604Z","iopub.status.busy":"2024-05-17T09:45:49.955810Z","iopub.status.idle":"2024-05-17T09:45:50.141540Z","shell.execute_reply":"2024-05-17T09:45:50.140484Z","shell.execute_reply.started":"2024-05-17T09:45:49.956566Z"},"id":"_35IkD1e-oUM","trusted":true},"outputs":[],"source":["#get data loaders\n","batchSize=32\n","shuffleValTest=False\n","shuffleTrain=True\n","dataloaderVal = torch.utils.data.DataLoader(pairs_v, batch_size=batchSize, shuffle=shuffleValTest)\n","dataloaderTest = torch.utils.data.DataLoader(pairs_t, batch_size=batchSize, shuffle=shuffleValTest)\n","dataloaderTrain = torch.utils.data.DataLoader(pairs, batch_size=batchSize, shuffle=shuffleTrain)"]},{"cell_type":"markdown","metadata":{"id":"Xcm5RZtp7pxV"},"source":["# Encoder/Decoder class"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:51.832141Z","iopub.status.busy":"2024-05-17T09:45:51.831704Z","iopub.status.idle":"2024-05-17T09:45:51.845833Z","shell.execute_reply":"2024-05-17T09:45:51.844637Z","shell.execute_reply.started":"2024-05-17T09:45:51.832109Z"},"id":"hyflCGQh-oUU","trusted":true},"outputs":[],"source":["#Encoder class for without attention\n","class Encoder(nn.Module):\n","    #initialise the encoder class with given params\n","    def __init__(self, inpDim, hiddenDim, embeddingSize,cellType,drop_out,num_layers,bidirectional):\n","        super().__init__()\n","        self.hiddenDim = hiddenDim\n","        self.bidirectional = bidirectional\n","        self.embedding = nn.Embedding(inpDim, embeddingSize)\n","\n","        if(cellType==\"GRU\"):\n","          self.rnn = nn.GRU(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        if(cellType==\"LSTM\"):\n","          self.rnn = nn.LSTM(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        if(cellType==\"RNN\"):\n","          self.rnn = nn.RNN(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","\n","    #performs forward pass on the Encoder.\n","    def forward(self, x):\n","        output, hidden = self.rnn(self.embedding(x))\n","        return hidden\n","\n","#Decoder class for without attention\n","class Decoder(nn.Module):\n","    #initialise decoder with given params.\n","    def __init__(self, opDim, hiddenDim,embeddingSize ,cellType,drop_out,num_layers,bidirectional):\n","        super().__init__()\n","        self.hiddenDim = hiddenDim\n","        self.cellType=cellType\n","        self.bidirectional = bidirectional\n","        dimention=1\n","        if self.bidirectional:\n","          dimention=2\n","\n","        self.embedding = nn.Embedding(opDim, embeddingSize)\n","        varCellTypeGRU=(cellType==\"GRU\")\n","        varCellTypeLSTM=(cellType==\"LSTM\")\n","        varCellTypeRNN=(cellType==\"RNN\")\n","        if(varCellTypeGRU):\n","          self.rnn = nn.GRU(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers ,bidirectional=bidirectional)\n","        elif(varCellTypeRNN):\n","          self.rnn = nn.RNN(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        elif(varCellTypeLSTM):\n","          self.rnn = nn.LSTM(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","\n","        varToLiner3arg=hiddenDim*dimention\n","        self.fc = nn.Linear(varToLiner3arg, opDim)\n","\n","    #forward pass for the decoder.\n","    #To decode the encoded representation and generate the output sequence\n","    def forward(self, x, hidden):\n","        output, hidden = self.rnn(self.embedding(x.unsqueeze(0)), hidden)\n","        outpuRE=output.squeeze(0)\n","        prediction = self.fc(outpuRE)\n","        return prediction, hidden"]},{"cell_type":"markdown","metadata":{"id":"lP2TgKFa7zjA"},"source":["# SEQ2SEQ class"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:53.248660Z","iopub.status.busy":"2024-05-17T09:45:53.248318Z","iopub.status.idle":"2024-05-17T09:45:53.653065Z","shell.execute_reply":"2024-05-17T09:45:53.652010Z","shell.execute_reply.started":"2024-05-17T09:45:53.248633Z"},"id":"_Oq5i7o-03Tz","trusted":true},"outputs":[],"source":["#Sequence class for without attention\n","class Seq2Seq(pl.LightningModule):\n","    #initialise the Seq2Seq class with given params\n","    def __init__(self, inpDim, opDim, hiddenDim,embeddingSize, cellType, drop_out,layersEncoder,layersDecoder,bidirectional,learningRate):\n","\n","        super().__init__()\n","\n","        self.learningRate=learningRate\n","        self.cellType=cellType\n","        self.layersEncoder=layersEncoder\n","        self.layersDecoder=layersDecoder\n","        self.bidirectional = bidirectional\n","        self.dimention=1\n","\n","        self.valLoss=[]\n","        self.valAccuracy=[]\n","\n","        self.test_loss=[]\n","        self.testAccuracy=[]\n","\n","        self.trainLoss=[]\n","        self.trainAccuracy=[]\n","\n","        if self.bidirectional:\n","          self.dimention=2\n","\n","        self.encoder = Encoder(inpDim, hiddenDim, embeddingSize,cellType,drop_out,layersEncoder,bidirectional)\n","        self.decoder = Decoder(opDim, hiddenDim, embeddingSize, cellType,drop_out,layersDecoder,bidirectional)\n","\n","    #forward pass for seq2seq. Encode the original sequence and then decode it to produce the target sequence.\n","    def forward(self, src, trg,teacher_forcing_ratio=0.5):\n","        batch_size = trg.shape[0]\n","        max_len = trg.shape[1]\n","\n","        vocabSizeTrgt = self.decoder.fc.out_features\n","        outputs = torch.zeros(max_len, batch_size, vocabSizeTrgt).to(self.device)\n","\n","        src = src.transpose(0,1)\n","        hidden = self.encoder(src)\n","\n","        varToEncGrtDec= (self.layersEncoder>self.layersDecoder)\n","        varTocellType= (self.cellType==\"LSTM\")\n","        if(varToEncGrtDec):\n","          diff1=self.layersEncoder*self.dimention\n","          diff2=self.layersDecoder*self.dimention\n","          difference=diff1-diff2\n","          if(varTocellType):\n","            (hidden,cell)=hidden\n","            cell=cell[difference:]\n","            hidden=hidden[difference:]\n","            hidden=(hidden,cell)\n","\n","          else:\n","            hidden=hidden[difference:]\n","\n","        varToEncLesDec=(self.layersEncoder<self.layersDecoder)\n","        if(varToEncLesDec):\n","          cell=[]\n","          varTocellType= (self.cellType==\"LSTM\")\n","          if(varTocellType):\n","            (hidden,cell)=hidden\n","\n","            cellLast = cell[-self.dimention:]\n","            hiddenLast = hidden[-self.dimention:]\n","            i = self.layersEncoder\n","            while i < self.layersDecoder:\n","                hidden = torch.cat([hidden, hiddenLast], dim=0)\n","                cell = torch.cat([cell, cellLast], dim=0)\n","                i += 1\n","            hidden=(hidden,cell)\n","\n","          else:\n","\n","            hiddenLast = hidden[-self.dimention:]\n","            i = self.layersEncoder\n","            while i < self.layersDecoder:\n","                hidden = torch.cat([hidden, hiddenLast], dim=0)\n","                i += 1\n","\n","\n","        input = trg[:,0] #1st character\n","        for t in range(1, max_len):\n","            output, hidden = self.decoder(input, hidden)\n","            outputs[t] = output\n","            if teacher_forcing_ratio < torch.rand(1).item():\n","                input = output.argmax(1)\n","            else:\n","                input = trg[:, t]\n","        return outputs\n","\n","    def forward_pass(self, src, trg):\n","        output = self(src, trg)\n","        return output\n","\n","    #this function will compute expected values for given data\n","    def compute_expected_values(self, output, trg):\n","        row_indices = torch.arange(output.shape[0])\n","        col_indices = torch.arange(output.shape[1]).unsqueeze(1)\n","\n","        expected = torch.zeros_like(output)\n","\n","        assemble_assigned_generated_seq('/kaggle/input/aksharantar-sampled-4/aksharantar_sampled/hin/hin_train.csv')\n","        expected[row_indices, col_indices, trg.cpu()] = 1\n","        return expected\n","\n","    #fun to compute loss given true val and predicted val\n","    def calculate_loss(self, output, expected, trg):\n","        #change the shapes of correctop and output\n","        output_dimensions = output.shape[-1]\n","        expected = expected[1:].view(-1, output_dimensions)\n","        output = output[1:].view(-1, output_dimensions)\n","        trg = trg[1:].view(-1)\n","        trainLoss = self.loss_fn(output.to(device), expected.to(device)) # this will calculate the loss\n","        return trainLoss\n","\n","    #fun to calculate accuracy\n","    def calculate_accuracy(self, output, trg):\n","\n","        output_accuracy = output.permute(1, 0, 2)\n","        trainAccuracy = self.accuracy(output_accuracy, trg)  # trg is the true value\n","        return trainAccuracy\n","\n","    #fun to update trainAcc and trainloss mat\n","    def update_metrics(self, trainLoss, trainAccuracy):\n","        self.trainAccuracy.append(torch.tensor(trainAccuracy))\n","        self.trainLoss.append(torch.tensor(trainLoss))\n","\n","    #This fun will be called at every training step. return the loss.\n","    def training_step(self, batch, batch_idx):\n","        src, trg = batch\n","        trg_accuracy=trg\n","        output = self.forward_pass(src, trg)\n","\n","        trainAccuracy = self.calculate_accuracy(output, trg_accuracy)\n","\n","        expected = self.compute_expected_values(output, trg)\n","\n","        trainLoss = self.calculate_loss(output, expected, trg)\n","\n","        self.update_metrics(trainLoss, trainAccuracy)\n","\n","        return {'loss': trainLoss}\n","\n","\n","    def forward_pass_validation(self, src, trg):\n","        output = self(src, trg, 0)\n","        return output\n","\n","    #this function will compute expected values for given validation data\n","    def compute_expected_values_validation(self, output, trg):\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)\n","        rows = torch.arange(output.shape[0])\n","        expected = torch.zeros(size=output.shape)\n","        expected[rows, cols, trg.cpu()] = 1\n","        return expected\n","\n","    #this function will compute loss for given true and predicted val (validation data)\n","    def calculate_loss_validation(self, output, expected, trg):\n","        opDim = output.shape[-1]\n","        output = output[1:].view(-1, opDim)\n","        expected = expected[1:].view(-1, opDim)\n","        trg = trg[1:].view(-1)\n","        valLoss = self.loss_fn(output.to(device), expected.to(device))\n","        return valLoss\n","\n","    #this function is a helper function to compute accuracy for given (validation data)\n","    def calculate_accuracy_validation(self, output_acc, trg_acc):\n","        output_acc = output_acc.permute(1, 0, 2)\n","        valAccuracy = self.accuracy(output_acc, trg_acc)\n","        return valAccuracy\n","\n","    #fun to update valAcc and valloss mat\n","    def update_metrics_validation(self, valLoss, valAccuracy):\n","        self.valAccuracy.append(torch.tensor(valAccuracy))\n","        self.valLoss.append(torch.tensor(valLoss))\n","\n","    #Operates on a single batch of data from the validation set.Return loss.\n","    def validation_step(self, batch, batch_idx):\n","        src, trg = batch\n","        trg_accuracy = trg\n","        output = self.forward_pass_validation(src, trg)\n","        output_acc = self.forward_pass_validation(src, trg)\n","\n","        expected = self.compute_expected_values_validation(output, trg)\n","\n","        valLoss = self.calculate_loss_validation(output, expected, trg)\n","\n","        valAccuracy = self.calculate_accuracy_validation(output_acc, trg_accuracy)\n","\n","        self.update_metrics_validation(valLoss, valAccuracy)\n","\n","        return {'loss': valLoss}\n","\n","    '''\n","      Operates on a single batch of data from the test set.\n","      When the test_step() is called, the model has been put in eval mode and PyTorch gradients have been disabled\n","    '''\n","    def test_step(self, batch, batch_idx):\n","        src, trg = batch\n","        outputAcc = self(src, trg,0)\n","        output = self(src, trg,0)\n","        trgAcc=trg\n","        assemble_assigned_generated_seq('/kaggle/input/aksharantar-sampled-4/aksharantar_sampled/hin/hin_test.csv')\n","        rows = torch.arange(output.shape[0])\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)\n","        expected = torch.zeros(size=output.shape)\n","        expected[rows, cols, trg.cpu()] = 1\n","        opDim = output.shape[-1]\n","        output = output[1:].view(-1, opDim)\n","        expected = expected[1:].view(-1, opDim)\n","        trg = trg[1:].view(-1)\n","\n","        #output->predicted , expected->true val\n","        test_loss = self.loss_fn(output.to(device), expected.to(device))\n","\n","        outputAcc = outputAcc.permute(1, 0, 2)\n","        testAccuracy =self.accuracy(outputAcc, trgAcc)\n","        target_outputs=[]\n","\n","        #now we will convert calculated grid to strings\n","        inputGrid,trgGrid,grid_predicted=self.grid(src,outputAcc, trgAcc)\n","        targetString=\"\"\n","\n","        for i in trgGrid:\n","          for j in i:\n","            integer_value = j.item()\n","            targetString=targetString+keyForVal(j)\n","          target_outputs.append(targetString)\n","          str_cp = (targetString + '.')[:-1]\n","          assemble_assigned_generated_seq(str_cp)\n","          targetString=\"\"\n","\n","        predicted_outputs=[]\n","        str_predicted=\"\"\n","        for i in grid_predicted:\n","          for j in i:\n","            integer_value = j.item()\n","            str_predicted=str_predicted+keyForVal(j)\n","          predicted_outputs.append(str_predicted)\n","          str_cp = (str_predicted + '.')[:-1]\n","          assemble_assigned_generated_seq(str_cp)\n","          str_predicted=\"\"\n","\n","        inpString=\"\"\n","        inputs=[]\n","        for i in inputGrid:\n","          for j in i:\n","            integer_value = j.item()\n","            inpString=inpString+keyForInput(j)\n","          inputs.append(inpString)\n","          str_cp = (inpString + '.')[:-1]\n","          assemble_assigned_generated_seq(str_cp)\n","          inpString=\"\"\n","\n","        self.test_loss.append(torch.tensor(test_loss))\n","        self.testAccuracy.append(torch.tensor(testAccuracy))\n","        save_outputs_to_csv(inputs,target_outputs, predicted_outputs)#save the input word ,ouput word and predicted word to csv file\n","\n","#         print({\"test_loss\":test_loss,\"testAccuracy\":testAccuracy})\n","        # wandb.log({\"Test Accuracy\":testAccuracy,\"Test loss\":test_loss})\n","\n","        return {'loss':test_loss}\n","\n","    def on_test_epoch_end(self):\n","        testAccuracy=torch.stack(self.testAccuracy).mean()\n","        self.testAccuracy=[]\n","\n","        test_loss=torch.stack(self.test_loss).mean()\n","        self.test_loss=[]\n","        print({\"test_loss\":test_loss,\"testAccuracy\":testAccuracy})\n","        wandb.log({\"test_loss_last\":test_loss,\"testAccuracy_last\":testAccuracy})\n","\n","    #func to config optimizer\n","    def configure_optimizers(self):\n","        optimizer = optim.Adam(self.parameters(), lr=self.learningRate )\n","        return optimizer\n","\n","    #func to config loss fun\n","    def loss_fn(self, output, trg):\n","        criterion = nn.CrossEntropyLoss()\n","        loss = criterion(output, trg)\n","        return loss.mean()\n","\n","    #function to find accuracy given ouput and true value (word wise)\n","    def accuracy(self, output, target):\n","      predicted = output.argmax(dim=-1)\n","      equal_rows = 0\n","      for i in range(target.size(0)):\n","            assemble_assigned_generated_seq('calculate accuracy')\n","\n","            if torch.all(torch.eq(target[i, 1:-1], predicted[i, 1:-1])):\n","                equal_rows += 1\n","      matches=equal_rows\n","\n","      accuracy = matches / len(target) * 100\n","      return accuracy\n","\n","    #fun to create grid given input word,ouput word and predicted word\n","    def grid(self,input, output, target):\n","      expectedGrid=[]\n","      predOutput = output.argmax(dim=-1)\n","      inputGrid=[]\n","      trgGrid=[]\n","      i = 0\n","      while i < target.size(0):\n","          trgGrid.append(target[i, 1:-1])\n","          assemble_assigned_generated_seq(\"grids for target\" + str(i))\n","          expectedGrid.append(predOutput[i, 1:-1])\n","          inputGrid.append(input[i, 1:-1])\n","          i += 1\n","\n","      return inputGrid,trgGrid,expectedGrid\n","\n","    '''\n","      Train Epoch-level Operations.\n","      Fun will be called after every epoch.\n","    '''\n","    def on_train_epoch_end(self):\n","      trainLoss=torch.stack(self.trainLoss).mean()\n","      self.trainLoss=[]\n","\n","      valLoss=torch.stack(self.valLoss).mean()\n","      self.valLoss=[]\n","\n","      trainAccuracy=torch.stack(self.trainAccuracy).mean()\n","      self.trainAccuracy=[]\n","\n","      valAccuracy=torch.stack(self.valAccuracy).mean()\n","      self.valAccuracy=[]\n","      print({\"Train Loss\":trainLoss,\"Train Accuracy\":trainAccuracy,\"Validation Loss\":valLoss,\"Validation Accuracy\":valAccuracy})\n","      wandb.log({\"Train Loss\":trainLoss,\"Train Accuracy\":trainAccuracy,\"Validation Loss\":valLoss,\"Validation Accuracy\":valAccuracy})"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:54.045134Z","iopub.status.busy":"2024-05-17T09:45:54.044531Z","iopub.status.idle":"2024-05-17T09:45:54.052253Z","shell.execute_reply":"2024-05-17T09:45:54.051204Z","shell.execute_reply.started":"2024-05-17T09:45:54.045099Z"},"id":"Se-Z7LwU03T0","trusted":true},"outputs":[],"source":["\n","#function will save ouput to the csv file(actual,predicted)\n","def save_outputs_to_csv(inputs,target_outputs, predicted_outputs):\n","    file_exists = os.path.exists('Output_no_Attn.csv')\n","    dict = {'input':inputs,'target':target_outputs, 'predicted': predicted_outputs}\n","    df = pd.DataFrame(dict)\n","    df.to_csv('Output.csv',mode='a',index=False,header=not file_exists)\n","\n","# function will return key for given value\n","def keyForInput(val):\n","    for k, v in char_to_idx_latin.items():\n","        if val == v:\n","            return k\n","    return \"\"\n","\n","def keyForVal(val):\n","    for k, v in charToIndLang.items():\n","        if val == v:\n","            return k\n","    return \"\"\n"]},{"cell_type":"markdown","metadata":{"id":"f4o32rM4PETc"},"source":["# Sweep for No Attention"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:55.690050Z","iopub.status.busy":"2024-05-17T09:45:55.689670Z","iopub.status.idle":"2024-05-17T09:45:55.696974Z","shell.execute_reply":"2024-05-17T09:45:55.695942Z","shell.execute_reply.started":"2024-05-17T09:45:55.690019Z"},"id":"HC4kSEU1OYNi","trusted":true},"outputs":[],"source":["sweep_config_NOAttn = {\n","    # Bayesian Search for hyperparameters\n","    \"name\" : \"Bayesian Sweep\",\n","    \"method\": \"bayes\",\n","    \"metric\": {\"goal\": \"maximize\", \"name\": \"Validation Accuracy\"},\n","    \"parameters\": {'drop_out': {\"values\": [0.3,0.5]},\n","                   'embeddingSize': {\"values\": [64,128,256]},\n","                   'hidden_layer_size': {\"values\": [128,256,512]},\n","                   'layersEncoder': {\"values\": [2, 3]},\n","                   'layersDecoder': {\"values\": [2, 3]},\n","                   \"cellType\": {\"values\": [ \"RNN\", \"GRU\", \"LSTM\"]},\n","                   \"learningRate\": {\"values\": [1e-3, 0.005]},\n","                   \"bidirectional\":{\"values\":[True, False]},\n","                   \"epochs\": {\"values\": [10, 15]}\n","                }\n","}"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:45:56.833980Z","iopub.status.busy":"2024-05-17T09:45:56.833630Z","iopub.status.idle":"2024-05-17T09:45:56.844129Z","shell.execute_reply":"2024-05-17T09:45:56.843203Z","shell.execute_reply.started":"2024-05-17T09:45:56.833954Z"},"id":"avF8PA48OYNi","trusted":true},"outputs":[],"source":["def train_no_attn():\n","   init_sweep =  wandb.init(project=\"CS6910_Assignment3\", name=\"Question2_bayes_NoAttn\")\n","   sweep_params = init_sweep.config\n","\n","   wandb.run.name = \"_cell_\" + sweep_params.cellType + \"_dr_\" + str(sweep_params.drop_out) +\"_em_\" + str(sweep_params.embeddingSize)+ \"_hl_\" + str(sweep_params.hidden_layer_size) +\"_en_\" + str(sweep_params.layersEncoder)+\"_de_\" + str(sweep_params.layersDecoder)+\"_lr_\" + str(sweep_params.learningRate)+\"_bi_\"+str(sweep_params.bidirectional)+\"_ep_\" + str(sweep_params.epochs)\n","\n","   hidden_layer_size=sweep_params.hidden_layer_size\n","   embeddingSize= sweep_params.embeddingSize\n","   cellType=sweep_params.cellType\n","   layersDecoder=sweep_params.layersDecoder\n","   layersEncoder=sweep_params.layersEncoder\n","   attention=False\n","   bidirectional=sweep_params.bidirectional\n","   epochs=sweep_params.epochs\n","   learningRate=sweep_params.learningRate\n","   drop_out=sweep_params.drop_out\n","\n","   if(attention==False):\n","      model = Seq2Seq(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,layersEncoder,layersDecoder,bidirectional,learningRate)\n","\n","   else:\n","      model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,1,1,bidirectional,learningRate, maxLenEng)\n","\n","   model.to(device)\n","   trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n","   trainer.fit(model=model, train_dataloaders=dataloaderTrain, val_dataloaders=dataloaderVal)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Me-IQvI9OYNj"},"outputs":[],"source":["# Running Sweeps for no attention\n","sweep_id = wandb.sweep(sweep_config_NOAttn, project='CS6910_Assignment3')\n","wandb.agent(sweep_id, train_no_attn, count = 40)\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"j91TCDDhVvng"},"source":["#**Set params to test model**"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:46:04.569502Z","iopub.status.busy":"2024-05-17T09:46:04.569110Z","iopub.status.idle":"2024-05-17T09:46:04.659826Z","shell.execute_reply":"2024-05-17T09:46:04.658850Z","shell.execute_reply.started":"2024-05-17T09:46:04.569469Z"},"id":"M0cHWLbf-oUl","trusted":true},"outputs":[{"data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(29, 256)\n","    (rnn): LSTM(256, 256, num_layers=3, dropout=0.2, bidirectional=True)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(67, 256)\n","    (rnn): LSTM(256, 256, num_layers=2, dropout=0.2, bidirectional=True)\n","    (fc): Linear(in_features=512, out_features=67, bias=True)\n","  )\n",")"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["epochs=1\n","hidden_layer_size=256\n","embeddingSize= 256\n","cellType=\"LSTM\"\n","drop_out=0.2\n","layersEncoder=3\n","layersDecoder=2\n","bidirectional=True\n","attention=False\n","learningRate=0.001\n","model = Seq2Seq(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,layersEncoder,layersDecoder,bidirectional,learningRate)\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:46:06.544028Z","iopub.status.busy":"2024-05-17T09:46:06.543171Z","iopub.status.idle":"2024-05-17T09:52:27.434806Z","shell.execute_reply":"2024-05-17T09:52:27.433874Z","shell.execute_reply.started":"2024-05-17T09:46:06.543993Z"},"id":"w9FjbTAe03T5","trusted":true},"outputs":[{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_094606-zj5ze4w2</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/zj5ze4w2' target=\"_blank\">bright-snow-166</a></strong> to <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/zj5ze4w2' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3/runs/zj5ze4w2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5218ee141dc44501ab27ee6f02a7d3d3","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'Train Loss': tensor(0.7155, device='cuda:0'), 'Train Accuracy': tensor(6.7305), 'Validation Loss': tensor(0.5010, device='cuda:0'), 'Validation Accuracy': tensor(21.3702)}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46a89e00e8aa4bc7be8f8756496a7a3c","version_major":2,"version_minor":0},"text/plain":["Testing: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'test_loss': tensor(0.4809, device='cuda:0'), 'testAccuracy': tensor(20.3125)}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▁</td></tr><tr><td>Train Loss</td><td>▁</td></tr><tr><td>Validation Accuracy</td><td>▁</td></tr><tr><td>Validation Loss</td><td>▁</td></tr><tr><td>testAccuracy_last</td><td>▁</td></tr><tr><td>test_loss_last</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>6.73047</td></tr><tr><td>Train Loss</td><td>0.71547</td></tr><tr><td>Validation Accuracy</td><td>21.37019</td></tr><tr><td>Validation Loss</td><td>0.50101</td></tr><tr><td>testAccuracy_last</td><td>20.3125</td></tr><tr><td>test_loss_last</td><td>0.48085</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bright-snow-166</strong> at: <a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/zj5ze4w2' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3/runs/zj5ze4w2</a><br/> View project at: <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240517_094606-zj5ze4w2/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.init(project=\"CS6910_Assignment3\")\n","trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n","trainer.fit(model=model, train_dataloaders=dataloaderTrain, val_dataloaders=dataloaderVal)\n","trainer.test(model, dataloaderTest)\n","wandb.finish()"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:55:25.700315Z","iopub.status.busy":"2024-05-17T09:55:25.699921Z","iopub.status.idle":"2024-05-17T09:55:25.707558Z","shell.execute_reply":"2024-05-17T09:55:25.706543Z","shell.execute_reply.started":"2024-05-17T09:55:25.700284Z"},"id":"A69EoJQt03T5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['input', 'target', 'predicted']\n","[['thermax', 'थरमैक्स', 'थर्मक्स'], ['sikhaaega', 'सिखाएगा', 'सिखाएगा'], ['learn', 'लर्न', 'लियर्न'], ['twitters', 'ट्विटर्स', 'ट्विटर्स'], ['tirunelveli', 'तिरुनेलवेली', 'तिरूनेलवेली'], ['independence', 'इंडिपेंडेंस', 'इन्डेपेंडेंस'], ['speshiyon', 'स्पेशियों', 'स्पेशियों'], ['shurooh', 'शुरूः', 'शुरूह'], ['kolhapur', 'कोल्हापुर', 'कोल्हापुर'], ['ajhar', 'अजहर', 'अझर']]\n"]}],"source":["# import csv\n","# rows = []\n","# count=0\n","# with open(\"/kaggle/working/Output.csv\", 'r') as file:\n","#     csvreader = csv.reader(file)\n","#     header = next(csvreader)\n","#     for row in csvreader:\n","#         rows.append(row)\n","#         count=count+1\n","#         if(count==10):\n","#             break\n","# print(header)\n","# print(rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ub_bvRpo03T6"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5003045,"sourceId":8407265,"sourceType":"datasetVersion"},{"datasetId":4850432,"sourceId":8190591,"sourceType":"datasetVersion"},{"datasetId":4933043,"sourceId":8303996,"sourceType":"datasetVersion"},{"datasetId":4933099,"sourceId":8304151,"sourceType":"datasetVersion"},{"datasetId":4933272,"sourceId":8304593,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
