{"cells":[{"cell_type":"markdown","metadata":{"id":"VejTsKhNLm2A"},"source":["# Import and login"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:16:39.198939Z","iopub.status.busy":"2024-05-17T09:16:39.198555Z","iopub.status.idle":"2024-05-17T09:16:39.208431Z","shell.execute_reply":"2024-05-17T09:16:39.206543Z","shell.execute_reply.started":"2024-05-17T09:16:39.198910Z"},"id":"ea9Qw2XX03Tv","trusted":true},"outputs":[],"source":["# !pip install pytorch_lightning\n","# !pip install wandb"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:49:34.901417Z","iopub.status.busy":"2024-05-17T09:49:34.900550Z","iopub.status.idle":"2024-05-17T09:49:46.118817Z","shell.execute_reply":"2024-05-17T09:49:46.117565Z","shell.execute_reply.started":"2024-05-17T09:49:34.901383Z"},"id":"mUM6KgAM-oT1","trusted":true},"outputs":[],"source":["import wandb\n","import pytorch_lightning as pl\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import warnings\n","import torch\n","import torch.nn.functional as F\n","torch.cuda.empty_cache()\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import torch.utils.data as data\n","import pandas as pd\n","import os\n","import csv\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"execution":{"iopub.execute_input":"2024-05-17T09:49:46.121416Z","iopub.status.busy":"2024-05-17T09:49:46.120893Z","iopub.status.idle":"2024-05-17T09:49:48.399844Z","shell.execute_reply":"2024-05-17T09:49:48.398809Z","shell.execute_reply.started":"2024-05-17T09:49:46.121386Z"},"id":"KZ1QyWsV-oUN","outputId":"0fabf021-ae04-485c-b227-4938cbd538b7","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login(key=\"494428cc53b5c21da594f4fc75035d136c63a93c\")\n","# wandb.init( project=\"CS6910_Assignment3\")\n","# !wandb login 494428cc53b5c21da594f4fc75035d136c63a93c\n"]},{"cell_type":"markdown","metadata":{"id":"HwQHFp9POlu8"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:49:51.683074Z","iopub.status.busy":"2024-05-17T09:49:51.682438Z","iopub.status.idle":"2024-05-17T09:49:51.715728Z","shell.execute_reply":"2024-05-17T09:49:51.714697Z","shell.execute_reply.started":"2024-05-17T09:49:51.683042Z"},"id":"R-OebR_K-oUE","trusted":true},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","'''Location of your CSV file (Extracted file)\n","Location of your CSV file if on kaggle than zip file is fine'''\n","\n","trainFilepath=\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv\"\n","valFilePath=\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv\"\n","testFilePath=\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:49:52.848571Z","iopub.status.busy":"2024-05-17T09:49:52.848147Z","iopub.status.idle":"2024-05-17T09:49:52.854686Z","shell.execute_reply":"2024-05-17T09:49:52.853507Z","shell.execute_reply.started":"2024-05-17T09:49:52.848539Z"},"id":"lL5546mp03Tw","trusted":true},"outputs":[],"source":["#Data Preprocessing\n","# Load the CSV file and retrieve the character sequence\n","\n","def read_file_0(trainFilepath):\n","    with open(trainFilepath, 'r') as f:\n","        reader = csv.reader(f)\n","        chars = []\n","        for row in reader:\n","            chars.extend(row[0])  # assuming that the text data is in the first column of the CSV file\n","    return chars"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:49:53.731108Z","iopub.status.busy":"2024-05-17T09:49:53.730723Z","iopub.status.idle":"2024-05-17T09:49:53.829977Z","shell.execute_reply":"2024-05-17T09:49:53.828951Z","shell.execute_reply.started":"2024-05-17T09:49:53.731079Z"},"id":"MuY2sxX_03Tx","trusted":true},"outputs":[],"source":["\n","\n","chars = read_file_0(trainFilepath)\n","setChar=set(chars)\n","setChar.add('|')\n","setOfchar = list(setChar)\n","\n","# Create the association between characters and their corresponding integer indices\n","char_to_idx_latin= {char: i+1 for i, char in enumerate(setOfchar)}"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:49:54.635240Z","iopub.status.busy":"2024-05-17T09:49:54.634839Z","iopub.status.idle":"2024-05-17T09:49:54.641442Z","shell.execute_reply":"2024-05-17T09:49:54.640258Z","shell.execute_reply.started":"2024-05-17T09:49:54.635208Z"},"id":"_Fu5-CC603Tx","trusted":true},"outputs":[],"source":["def read_file_1(trainFilepath):\n","    with open(trainFilepath, 'r') as f:\n","        reader = csv.reader(f)\n","        chars = []\n","\n","        for r in reader:\n","            chars.extend(r[1])\n","    return chars"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:49:55.531777Z","iopub.status.busy":"2024-05-17T09:49:55.531388Z","iopub.status.idle":"2024-05-17T09:49:55.646180Z","shell.execute_reply":"2024-05-17T09:49:55.645045Z","shell.execute_reply.started":"2024-05-17T09:49:55.531745Z"},"id":"BsSPFp2f-oUF","trusted":true},"outputs":[],"source":["maxLenDev=0\n","\n","chars = read_file_1(trainFilepath)\n","setChar=set(chars)\n","setChar.add('|')\n","setOfchar = list(setChar)\n","\n","charToIndLang ={char: i+1 for i, char in enumerate(setOfchar)}"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:49:56.232749Z","iopub.status.busy":"2024-05-17T09:49:56.232292Z","iopub.status.idle":"2024-05-17T09:49:56.323278Z","shell.execute_reply":"2024-05-17T09:49:56.322060Z","shell.execute_reply.started":"2024-05-17T09:49:56.232690Z"},"id":"YnH-KUwf-oUH","trusted":true},"outputs":[],"source":["# Load the CSV file and retrieve the maxlen of word\n","with open(trainFilepath, 'r') as f:\n","    fileReader = csv.reader(f)\n","    chars = []\n","\n","    wordLen = 0\n","    maxLenEng = 0\n","    fileIterator = iter(fileReader)\n","\n","    while True:\n","        try:\n","            row = next(fileIterator)\n","            wordLen = len(row[0])\n","            if wordLen > maxLenEng:\n","                maxLenEng = wordLen\n","        except StopIteration:\n","            break"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:49:56.922354Z","iopub.status.busy":"2024-05-17T09:49:56.921635Z","iopub.status.idle":"2024-05-17T09:49:56.995069Z","shell.execute_reply":"2024-05-17T09:49:56.994131Z","shell.execute_reply.started":"2024-05-17T09:49:56.922316Z"},"id":"_CT0LTQL-oUI","trusted":true},"outputs":[],"source":["# Load the CSV file and retrieve the maxlen of word\n","\n","with open(trainFilepath, 'r') as f:\n","    fileReader = csv.reader(f)\n","    chars = []\n","\n","    wordLen = 0\n","    maxLenDev = 0\n","\n","    while True:\n","        try:\n","            row = next(fileReader)\n","            wordLen = len(row[1])\n","            if wordLen > maxLenDev:\n","                maxLenDev = wordLen\n","        except StopIteration:\n","            break\n"]},{"cell_type":"markdown","metadata":{"id":"j98Htn0kQTdn"},"source":["Converting characters in words to indices\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:49:58.231705Z","iopub.status.busy":"2024-05-17T09:49:58.231296Z","iopub.status.idle":"2024-05-17T09:49:58.238040Z","shell.execute_reply":"2024-05-17T09:49:58.236846Z","shell.execute_reply.started":"2024-05-17T09:49:58.231672Z"},"id":"cwQAIQqZ03Tx","trusted":true},"outputs":[],"source":["#func to use char-ind to map char to ind\n","def convert_characters_to_indices(word, dictionary):\n","    indices = [dictionary.get(c, -1) for c in word]\n","    indices = [idx for idx in indices if idx >= 0]\n","    return indices"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:49:59.131283Z","iopub.status.busy":"2024-05-17T09:49:59.130893Z","iopub.status.idle":"2024-05-17T09:49:59.138073Z","shell.execute_reply":"2024-05-17T09:49:59.136731Z","shell.execute_reply.started":"2024-05-17T09:49:59.131251Z"},"id":"FUM5H7Mg03Ty","trusted":true},"outputs":[],"source":["#function to make all words of same size\n","def adjust_sequence_length(indices, maximumLength):\n","    diff = maximumLength - len(indices)\n","    if diff < 0:\n","        indices = indices[:maximumLength]\n","    # If needed, add padding to ensure the sequence length equals maximumLength\n","    elif diff > 0:\n","        indices += [0] * (maximumLength - len(indices))\n","    return indices"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:00.068868Z","iopub.status.busy":"2024-05-17T09:50:00.067969Z","iopub.status.idle":"2024-05-17T09:50:00.074668Z","shell.execute_reply":"2024-05-17T09:50:00.073497Z","shell.execute_reply.started":"2024-05-17T09:50:00.068831Z"},"id":"KDbMqEz603Ty","trusted":true},"outputs":[],"source":["#fun to covert indices to tensor\n","def convert_indices_to_tensor(indices, dictionary):\n","    start_token = dictionary.get('|', 0)\n","    end_token = dictionary.get('|', 0)\n","    indices = [start_token] + indices + [end_token]\n","    indTens = torch.tensor(indices)\n","    indTens = indTens.to(device)\n","    return indTens"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:00.886868Z","iopub.status.busy":"2024-05-17T09:50:00.886011Z","iopub.status.idle":"2024-05-17T09:50:00.891986Z","shell.execute_reply":"2024-05-17T09:50:00.890910Z","shell.execute_reply.started":"2024-05-17T09:50:00.886834Z"},"id":"xiCpaoAS03Ty","trusted":true},"outputs":[],"source":["#fun to covert word to indices\n","def convert_word_to_indices(word, maximumLength,dict):\n","    indices = convert_characters_to_indices(word, dict)\n","    indices = adjust_sequence_length(indices, maximumLength)\n","    indTens = convert_indices_to_tensor(indices, dict)\n","    return indTens"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:01.631469Z","iopub.status.busy":"2024-05-17T09:50:01.630743Z","iopub.status.idle":"2024-05-17T09:50:01.637056Z","shell.execute_reply":"2024-05-17T09:50:01.635840Z","shell.execute_reply.started":"2024-05-17T09:50:01.631432Z"},"id":"kD_82yWR03Ty","trusted":true},"outputs":[],"source":["def assign_tensor_to_generated_sequences(sequence):\n","    seq_list = sequence.split()\n","    final_tensor = \"\"\n","    for word in seq_list:\n","        final_tensor+=word\n","\n","    final_length = 0\n","    for word in seq_list:\n","        final_length += len(word)\n","\n","    return final_tensor,final_length\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:02.500505Z","iopub.status.busy":"2024-05-17T09:50:02.499877Z","iopub.status.idle":"2024-05-17T09:50:02.506190Z","shell.execute_reply":"2024-05-17T09:50:02.504982Z","shell.execute_reply.started":"2024-05-17T09:50:02.500474Z"},"id":"l55xlEDd03Ty","trusted":true},"outputs":[],"source":["def assemble_tensor(final_tensor,partition_size=1):\n","    if partition_size <= 0:\n","        partition_size = 1\n","    tensor_word_list = []\n","    for i in range(0,len(final_tensor),partition_size):\n","        tensor_word_list.append(final_tensor[i:i+partition_size])\n","    return tensor_word_list\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:03.332755Z","iopub.status.busy":"2024-05-17T09:50:03.331788Z","iopub.status.idle":"2024-05-17T09:50:03.337811Z","shell.execute_reply":"2024-05-17T09:50:03.336537Z","shell.execute_reply.started":"2024-05-17T09:50:03.332706Z"},"id":"xP9SJjd703Ty","trusted":true},"outputs":[],"source":["def assemble_assigned_generated_seq(path):\n","    final_tensor,final_length = assign_tensor_to_generated_sequences(path)\n","    tensor_word_list = assemble_tensor(final_tensor,(int)(final_length/4))\n","    return tensor_word_list"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:04.065363Z","iopub.status.busy":"2024-05-17T09:50:04.064724Z","iopub.status.idle":"2024-05-17T09:50:04.070719Z","shell.execute_reply":"2024-05-17T09:50:04.069540Z","shell.execute_reply.started":"2024-05-17T09:50:04.065330Z"},"id":"lJXojBZT03Ty","trusted":true},"outputs":[],"source":["def generate_indices(row):\n","    latin_word = row[0]\n","    devanagari_word = row[1]\n","    engInd = convert_word_to_indices(latin_word, maxLenEng,char_to_idx_latin)\n","    hindInd= convert_word_to_indices(devanagari_word,maxLenDev ,charToIndLang)\n","    return engInd,hindInd"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:04.833236Z","iopub.status.busy":"2024-05-17T09:50:04.831789Z","iopub.status.idle":"2024-05-17T09:50:05.370146Z","shell.execute_reply":"2024-05-17T09:50:05.369064Z","shell.execute_reply.started":"2024-05-17T09:50:04.833201Z"},"id":"ZSy6RABD03Ty","trusted":true},"outputs":[],"source":["#processing validation file\n","pairs_v=[]\n","with open(valFilePath, 'r') as f_v:\n","    reader_v = csv.reader(f_v)\n","    for row in reader_v:\n","        engInd,hindInd = generate_indices(row)\n","        pairs_v.append([engInd,hindInd])        \n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:05.552301Z","iopub.status.busy":"2024-05-17T09:50:05.551622Z","iopub.status.idle":"2024-05-17T09:50:05.919624Z","shell.execute_reply":"2024-05-17T09:50:05.918532Z","shell.execute_reply.started":"2024-05-17T09:50:05.552270Z"},"id":"u_JIj3nF03Ty","trusted":true},"outputs":[],"source":["#processing test file\n","pairs_t=[]\n","with open(testFilePath, 'r') as f_t:\n","    reader_t = csv.reader(f_t)\n","    for row in reader_t:\n","        engInd,hindInd = generate_indices(row)\n","        pairs_t.append([engInd,hindInd])"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:06.530968Z","iopub.status.busy":"2024-05-17T09:50:06.530577Z","iopub.status.idle":"2024-05-17T09:50:11.230561Z","shell.execute_reply":"2024-05-17T09:50:11.229167Z","shell.execute_reply.started":"2024-05-17T09:50:06.530928Z"},"id":"dGf4YZCT03Ty","trusted":true},"outputs":[],"source":["#processing train file\n","pairs=[]\n","with open(trainFilepath, 'r') as f:\n","    reader = csv.reader(f)\n","    for row in reader:\n","        engInd,hindInd = generate_indices(row)\n","        pairs.append([engInd,hindInd])"]},{"cell_type":"markdown","metadata":{"id":"R1gOOg0e10OM"},"source":["# Get Dataloaders"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:11.233554Z","iopub.status.busy":"2024-05-17T09:50:11.232592Z","iopub.status.idle":"2024-05-17T09:50:11.241210Z","shell.execute_reply":"2024-05-17T09:50:11.239892Z","shell.execute_reply.started":"2024-05-17T09:50:11.233515Z"},"id":"_35IkD1e-oUM","trusted":true},"outputs":[],"source":["#get data loaders\n","batchSize=32\n","shuffleValTest=False\n","shuffleTrain=True\n","dataloaderVal = torch.utils.data.DataLoader(pairs_v, batch_size=batchSize, shuffle=shuffleValTest)\n","dataloaderTest = torch.utils.data.DataLoader(pairs_t, batch_size=batchSize, shuffle=shuffleValTest)\n","dataloaderTrain = torch.utils.data.DataLoader(pairs, batch_size=batchSize, shuffle=shuffleTrain)"]},{"cell_type":"markdown","metadata":{"id":"srus1PiK78L8"},"source":["# AttnEncoder/AttnDecoder class(with attention)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"execution":{"iopub.execute_input":"2024-05-17T09:50:13.133895Z","iopub.status.busy":"2024-05-17T09:50:13.133445Z","iopub.status.idle":"2024-05-17T09:50:13.222163Z","shell.execute_reply":"2024-05-17T09:50:13.220989Z","shell.execute_reply.started":"2024-05-17T09:50:13.133848Z"},"id":"6uWSEe9Y-oUf","outputId":"3f5a2ab3-c9d1-4455-d8d6-93021005453e","trusted":true},"outputs":[],"source":["#AttnEncoder class for with attention\n","\n","class AttnEncoder(nn.Module):\n","  #initialise the Attnencoder class with given params\n","    def __init__(self, inpDim, hiddenDim, embeddingSize,cellType,drop_out,num_layers,bidirectional):\n","        super().__init__()\n","        self.hiddenDim = hiddenDim\n","        self.bidirectional = bidirectional\n","        self.embedding = nn.Embedding(inpDim, embeddingSize)\n","\n","        if(cellType==\"GRU\"):\n","          self.rnn = nn.GRU(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        if(cellType==\"LSTM\"):\n","          self.rnn = nn.LSTM(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        if(cellType==\"RNN\"):\n","          self.rnn = nn.RNN(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","\n","    #performs forward pass on the AttnEncoder.\n","    def forward(self, x):\n","        output, hidden = self.rnn(self.embedding(x))\n","        return output, hidden\n","\n","#AttnDecoder class for without attention\n","class AttnDecoder(nn.Module):\n","    #initialise AttnDecoder with given params.\n","    def __init__(self, opDim, hiddenDim,embeddingSize ,cellType,drop_out,num_layers,bidirectional,maximumLength):\n","\n","        self.maximumLength=maximumLength+2\n","        super(AttnDecoder, self).__init__()\n","        self.embedding = nn.Embedding(opDim, embeddingSize)\n","        self.hiddenDim = hiddenDim\n","        self.bidirectional = bidirectional\n","        varToLinerArg=(self.hiddenDim + embeddingSize)\n","        self.attn = nn.Linear(varToLinerArg, self.maximumLength)\n","        self.cellType=cellType\n","        dimention=1\n","        if self.bidirectional:\n","          dimention=2\n","\n","        varToAttnCombineArg=(self.hiddenDim*dimention + embeddingSize)\n","        self.attn_combine = nn.Linear(varToAttnCombineArg, self.hiddenDim)\n","\n","        varCellTypeGRU=(cellType==\"GRU\")\n","        varCellTypeLSTM=(cellType==\"LSTM\")\n","        varCellTypeRNN=(cellType==\"RNN\")\n","\n","        if(varCellTypeGRU):\n","          self.rnn = nn.GRU(hiddenDim, hiddenDim,dropout=drop_out,num_layers=num_layers ,bidirectional=bidirectional)\n","        elif(varCellTypeRNN):\n","          self.rnn = nn.RNN(hiddenDim, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        elif(varCellTypeLSTM):\n","          self.rnn = nn.LSTM(hiddenDim, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","\n","        varToLiner2Arg=hiddenDim*dimention\n","        self.fc = nn.Linear(varToLiner2Arg, opDim)\n","\n","    '''\n","    forward pass for the decoder.\n","    To decode the encoded representation and generate the output sequence\n","    we will also calculate Attention weights\n","    '''\n","    def forward(self, x, hidden, encoderOutput):\n","        x = x.unsqueeze(1)\n","        x=x.transpose(0,1)\n","\n","        varTocellType= (self.cellType==\"LSTM\")\n","        embedded = self.embedding(x)\n","        if(varTocellType):\n","          selfAttn=self.attn(torch.cat((embedded[0], hidden[0][0]), 1))\n","          attentionWeights = F.softmax(selfAttn, dim=1)\n","        else:\n","          selfAttn=self.attn(torch.cat((embedded[0], hidden[0]), 1))\n","          attentionWeights = F.softmax(selfAttn, dim=1)\n","\n","        #resize attentionWeights and  encoderOutput\n","        attentionApplied = torch.bmm(attentionWeights.unsqueeze(1),\n","                                 encoderOutput.permute(1,0,2))\n","        output = torch.cat((embedded[0], attentionApplied.squeeze(1)), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        varTocellType= (self.cellType==\"LSTM\")\n","        #as LSTM return 2 things hidden and cell\n","        if(varTocellType):\n","          (hidden,cell)=hidden\n","\n","        if(varTocellType):\n","          output, hidden = self.rnn(output, (hidden,cell))\n","        else:\n","          output, hidden = self.rnn(output, hidden)\n","\n","        prediction = self.fc(output.squeeze(0))\n","        return prediction, hidden, attentionWeights\n","\n","#Sequence class for with attention\n","class Seq2SeqAttn(pl.LightningModule):\n","    #initialise the Seq2SeqAttn class with given params\n","    def __init__(self, inpDim, opDim, hiddenDim,embeddingSize, cellType, drop_out,layersEncoder,layersDecoder,bidirectional,learningRate,maxLenEng):\n","\n","        super().__init__()\n","\n","        self.layersEncoder=layersEncoder\n","        self.learningRate=learningRate\n","        self.layersDecoder=layersDecoder\n","        self.cellType=cellType\n","\n","        self.valLoss=[]\n","        self.valAccuracy=[]\n","\n","        self.trainLoss=[]\n","        self.trainAccuracy=[]\n","\n","        self.test_loss=[]\n","        self.testAccuracy=[]\n","        self.bidirectional = bidirectional\n","\n","        self.encoder = AttnEncoder(inpDim, hiddenDim, embeddingSize,cellType,drop_out,layersEncoder,bidirectional)\n","        self.decoder = AttnDecoder(opDim, hiddenDim, embeddingSize, cellType,drop_out,layersDecoder,bidirectional,maxLenEng)\n","        self.dimention=1\n","        varTobidir=self.bidirectional\n","        if varTobidir:\n","          self.dimention=2\n","\n","        self.counter=0\n","        self.attentionWeights=[]\n","\n","    #forward pass for seq2seqAttn. Encode the original sequence and then decode it to produce the target sequence.\n","    #return output and attention weights\n","    def forward(self, src, trg,teacher_forcing_ratio=0.5):\n","        batch_size = trg.shape[0]\n","        max_len = trg.shape[1]\n","        src = src.transpose(0,1)\n","        attentionV = torch.zeros(max_len, batch_size, maxLenEng+2).to(self.device)\n","\n","        vocabSizeTrgt = self.decoder.fc.out_features\n","        encoder_output,hidden = self.encoder(src)\n","        outputs = torch.zeros(max_len, batch_size, vocabSizeTrgt).to(self.device)\n","\n","        input = trg[:,0]\n","        t = 1\n","        while t < max_len:\n","            output, hidden, attentionV[t] = self.decoder(input, hidden, encoder_output)\n","            outputs[t] = output\n","            if teacher_forcing_ratio < torch.rand(1).item():\n","                input = output.argmax(1)\n","            else:\n","                input = trg[:, t]\n","            t += 1\n","        return outputs, attentionV\n","\n","    #fun to get model output\n","    def get_model_output(self, src, trg):\n","        output, attentionV = self(src, trg)\n","        output_acc, _ = self(src, trg)\n","        return output, output_acc.permute(1, 0, 2)\n","\n","    #fun will return expected values tensor\n","    def prepare_expected_tensor(self, output, trg):\n","        rows = torch.arange(output.shape[0])\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)\n","        expected = torch.zeros(size=output.shape)\n","        expected[rows, cols, trg.cpu()] = 1\n","        return expected\n","\n","    def prepare_output_expected_tensors(self, output, trg):\n","        opDim = output.shape[-1]\n","        output = output[1:].view(-1, opDim)\n","        expected = self.prepare_expected_tensor(output, trg)[1:].view(-1, opDim)\n","        trg = trg[1:].view(-1)\n","        return output, expected, trg\n","\n","    #helper func to find loss\n","    def calculate_loss(self, output, expected):\n","        return self.loss_fn(output.to(device), expected.to(device))\n","\n","    #helper fun to find accuracy\n","    def calculate_accuracy(self, output, trg):\n","        return self.accuracy(output, trg)\n","\n","    def append_metrics(self, trainLoss, trainAccuracy):\n","        self.trainAccuracy.append(torch.tensor(trainAccuracy))\n","        self.trainLoss.append(torch.tensor(trainLoss))\n","\n","    #This fun will be called at every training step. return the loss.\n","    def training_step(self, batch, batch_idx):\n","        src, trg = batch\n","\n","        trg_accuracy = trg\n","        output, output_acc = self.get_model_output(src, trg)\n","\n","        output, expected, trg = self.prepare_output_expected_tensors(output, trg)\n","\n","        trainAccuracy = self.calculate_accuracy(output_acc, trg_accuracy)\n","\n","        trainLoss = self.calculate_loss(output, expected)\n","\n","        self.append_metrics(trainLoss, trainAccuracy)\n","\n","        return {'loss': trainLoss}\n","\n","\n","    def get_output(self, src, trg):\n","        output, attentionV = self(src, trg, 0)\n","        output_acc, attentionV = self(src, trg, 0)\n","        return output, output_acc.permute(1, 0, 2)\n","\n","    def prepare_output_expected_tensors(self, output, trg):\n","        rows = torch.arange(output.shape[0])\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)\n","        expected = torch.zeros(size=output.shape)\n","        path = '/kaggle/input/aksharantar-sampled-5/aksharantar_sampled/hin/hin_val.csv'\n","        expected[rows, cols, trg.cpu()] = 1\n","        opDim = output.shape[-1]\n","        return output[1:].view(-1, opDim), expected[1:].view(-1, opDim), trg[1:].view(-1)\n","\n","    def calculate_loss(self, output, expected):\n","        return self.loss_fn(output.to(device), expected.to(device))\n","\n","    def calculate_accuracy(self, output, trg):\n","        return self.accuracy(output, trg)\n","\n","    def assemble_and_save_sequences(self, path):\n","        assemble_assigned_generated_seq(path)\n","\n","    #Operates on a single batch of data from the validation set.Return validationLoss.\n","    def validation_step(self, batch, batch_idx):\n","        src, trg = batch\n","        trg_accuracy = trg\n","\n","        output, output_accuracy = self.get_output(src, trg)\n","\n","        output, expected, trg = self.prepare_output_expected_tensors(output, trg)\n","\n","        valLoss = self.calculate_loss(output, expected)\n","\n","        valAccuracy = self.calculate_accuracy(output_accuracy, trg_accuracy)\n","\n","        path = '/kaggle/input/aksharantar-sampled-5/aksharantar_sampled/hin/hin_val.csv'\n","        self.assemble_and_save_sequences(path)\n","\n","        self.valAccuracy.append(torch.tensor(valAccuracy))\n","        self.valLoss.append(torch.tensor(valLoss))\n","\n","        return {'loss': valLoss}\n","\n","\n","    #func to config optimizer\n","    def configure_optimizers(self):\n","        optimizer = optim.Adam(self.parameters(), lr=self.learningRate )\n","        return optimizer\n","\n","    #func to config loss fun\n","    def loss_fn(self, output, trg):\n","        criterion = nn.CrossEntropyLoss()\n","        loss = criterion(output, trg)\n","        return loss.mean()\n","\n","    #function to find accuracy given ouput and true value (word wise)\n","    def accuracy(self, output, target):\n","      predicted = output.argmax(dim=-1)\n","      equal_rows = 0\n","      i = 0\n","      while i < target.size(0):\n","          if torch.all(torch.eq(target[i, 1:-1], predicted[i, 1:-1])):\n","              equal_rows += 1\n","          i += 1\n","      matches=equal_rows\n","\n","      accuracy = matches / len(target) * 100\n","      return accuracy\n","\n","    #fun to create grid given input word,ouput word and predicted word\n","    def grid(self,input, output, target):\n","      inputGrid=[]\n","      trgGrid=[]\n","      expectedGrid=[]\n","      predicted = output.argmax(dim=-1)\n","      i = 0\n","      while i < target.size(0):\n","          trgGrid.append(target[i, 1:-1])\n","          expectedGrid.append(predicted[i, 1:-1])\n","          inputGrid.append(input[i, 1:-1])\n","          i += 1\n","      return inputGrid,trgGrid,expectedGrid\n","\n","    '''\n","      Train Epoch-level Operations.\n","      Fun will be called after every epoch.\n","    '''\n","    def on_train_epoch_end(self):\n","      trainLoss=torch.stack(self.trainLoss).mean()\n","      self.trainLoss=[]\n","\n","      valLoss=torch.stack(self.valLoss).mean()\n","      self.valLoss=[]\n","\n","      trainAccuracy=torch.stack(self.trainAccuracy).mean()\n","      self.trainAccuracy=[]\n","\n","      valAccuracy=torch.stack(self.valAccuracy).mean()\n","      self.valAccuracy=[]\n","      print({\"trainLoss\":trainLoss,\"trainAccuracy\":trainAccuracy,\"valLoss\":valLoss,\"valAccuracy\":valAccuracy})\n","      wandb.log({\"Train Loss\":trainLoss,\"Train Accuracy\":trainAccuracy,\"Validation Loss\":valLoss,\"Validation Accuracy\":valAccuracy})\n","\n","\n","    def get_out_attention(self,src,trg):\n","        output, attentionV = self(src, trg,0)\n","        outputAcc, attentionVD = self(src, trg,0)\n","        return output,attentionV,outputAcc.permute(1,0,2)\n","\n","    def get_expected(self,output, trg):\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)\n","        rows = torch.arange(output.shape[0])\n","        expected = torch.zeros(size=output.shape)\n","        expected[rows, cols, trg.cpu()] = 1\n","        return expected\n","\n","    '''\n","      Operates on a single batch of data from the test set.\n","      When the test_step() is called, the model has been put in eval mode and PyTorch gradients have been disabled\n","    '''\n","    def test_step(self, batch, batch_idx):\n","        test_path = '/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_val.csv'\n","        assemble_assigned_generated_seq(test_path)\n","        src, trg = batch\n","        trgAcc=trg\n","\n","        output, attentionV, outputAcc = self.get_out_attention(src, trg)\n","\n","        expected = self.get_expected(output, trg)\n","        opDim = output.shape[-1]\n","\n","        output = output[1:].view(-1, opDim)\n","        expected = expected[1:].view(-1, opDim)\n","        trg = trg[1:].view(-1)\n","\n","        test_loss = self.loss_fn(output.to(device), expected.to(device))\n","        testAccuracy =self.accuracy(outputAcc, trgAcc)\n","        inputGrid,trgGrid,grid_predicted=self.grid(src,outputAcc, trgAcc)\n","\n","        assemble_assigned_generated_seq(\"string representations\")\n","        #convert grid representation to string\n","        #for target string\n","        target_outputs=[]\n","        targetString=\"\"\n","        for i in trgGrid:\n","          for j in i:\n","            integer_value = j.item()\n","            targetString=targetString+keyForVal(j)\n","          target_outputs.append(targetString)\n","          str_cp = (targetString + '.')[:-1]\n","          assemble_assigned_generated_seq(str_cp)\n","          targetString=\"\"\n","\n","        #for predicted string\n","        predicted_outputs=[]\n","        str_predicted=\"\"\n","        for i in grid_predicted:\n","          for j in i:\n","            integer_value = j.item()\n","            str_predicted=str_predicted+get_keyAttn(j)\n","          predicted_outputs.append(str_predicted)\n","          str_cp = (str_predicted + '.')[:-1]\n","          assemble_assigned_generated_seq(str_cp)\n","          str_predicted=\"\"\n","\n","        #for input string\n","        inputs=[]\n","        inpString=\"\"\n","        for i in inputGrid:\n","          for j in i:\n","            integer_value = j.item()\n","            inpString=inpString+keyForInput(j)\n","          inputs.append(inpString)\n","          inpString=\"\"\n","\n","        str_cp = (inpString + '.')[:-1]\n","        assemble_assigned_generated_seq(str_cp)\n","        self.testAccuracy.append(torch.tensor(testAccuracy))\n","        self.test_loss.append(torch.tensor(test_loss))\n","        # print({\"for batch test_loss\":test_loss,\"testAccuracy\":testAccuracy})\n","#         wandb.log({\"Test Loss\":test_loss,\"Test Accuracy\":testAccuracy})\n","        # Save target and predicted outputs to a CSV file\n","        save_outputs_to_csvAttn(inputs,target_outputs, predicted_outputs)\n","        # plot_attention_weights(self.attentionWeights)\n","#         if(self.counter<1):\n","#           s(inputs,predicted_outputs,attentionV)\n","#           self.counter=self.counter+1\n","        return {'loss':test_loss}\n","\n","    def on_test_epoch_end(self):\n","        testAccuracy=torch.stack(self.testAccuracy).mean()\n","        self.testAccuracy=[]\n","\n","        test_loss=torch.stack(self.test_loss).mean()\n","        self.test_loss=[]\n","        print({\"test_loss\":test_loss,\"testAccuracy\":testAccuracy})\n","        wandb.log({\"test_loss_last\":test_loss,\"testAccuracy_last\":testAccuracy})\n","\n","\n","# function to return key for any value\n","def get_keyAttn(val):\n","    keys = list(charToIndLang.keys())\n","    values = list(charToIndLang.values())\n","    index = 0\n","    key = \"\"\n","\n","    while index < len(values):\n","        if val == values[index]:\n","            key = keys[index]\n","            break\n","        index += 1\n","\n","    return key\n","\n","def keyForInput(val):\n","    for k, v in char_to_idx_latin.items():\n","        if val == v:\n","            return k\n","    return \"\"\n","\n","def keyForVal(val):\n","    for k, v in charToIndLang.items():\n","        if val == v:\n","            return k\n","    return \"\"\n","\n","def get_key_inputAttn(val):\n","    keys = list(char_to_idx_latin.keys())\n","    values = list(char_to_idx_latin.values())\n","    index = 0\n","    key = \"\"\n","\n","    while index < len(values):\n","        if val == values[index]:\n","            key = keys[index]\n","            break\n","        index += 1\n","\n","    return key\n","\n","#function will save the input word ,ouput word and predicted word to csv file for attention module\n","def save_outputs_to_csvAttn(inputs,target_outputs, predicted_outputs):\n","    file_exists = os.path.exists('Output_Attn.csv')\n","    dict = {'input':inputs,'target':target_outputs, 'predicted': predicted_outputs}\n","    df = pd.DataFrame(dict)\n","    df.to_csv('Output.csv',mode='a',index=False,header=not file_exists)\n","\n","#function to create 3*3 grid of heatMap\n","def s(input_words, output_words, attentionWeights):\n","    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n","\n","    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n","\n","    for i, ax in enumerate(axes.flat):\n","        # Check if input and output words are provided\n","        if i < len(input_words) and i < len(output_words):\n","            # Get the attention weights for the corresponding input word\n","            attn_weight = attentionWeights[i].cpu().detach().numpy()\n","            attn_weight = attn_weight[1:len(input_words[i]) + 1, :len(output_words[i])]\n","\n","            # Plot the attention weights as a heatmap on the current axis\n","            sns.heatmap(attn_weight, ax=ax, cmap='Blues', cbar=False)\n","\n","            # Set the y-axis tick positions and labels to the input words and rotate them vertically\n","            ax.set_yticks(range(len(input_words[i])))\n","            ax.set_yticklabels(reversed(input_words[i]), rotation='vertical')\n","\n","            # Set the x-axis tick positions and labels to the output words and rotate them horizontally\n","            ax.set_xticks(range(len(output_words[i])))\n","#             fontproperties=hindi_font,\n","            ax.set_xticklabels(reversed(output_words[i]), rotation=45, ha='right')\n","\n","            # Set the title of each subplot as the index number\n","            ax.set_title(f'Attention {i+1}', fontsize=12)\n","        else:\n","            # If input or output words are missing, display a message in the subplot\n","            ax.text(0.5, 0.5, 'Missing Data', horizontalalignment='center', verticalalignment='center', fontsize=12)\n","            ax.axis('off')\n","\n","    for j in range(len(input_words), len(axes.flat)):\n","        fig.delaxes(axes.flat[j])\n","\n","    wandb.log({\"Question5_HeatMap\": wandb.Image(plt)})\n","\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"vB4gwUdftBb6"},"source":["# Sweep for Attention"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:17.696313Z","iopub.status.busy":"2024-05-17T09:50:17.695904Z","iopub.status.idle":"2024-05-17T09:50:17.704171Z","shell.execute_reply":"2024-05-17T09:50:17.702893Z","shell.execute_reply.started":"2024-05-17T09:50:17.696280Z"},"id":"P3Mbgj3-03T1","trusted":true},"outputs":[],"source":["sweep_config = {\n","    # Bayesian Search for hyperparameters\n","    \"name\" : \"Bayesian Sweep_Attn\",\n","    \"method\": \"bayes\",\n","    \"metric\": {\"goal\": \"maximize\", \"name\": \"Validation Accuracy\"},\n","    \"parameters\": {'drop_out': {\"values\": [0.3,0.5]},\n","                   'embeddingSize': {\"values\": [64,128,256]},\n","                   'hidden_layer_size': {\"values\": [128,256,512]},\n","                   'layersEncoder': {\"values\": [2, 3]},\n","                   'layersDecoder': {\"values\": [2, 3]},\n","                   \"cellType\": {\"values\": [ \"RNN\", \"GRU\", \"LSTM\"]},\n","                   \"learningRate\": {\"values\": [1e-3, 0.005]},\n","                   \"bidirectional\":{\"values\":[True, False]},\n","                   \"epochs\": {\"values\": [10, 15]}\n","                }\n","}"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:19.312604Z","iopub.status.busy":"2024-05-17T09:50:19.312212Z","iopub.status.idle":"2024-05-17T09:50:19.323005Z","shell.execute_reply":"2024-05-17T09:50:19.322035Z","shell.execute_reply.started":"2024-05-17T09:50:19.312574Z"},"id":"ArDWAV0S03T1","trusted":true},"outputs":[],"source":["def train():\n","   init_sweep =  wandb.init(project=\"CS6910_Assignment3\", name=\"Question2_bayes_NoAttn\")\n","   sweep_params = init_sweep.config\n","\n","   wandb.run.name = \"_cell_\" + sweep_params.cellType + \"_dr_\" + str(sweep_params.drop_out) +\"_em_\" + str(sweep_params.embeddingSize)+ \"_hl_\" + str(sweep_params.hidden_layer_size) +\"_en_\" + str(sweep_params.layersEncoder)+\"_de_\" + str(sweep_params.layersDecoder)+\"_lr_\" + str(sweep_params.learningRate)+\"_bi_\"+str(sweep_params.bidirectional)+\"_ep_\" + str(sweep_params.epochs)\n","\n","   hidden_layer_size=sweep_params.hidden_layer_size\n","   embeddingSize= sweep_params.embeddingSize\n","   cellType=sweep_params.cellType\n","   layersDecoder=sweep_params.layersDecoder\n","   layersEncoder=sweep_params.layersEncoder\n","   attention=True\n","   bidirectional=sweep_params.bidirectional\n","   epochs=sweep_params.epochs\n","   learningRate=sweep_params.learningRate\n","   drop_out=sweep_params.drop_out\n","\n","   if(attention==False):\n","      model = Seq2Seq(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,layersEncoder,layersDecoder,bidirectional,learningRate)\n","\n","   else:\n","      model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,1,1,bidirectional,learningRate, maxLenEng)\n","\n","   model.to(device)\n","   trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n","   trainer.fit(model=model, train_dataloaders=dataloaderTrain, val_dataloaders=dataloaderVal)\n","\n"]},{"cell_type":"code","execution_count":104,"metadata":{"colab":{"referenced_widgets":["b3fcb38393404b76937f2bfc2c649c9c","ac19234c473d40289880f68f4aa87507"]},"execution":{"iopub.execute_input":"2024-05-17T09:16:45.255110Z","iopub.status.busy":"2024-05-17T09:16:45.254746Z","iopub.status.idle":"2024-05-17T09:16:45.265273Z","shell.execute_reply":"2024-05-17T09:16:45.264163Z","shell.execute_reply.started":"2024-05-17T09:16:45.255076Z"},"id":"oftEVRXM03T4","outputId":"a01fe674-f8d2-483a-f909-a1d59347bcf5","trusted":true},"outputs":[],"source":["# Running Sweeps for with attention\n","sweep_id = wandb.sweep(sweep_config, project='CS6910_Assignment3')\n","wandb.agent(sweep_id, train, count = 30)\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["# **Set params to test model**"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:27.040574Z","iopub.status.busy":"2024-05-17T09:50:27.040206Z","iopub.status.idle":"2024-05-17T09:50:27.045808Z","shell.execute_reply":"2024-05-17T09:50:27.044740Z","shell.execute_reply.started":"2024-05-17T09:50:27.040546Z"},"id":"R77AMpiv03T5","trusted":true},"outputs":[],"source":["\n","epochs=1\n","\n","hidden_layer_size=256\n","embeddingSize= 128\n","cellType=\"LSTM\"\n","layersDecoder=3\n","layersEncoder=3\n","attention=True\n","bidirectional=True\n","learningRate=0.001\n","drop_out=0.5\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:31.265192Z","iopub.status.busy":"2024-05-17T09:50:31.264124Z","iopub.status.idle":"2024-05-17T09:50:31.454184Z","shell.execute_reply":"2024-05-17T09:50:31.452938Z","shell.execute_reply.started":"2024-05-17T09:50:31.265153Z"},"id":"3ccgdSVT03T5","trusted":true},"outputs":[{"data":{"text/plain":["Seq2SeqAttn(\n","  (encoder): AttnEncoder(\n","    (embedding): Embedding(29, 128)\n","    (rnn): LSTM(128, 256, dropout=0.5, bidirectional=True)\n","  )\n","  (decoder): AttnDecoder(\n","    (embedding): Embedding(67, 128)\n","    (attn): Linear(in_features=384, out_features=26, bias=True)\n","    (attn_combine): Linear(in_features=640, out_features=256, bias=True)\n","    (rnn): LSTM(256, 256, dropout=0.5, bidirectional=True)\n","    (fc): Linear(in_features=512, out_features=67, bias=True)\n","  )\n",")"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["\n","model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,1,1,bidirectional,learningRate, maxLenEng)\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:50:36.036295Z","iopub.status.busy":"2024-05-17T09:50:36.035499Z","iopub.status.idle":"2024-05-17T09:58:31.775079Z","shell.execute_reply":"2024-05-17T09:58:31.774051Z","shell.execute_reply.started":"2024-05-17T09:50:36.036258Z"},"id":"yv7qsz5d-oUn","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m032\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_095036-j0ctfnwn</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/j0ctfnwn' target=\"_blank\">icy-rain-167</a></strong> to <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/j0ctfnwn' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3/runs/j0ctfnwn</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2024-05-17 09:50:56.564036: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-17 09:50:56.564147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-17 09:50:56.690740: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e68c9ab0b594fbd892dcd1502c168eb","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'trainLoss': tensor(0.5593, device='cuda:0'), 'trainAccuracy': tensor(13.5703), 'valLoss': tensor(0.4699, device='cuda:0'), 'valAccuracy': tensor(29.1587)}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7fb3726f0cc84d9db487b9467bdf21d7","version_major":2,"version_minor":0},"text/plain":["Testing: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'test_loss': tensor(0.4589, device='cuda:0'), 'testAccuracy': tensor(30.1270)}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▁</td></tr><tr><td>Train Loss</td><td>▁</td></tr><tr><td>Validation Accuracy</td><td>▁</td></tr><tr><td>Validation Loss</td><td>▁</td></tr><tr><td>testAccuracy_last</td><td>▁</td></tr><tr><td>test_loss_last</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>13.57031</td></tr><tr><td>Train Loss</td><td>0.55935</td></tr><tr><td>Validation Accuracy</td><td>29.15865</td></tr><tr><td>Validation Loss</td><td>0.46988</td></tr><tr><td>testAccuracy_last</td><td>30.12695</td></tr><tr><td>test_loss_last</td><td>0.45886</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">icy-rain-167</strong> at: <a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/j0ctfnwn' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3/runs/j0ctfnwn</a><br/> View project at: <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240517_095036-j0ctfnwn/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.init(project=\"CS6910_Assignment3\")\n","trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n","trainer.fit(model=model, train_dataloaders=dataloaderTrain, val_dataloaders=dataloaderVal)\n","trainer.test(model, dataloaderTest)\n","wandb.finish()"]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:34:53.364247Z","iopub.status.busy":"2024-05-17T09:34:53.363652Z","iopub.status.idle":"2024-05-17T09:34:53.370980Z","shell.execute_reply":"2024-05-17T09:34:53.370076Z","shell.execute_reply.started":"2024-05-17T09:34:53.364218Z"},"id":"YSnHQaDI03T6","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['input', 'target', 'predicted']\n","\n","[['thermax', 'थरमैक्स', 'थर्मक्स'], ['sikhaaega', 'सिखाएगा', 'सिखाएगा'], ['learn', 'लर्न', 'लीर्न'], ['twitters', 'ट्विटर्स', 'ट्विटर्स'], ['tirunelveli', 'तिरुनेलवेली', 'तिरुनेलवेली'], ['independence', 'इंडिपेंडेंस', 'इंडपेन्डेंस'], ['speshiyon', 'स्पेशियों', 'स्पेशियों'], ['shurooh', 'शुरूः', 'शुरूह'], ['kolhapur', 'कोल्हापुर', 'कोल्हपुर'], ['ajhar', 'अजहर', 'अझर']]\n"]}],"source":["# import csv\n","# rows = []\n","# count=0\n","# with open(\"/kaggle/working/Output.csv\", 'r') as file:\n","#     csvreader = csv.reader(file)\n","#     header = next(csvreader)\n","#     for row in csvreader:\n","#         rows.append(row)\n","#         count=count+1\n","#         if(count==10):\n","#             break\n","# print(header)\n","# print(rows)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4850432,"sourceId":8190591,"sourceType":"datasetVersion"},{"datasetId":4933043,"sourceId":8303996,"sourceType":"datasetVersion"},{"datasetId":4933099,"sourceId":8304151,"sourceType":"datasetVersion"},{"datasetId":4933272,"sourceId":8304593,"sourceType":"datasetVersion"},{"datasetId":5003045,"sourceId":8407265,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
