{"cells":[{"cell_type":"markdown","metadata":{"id":"VejTsKhNLm2A"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"execution":{"iopub.execute_input":"2024-05-06T08:43:36.615958Z","iopub.status.busy":"2024-05-06T08:43:36.615297Z","iopub.status.idle":"2024-05-06T08:44:08.878333Z","shell.execute_reply":"2024-05-06T08:44:08.877409Z","shell.execute_reply.started":"2024-05-06T08:43:36.615925Z"},"id":"mUM6KgAM-oT1","jupyter":{"outputs_hidden":true},"outputId":"e148e589-ad2a-40a1-df9e-9301dad04358","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pytorch_lightning in /opt/conda/lib/python3.10/site-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (1.26.4)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (2.1.2)\n","Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (6.0.1)\n","Requirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.0)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (1.3.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (4.9.0)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning) (0.11.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.1)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (69.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch_lightning) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch_lightning) (3.13.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch_lightning) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch_lightning) (3.1.2)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n","Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.6)\n","Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\n","Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\n","Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\n","Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"]}],"source":["!pip install pytorch_lightning\n","!pip install wandb\n","import torch\n","torch.cuda.empty_cache()\n","import torch.utils.data as data\n","import zipfile\n","import wandb\n","import warnings\n","warnings.filterwarnings(\"ignore\") \n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"HwQHFp9POlu8"},"source":["## Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"tOCLaWWqNtN9"},"source":["###Mounting Drive\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-06T08:44:08.880965Z","iopub.status.busy":"2024-05-06T08:44:08.880339Z","iopub.status.idle":"2024-05-06T08:44:08.886463Z","shell.execute_reply":"2024-05-06T08:44:08.885406Z","shell.execute_reply.started":"2024-05-06T08:44:08.880929Z"},"id":"pEgf2dIi-oUB","outputId":"ad859be8-e2e8-4df1-b0a2-8aa543c21772","trusted":true},"outputs":[],"source":["# # Mount Google Drive to access the dataset\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T08:44:08.888073Z","iopub.status.busy":"2024-05-06T08:44:08.887732Z","iopub.status.idle":"2024-05-06T08:44:08.894812Z","shell.execute_reply":"2024-05-06T08:44:08.893847Z","shell.execute_reply.started":"2024-05-06T08:44:08.888040Z"},"id":"kFtwXvrn-oUC","trusted":true},"outputs":[],"source":["# # Set the path to your zipped dataset\n","# zip_file_path = '/content/drive/MyDrive/DL /aksharantar_sampled.zip'\n","\n","# # Extract the dataset to a folder in Google Drive\n","# zip_ref = zipfile.ZipFile(zip_file_path, 'r')\n","# zip_ref.extractall('aksharantar_sampled_extracted')\n","# zip_ref.close()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-06T08:44:08.897250Z","iopub.status.busy":"2024-05-06T08:44:08.896974Z","iopub.status.idle":"2024-05-06T08:44:08.903372Z","shell.execute_reply":"2024-05-06T08:44:08.902441Z","shell.execute_reply.started":"2024-05-06T08:44:08.897217Z"},"id":"V4sUEZbyOJMQ","outputId":"cd39e823-cc3d-4340-d044-0fbd89ea3bb7","trusted":true},"outputs":[],"source":["# from matplotlib.font_manager import FontProperties\n","# import seaborn as sns\n","# # !unzip Tiro_Devanagari_Hindi.zip -d hindi\n","# # hindi_font = FontProperties(fname = '/kaggle/input/tiro-devanagari-hindi/TiroDevanagariHindi-Regular.ttf')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T08:44:08.905267Z","iopub.status.busy":"2024-05-06T08:44:08.904783Z","iopub.status.idle":"2024-05-06T08:44:09.056082Z","shell.execute_reply":"2024-05-06T08:44:09.054761Z","shell.execute_reply.started":"2024-05-06T08:44:08.905210Z"},"id":"R-OebR_K-oUE","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","# from google.colab import drive\n","import csv\n","# move tensors to GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Path to your CSV file on Google Drive (Extracted file)\n","csv_file_path = '/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv'\n","\n","# Read the CSV file and extract the sequence of characters\n","with open(csv_file_path, 'r') as f:\n","    reader = csv.reader(f)\n","    chars = []\n","    for row in reader:\n","        chars.extend(row[0])  # assuming the first column of the CSV file contains the text data\n","\n","charS=set(chars)\n","charS.add('|')\n","char_set = list(charS)\n","\n","# Define the mapping between characters and integer indices\n","char_to_idx_latin= {char: i+1 for i, char in enumerate(char_set)}\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T08:44:09.058789Z","iopub.status.busy":"2024-05-06T08:44:09.057846Z","iopub.status.idle":"2024-05-06T08:44:09.169714Z","shell.execute_reply":"2024-05-06T08:44:09.168818Z","shell.execute_reply.started":"2024-05-06T08:44:09.058739Z"},"id":"BsSPFp2f-oUF","trusted":true},"outputs":[],"source":["max_length_devanagari=0\n","with open(csv_file_path, 'r') as f:\n","    reader = csv.reader(f)\n","    chars = []\n","\n","    for row in reader:\n","        chars.extend(row[1])  # assuming the first column of the CSV file contains the text data\n","\n","# Define the character set\n","charS=set(chars)\n","charS.add('|')\n","char_set = list(charS)\n","\n","# Define the mapping between characters and integer indices\n","char_to_idx_lang ={char: i+1 for i, char in enumerate(char_set)}"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T08:44:09.171362Z","iopub.status.busy":"2024-05-06T08:44:09.171026Z","iopub.status.idle":"2024-05-06T08:44:09.238717Z","shell.execute_reply":"2024-05-06T08:44:09.237563Z","shell.execute_reply.started":"2024-05-06T08:44:09.171334Z"},"id":"YnH-KUwf-oUH","trusted":true},"outputs":[],"source":["max_length_latin = 0\n","\n","# Read the CSV file and extract the sequence of characters\n","with open(csv_file_path, 'r') as f:\n","    reader = csv.reader(f)\n","    chars = []\n","\n","    for row in reader:\n","        length = len(row[0])  # assuming the column you want to check is the first one\n","        if length > max_length_latin:\n","            max_length_latin = length"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T08:44:09.241392Z","iopub.status.busy":"2024-05-06T08:44:09.240439Z","iopub.status.idle":"2024-05-06T08:44:09.305143Z","shell.execute_reply":"2024-05-06T08:44:09.304036Z","shell.execute_reply.started":"2024-05-06T08:44:09.241359Z"},"id":"_CT0LTQL-oUI","trusted":true},"outputs":[],"source":["max_length_devanagari = 0\n","# Read the CSV file and extract the sequence of characters\n","with open(csv_file_path, 'r') as f:\n","    reader = csv.reader(f)\n","    chars = []\n","\n","    for row in reader:\n","        length = len(row[1])  # assuming the column you want to check is the first one\n","        if length > max_length_devanagari:\n","            max_length_devanagari = length"]},{"cell_type":"markdown","metadata":{"id":"j98Htn0kQTdn"},"source":["Converting characters in words to indices\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T08:44:09.306843Z","iopub.status.busy":"2024-05-06T08:44:09.306486Z","iopub.status.idle":"2024-05-06T08:44:14.609444Z","shell.execute_reply":"2024-05-06T08:44:14.608655Z","shell.execute_reply.started":"2024-05-06T08:44:09.306815Z"},"id":"OQlR-LjU-oUJ","trusted":true},"outputs":[],"source":["def word_to_indices(word, max_length,dict):\n","    # Convert the characters to integer indices using the char_to_idx mapping\n","    indices = [dict.get(c, -1) for c in word]\n","    # Filter out characters not in the dictionary\n","    indices = [idx for idx in indices if idx >= 0]\n","    # Add padding if necessary to make the sequence length equal to max_length\n","    if len(indices) < max_length:\n","        indices += [0] * (max_length - len(indices))\n","    # Truncate the sequence if necessary to make the sequence length equal to max_length\n","    elif len(indices) > max_length:\n","        indices = indices[:max_length]\n","    # Add the start and end tokens to the sequence\n","    indices = [dict['|']] + indices + [dict['|']]\n","    # Convert the list of indices to a tensor\n","    tensor = torch.tensor(indices)\n","    tensor=tensor.to(device)\n","    return tensor\n","\n","pairs=[]\n","# Read the CSV file containing Latin-Devanagari word pairs\n","with open('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv', 'r') as f:\n","    reader = csv.reader(f)\n","    for row in reader:\n","        latin_word = row[0]\n","        devanagari_word = row[1]\n","        # Convert the Latin word to a tensor of integer indices\n","        latin_indices = word_to_indices(latin_word, max_length_latin,char_to_idx_latin)\n","        devanagari_indices= word_to_indices(devanagari_word,max_length_devanagari ,char_to_idx_lang)\n","        pairs.append([latin_indices,devanagari_indices])\n","\n","pairs_v=[]\n","# Read the CSV file containing Latin-Devanagari word pairs\n","with open('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv', 'r') as f_v:\n","    reader_v = csv.reader(f_v)\n","    for row in reader_v:\n","        latin_word = row[0]\n","        devanagari_word = row[1]\n","        # Convert the Latin word to a tensor of integer indices\n","        latin_indices = word_to_indices(latin_word, max_length_latin,char_to_idx_latin)\n","        devanagari_indices= word_to_indices(devanagari_word,max_length_devanagari ,char_to_idx_lang)\n","        pairs_v.append([latin_indices,devanagari_indices])\n","\n","pairs_t=[]\n","# Read the CSV file containing Latin-Devanagari word pairs\n","with open('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv', 'r') as f_t:\n","    reader_t = csv.reader(f_t)\n","    for row in reader_t:\n","        latin_word = row[0]\n","        devanagari_word = row[1]\n","        # Convert the Latin word to a tensor of integer indices\n","        latin_indices = word_to_indices(latin_word, max_length_latin,char_to_idx_latin)\n","        devanagari_indices= word_to_indices(devanagari_word,max_length_devanagari ,char_to_idx_lang)\n","        pairs_t.append([latin_indices,devanagari_indices])"]},{"cell_type":"markdown","metadata":{"id":"akPkrBg3QrqC"},"source":["Loading Data"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T08:44:14.613413Z","iopub.status.busy":"2024-05-06T08:44:14.613044Z","iopub.status.idle":"2024-05-06T08:44:14.619078Z","shell.execute_reply":"2024-05-06T08:44:14.618127Z","shell.execute_reply.started":"2024-05-06T08:44:14.613387Z"},"id":"_35IkD1e-oUM","trusted":true},"outputs":[],"source":["train_dataloader = torch.utils.data.DataLoader(pairs, batch_size=64, shuffle=True)\n","val_dataloader = torch.utils.data.DataLoader(pairs_v, batch_size=64, shuffle=False)\n","test_dataloader = torch.utils.data.DataLoader(pairs_t, batch_size=64, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"g536wVKNQ1XU"},"source":["### Sweep Configuration"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"execution":{"iopub.execute_input":"2024-05-06T08:44:14.620562Z","iopub.status.busy":"2024-05-06T08:44:14.620196Z","iopub.status.idle":"2024-05-06T08:44:33.428947Z","shell.execute_reply":"2024-05-06T08:44:33.427545Z","shell.execute_reply.started":"2024-05-06T08:44:14.620525Z"},"id":"KZ1QyWsV-oUN","outputId":"0fabf021-ae04-485c-b227-4938cbd538b7","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m032\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240506_084416-cj3xvw0e</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/cj3xvw0e' target=\"_blank\">earthy-dream-14</a></strong> to <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/cj3xvw0e' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3/runs/cj3xvw0e</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":[]},{"cell_type":"markdown","metadata":{"id":"xx7qY6JX-oUP"},"source":["Model Without Attention"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T08:44:33.431533Z","iopub.status.busy":"2024-05-06T08:44:33.431222Z","iopub.status.idle":"2024-05-06T08:44:37.499314Z","shell.execute_reply":"2024-05-06T08:44:37.498330Z","shell.execute_reply.started":"2024-05-06T08:44:33.431474Z"},"id":"hyflCGQh-oUU","trusted":true},"outputs":[],"source":["import pytorch_lightning as pl\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, embedding_size,cell_type,drop_out,num_layers,bidirectional):\n","        '''Initialize the Encoder class.\n","              \n","        Args:\n","            input_dim (int): Dimensionality of the input sequence.\n","            hidden_dim (int): Dimensionality of the hidden state in the encoder.\n","            embedding_size (int): Size of the input embedding.\n","            cell_type (str): Type of the RNN cell to use (e.g., LSTM, GRU).\n","            drop_out (float): Dropout probability to apply to the RNN output.\n","            num_layers (int): Number of layers in the encoder.\n","            bidirectional (bool): Flag indicating if the encoder is bidirectional.\n","\n","        '''\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.bidirectional = bidirectional\n","        self.embedding = nn.Embedding(input_dim, embedding_size)\n","\n","        if(cell_type==\"GRU\"):\n","          self.rnn = nn.GRU(embedding_size, hidden_dim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        if(cell_type==\"LSTM\"):\n","          self.rnn = nn.LSTM(embedding_size, hidden_dim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        if(cell_type==\"RNN\"): \n","          self.rnn = nn.RNN(embedding_size, hidden_dim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","\n","    def forward(self, x):\n","        '''Perform forward pass in the Encoder.\n","        \n","        Encode the input sequence into a fixed-size representation.\n","        \n","        Args:\n","            x (Tensor): Input tensor of shape (sequence_length, batch_size).\n","\n","        Returns:\n","            Tensor: Encoded representation of the input sequence.\n","\n","        '''\n","        embedded = self.embedding(x)\n","        output, hidden = self.rnn(embedded)\n","        return hidden\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, hidden_dim,embedding_size ,cell_type,drop_out,num_layers,bidirectional):\n","        '''Initialize the Decoder class.\n","                \n","        Args:\n","            output_dim (int): Dimensionality of the output sequence.\n","            hidden_dim (int): Dimensionality of the hidden state in the decoder.\n","            embedding_size (int): Size of the input embedding.\n","            cell_type (str): Type of the RNN cell to use (e.g., LSTM, GRU).\n","            drop_out (float): Dropout probability to apply to the RNN output.\n","            num_layers (int): Number of layers in the decoder.\n","            bidirectional (bool): Flag indicating if the decoder is bidirectional.\n","\n","        '''\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.embedding = nn.Embedding(output_dim, embedding_size)\n","        self.bidirectional = bidirectional\n","        self.cell_type=cell_type\n","        D=1\n","        if self.bidirectional:\n","          D=2\n","\n","        if(cell_type==\"GRU\"):\n","          self.rnn = nn.GRU(embedding_size, hidden_dim,dropout=drop_out,num_layers=num_layers ,bidirectional=bidirectional)\n","        elif(cell_type==\"LSTM\"):\n","          self.rnn = nn.LSTM(embedding_size, hidden_dim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        elif(cell_type==\"RNN\"):\n","          self.rnn = nn.RNN(embedding_size, hidden_dim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","\n","        self.fc = nn.Linear(hidden_dim*D, output_dim)\n","\n","    def forward(self, x, hidden):\n","        '''Perform forward pass in the Decoder.\n","        \n","        Generate the output sequence by decoding the encoded representation.\n","        \n","        Args:\n","            x (Tensor): Input tensor of shape (sequence_length, batch_size).\n","            hidden (Tensor): Initial hidden state of the decoder.\n","\n","        Returns:\n","            Tensor: Output tensor of shape (sequence_length, batch_size, output_dim).\n","            Tensor: Updated hidden state of the decoder.\n","\n","        '''\n","        x = x.unsqueeze(0)\n","        embedded = self.embedding(x)\n","        output, hidden = self.rnn(embedded, hidden)\n","        prediction = self.fc(output.squeeze(0))\n","        return prediction, hidden\n","\n","import torch.nn.functional as F\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Seq2Seq(pl.LightningModule):\n","    def __init__(self, input_dim, output_dim, hidden_dim,embedding_size, cell_type, drop_out,num_layers_encoders,num_layers_decoders,bidirectional,learning_rate):\n","        '''Initialize the Seq2Seq model.\n","        \n","        Define the architecture and parameters of the sequence-to-sequence model.\n","        \n","        Args:\n","            input_dim (int): Dimensionality of the input sequence.\n","            output_dim (int): Dimensionality of the output sequence.\n","            hidden_dim (int): Dimensionality of the hidden state in the encoder and decoder.\n","            embedding_size (int): Size of the input embedding.\n","            cell_type (str): Type of the RNN cell to use (e.g., LSTM, GRU).\n","            drop_out (float): Dropout probability to apply to the RNN output.\n","            num_layers_encoders (int): Number of layers in the encoder.\n","            num_layers_decoders (int): Number of layers in the decoder.\n","            bidirectional (bool): Flag indicating if the encoder and decoder are bidirectional.\n","            learning_rate (float): Learning rate for the optimizer.\n","\n","        '''\n","        super().__init__()\n","\n","        self.val_loss=[]\n","        self.test_loss=[]\n","        self.train_loss=[]\n","\n","        self.train_accuracy=[]\n","        self.val_accuracy=[]\n","        self.test_accuracy=[]\n","\n","        self.encoder = Encoder(input_dim, hidden_dim, embedding_size,cell_type,drop_out,num_layers_encoders,bidirectional)\n","        self.decoder = Decoder(output_dim, hidden_dim, embedding_size, cell_type,drop_out,num_layers_decoders,bidirectional)\n","        self.num_layers_encoders=num_layers_encoders\n","        self.num_layers_decoders=num_layers_decoders\n","\n","        self.learning_rate=learning_rate\n","        self.cell_type=cell_type\n","\n","        self.bidirectional = bidirectional\n","        self.D=1\n","        if self.bidirectional:\n","          self.D=2\n","\n","    def forward(self, src, trg,teacher_forcing_ratio=0.5):\n","        '''Perform forward pass in the Seq2Seq model.\n","\n","        Encode the source sequence, then decode it to generate the target sequence.\n","        \n","        Args:\n","            src (Tensor): Source input tensor of shape (source_sequence_length, batch_size).\n","            trg (Tensor): Target input tensor of shape (target_sequence_length, batch_size).\n","            teacher_forcing_ratio (float): Probability of using teacher forcing during decoding.\n","\n","        Returns:\n","            Tensor: Output tensor of shape (target_sequence_length, batch_size, output_dim).\n","\n","        '''\n","        batch_size = trg.shape[0]\n","        max_len = trg.shape[1]\n","        trg_vocab_size = self.decoder.fc.out_features\n","        src = src.transpose(0,1)\n","        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n","        hidden = self.encoder(src)\n","\n","        if(self.num_layers_encoders>self.num_layers_decoders):\n","          if(self.cell_type==\"LSTM\"):\n","            (hidden,cell)=hidden\n","            difference=self.num_layers_encoders*self.D-self.num_layers_decoders*self.D\n","            hidden=hidden[difference:]\n","            cell=cell[difference:]\n","            #from the difference to the last\n","            hidden=(hidden,cell)\n","\n","          else:  \n","            difference=self.num_layers_encoders*self.D-self.num_layers_decoders*self.D\n","            hidden=hidden[difference:]  #from the difference to the last\n","\n","        elif(self.num_layers_encoders<self.num_layers_decoders):\n","          cell=[]\n","          if(self.cell_type==\"LSTM\"):\n","            (hidden,cell)=hidden\n","            \n","            last_hidden = hidden[-self.D:]  # Shape: [1, 64, 256]\n","            last_cell = cell[-self.D:]\n","            for i in range(self.num_layers_encoders,self.num_layers_decoders):\n","              hidden = torch.cat([hidden, last_hidden], dim=0)  # Shape: [4, 64, 256]\n","              cell = torch.cat([cell, last_cell], dim=0)  # Shape: [4, 64, 256]\n","            hidden=(hidden,cell)\n","\n","          else:\n","\n","            last_hidden = hidden[-self.D:] # Shape: [1, 64, 256]\n","\n","            for i in range(self.num_layers_encoders,self.num_layers_decoders):\n","              hidden = torch.cat([hidden, last_hidden], dim=0)  # Shape: [4, 64, 256]\n","\n","        input = trg[:,0]#start character\n","        for t in range(1, max_len):\n","            output, hidden = self.decoder(input, hidden)\n","            outputs[t] = output\n","            top1 = output.argmax(1)\n","            input = top1 if teacher_forcing_ratio < torch.rand(1).item() else trg[:,t]\n","            #if teacher_forcing_ratio > the random number generated then use the predicted character at the timestep t in timestamp t+1, else use the true value from the target \n","        return outputs\n","\n","    def training_step(self, batch, batch_idx):\n","        '''Perform a single training step.\n","        \n","        Compute the loss, update the model's parameters, and return the loss value.\n","        \n","        Args:\n","            batch (tuple): Batch of input and target sequences.\n","            batch_idx (int): Index of the current batch.\n","\n","        Returns:\n","            Tensor: Loss value.\n","\n","        '''\n","\n","        src, trg = batch\n","        # Forward pass through the model\n","        output = self(src, trg)\n","        outputAcc = self(src, trg)\n","        trgAcc=trg \n","\n","        outputAcc = outputAcc.permute(1, 0, 2)\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)        \n","        rows = torch.arange(output.shape[0])\n","        # Create a tensor of zeros for expected values and assign 1 at corresponding positions\n","        expected = torch.zeros(size=output.shape)\n","        expected[rows, cols, trg.cpu()] = 1\n","        # Get the output and expected values in the appropriate shape for loss calculation\n","        output_dim = output.shape[-1]\n","        output = output[1:].view(-1, output_dim)\n","        expected = expected[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        train_loss = self.loss_fn(output.to(device), expected.to(device))\n","\n","        train_accuracy =self.accuracy(outputAcc, trgAcc)    #trg is the true value\n","        self.train_accuracy.append(torch.tensor(train_accuracy))\n","        self.train_loss.append(torch.tensor(train_loss))\n","\n","        return {'loss': train_loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","        '''Perform a single validation step.\n","        \n","        Evaluate the model's performance on a validation batch and return the results.\n","        \n","        Args:\n","            batch (tuple): Batch of input and target sequences.\n","            batch_idx (int): Index of the current batch.\n","\n","        '''\n","\n","\n","        src, trg = batch\n","        # Forward pass through the model with a flag value of 0\n","\n","        output = self(src, trg,0)\n","        outputAcc = self(src, trg,0)\n","        trgAcc=trg\n","        # Permute the dimensions of outputAcc for further processing\n","        outputAcc = outputAcc.permute(1, 0, 2)\n","\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)\n","        rows = torch.arange(output.shape[0])\n","        # Create a tensor of zeros for expected values and assign 1 at corresponding positions\n","        expected = torch.zeros(size=output.shape)\n","        expected[rows, cols, trg.cpu()] = 1\n","        # Get the output and expected values in the appropriate shape for loss calculation\n","        output_dim = output.shape[-1]\n","        output = output[1:].view(-1, output_dim)\n","        expected = expected[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","\n","        val_loss = self.loss_fn(output.to(device), expected.to(device))\n","\n","        val_accuracy =self.accuracy(outputAcc, trgAcc)   \n","        self.val_accuracy.append(torch.tensor(val_accuracy))\n","        self.val_loss.append(torch.tensor(val_loss))\n","        return {'loss': val_loss}\n","\n","    def test_step(self, batch, batch_idx):\n","        '''Perform a single test step.\n","        \n","        Evaluate the model's performance on a test batch and return the results.\n","        \n","        Args:\n","            batch (tuple): Batch of input and target sequences.\n","            batch_idx (int): Index of the current batch.\n","\n","        '''\n","        src, trg = batch\n","        # Get the output and expected values for evaluation\n","        output = self(src, trg,0)\n","        outputAcc = self(src, trg,0)\n","        trgAcc=trg\n","\n","        outputAcc = outputAcc.permute(1, 0, 2)\n","        # Create indices for indexing the expected tensor\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)\n","        rows = torch.arange(output.shape[0])\n","        # Create a tensor of zeros with the same size as output for expected values\n","        expected = torch.zeros(size=output.shape)\n","        expected[rows, cols, trg.cpu()] = 1\n","        # Reshape the output and expected tensors for loss calculation\n","        output_dim = output.shape[-1]\n","        output = output[1:].view(-1, output_dim)\n","        expected = expected[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","\n","        test_loss = self.loss_fn(output.to(device), expected.to(device))\n","        test_accuracy =self.accuracy(outputAcc, trgAcc)    #trg is the true value\n","        grid_input,grid_target,grid_predicted=self.grid(src,outputAcc, trgAcc)\n","\n","        # Convert grid target and predicted values to string representations\n","        target_outputs=[]\n","        str_target=\"\"\n","        for i in grid_target:\n","          for j in i:\n","            integer_value = j.item()\n","            str_target=str_target+get_key(j)\n","          target_outputs.append(str_target)\n","          str_target=\"\"\n","\n","        predicted_outputs=[]\n","        str_predicted=\"\"\n","        for i in grid_predicted:\n","          for j in i:\n","            integer_value = j.item()\n","            str_predicted=str_predicted+get_key(j)\n","          predicted_outputs.append(str_predicted)\n","          str_predicted=\"\"\n","\n","        inputs=[]\n","        str_input=\"\"\n","        for i in grid_input:\n","          for j in i:\n","            integer_value = j.item()\n","            str_input=str_input+get_key_input(j)\n","          inputs.append(str_input)\n","          str_input=\"\"\n","\n","        # Append test accuracy and loss to their respective lists\n","        self.test_accuracy.append(torch.tensor(test_accuracy))\n","        self.test_loss.append(torch.tensor(test_loss))\n","#         print({\"test_loss\":test_loss,\"test_accuracy\":test_accuracy})\n","        wandb.log({\"test_loss\":test_loss,\"test_accuracy\":test_accuracy})\n","\n","        save_outputs_to_csv(inputs,target_outputs, predicted_outputs)\n","        return {'loss':test_loss}\n","\n","\n","    def configure_optimizers(self):\n","        \"\"\"\n","        Configure the optimizer.\n","        \"\"\"\n","        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate )\n","        return optimizer\n","\n","    def loss_fn(self, output, trg):\n","        \"\"\"\n","        Calculate the loss function.\n","        \"\"\"\n","        criterion = nn.CrossEntropyLoss()\n","        loss = criterion(output, trg)\n","        return loss.mean()\n","\n","    def accuracy(self, output, target):\n","      \"\"\"\n","      Calculate the accuracy.\n","      \"\"\"\n","      predicted = output.argmax(dim=-1)  # shape: (sequence_length, batch_size)\n","      equal_rows = 0\n","      for i in range(target.size(0)):\n","          # Remove the first and last indices and check if the sliced tensors are equal\n","          if torch.all(torch.eq(target[i, 1:-1], predicted[i, 1:-1])):\n","              equal_rows += 1\n","      matches=equal_rows\n","\n","      # Compute the accuracy\n","      accuracy = matches / len(target) * 100\n","      return accuracy\n","\n","    # def grid(self, output, target):\n","    #   \"\"\"\n","    #   Generate grids for target and expected outputs.\n","    #   \"\"\"\n","    #   grid_target=[]\n","    #   grid_expected=[]\n","    #   predicted = output.argmax(dim=-1)  # shape: (sequence_length, batch_size)\n","    #   for i in range(target.size(0)):\n","    #       # Remove the first and last indices and check if the sliced tensors are equal\n","    #       grid_target.append(target[i, 1:-1])\n","    #       grid_expected.append(predicted[i, 1:-1])\n","\n","    #   return grid_target,grid_expected\n","\n","    def grid(self,input, output, target):\n","      \"\"\"\n","      Generate grids for target and expected outputs.\n","      \"\"\"\n","      grid_input=[]\n","      grid_target=[]\n","      grid_expected=[]\n","      predicted = output.argmax(dim=-1) \n","      for i in range(target.size(0)):\n","          # Remove the first and last indices and check if the sliced tensors are equal\n","          grid_target.append(target[i, 1:-1])\n","          grid_expected.append(predicted[i, 1:-1])\n","          grid_input.append(input[i, 1:-1])\n","      return grid_input,grid_target,grid_expected\n","\n","\n","    def on_train_epoch_end(self):\n","      \"\"\"\n","      Actions to perform at the end of each training epoch.\n","      \"\"\"\n","      train_loss=torch.stack(self.train_loss).mean()\n","      self.train_loss=[]\n","\n","      val_loss=torch.stack(self.val_loss).mean()\n","      self.val_loss=[]\n","\n","      train_accuracy=torch.stack(self.train_accuracy).mean()\n","      self.train_accuracy=[]\n","\n","      val_accuracy=torch.stack(self.val_accuracy).mean()\n","      self.val_accuracy=[]\n","#       print({\"train_loss\":train_loss,\"train_accuracy\":train_accuracy,\"val_loss\":val_loss,\"val_accuracy\":val_accuracy})\n","      wandb.log({\"train_loss\":train_loss,\"train_accuracy\":train_accuracy,\"val_loss\":val_loss,\"val_accuracy\":val_accuracy})\n","\n","# function to return key for any value \n","def get_key(val):\n","    for key, value in char_to_idx_lang.items():\n","        if val == value:\n","            return key\n","    return \"\"\n","\n","def get_key_input(val):\n","    for key, value in char_to_idx_latin.items():\n","        if val == value:\n","            return key\n","    return \"\"\n","\n","def beam_search(self, encoder_output, encoder_hidden, decoder_input, beam_width,batch_size,max_len,trg_vocab_size,output):\n","    # Set initial beam\n","    beam = [(decoder_input, 0, encoder_hidden)]\n","    outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n","\n","\n","    # Iterate through the sequence\n","    for i in range(self.max_seq_len):\n","        new_beam = []\n","        for j in range(len(beam)):\n","            decoder_input = beam[j][0]\n","            decoder_hidden = beam[j][2]\n","\n","            # Run the decoder\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_output)\n","\n","            # Get the top-k most probable tokens\n","            topk_probs, topk_indices = torch.topk(decoder_output, beam_width)\n","\n","            for k in range(beam_width):\n","                # Calculate the new score\n","                score = beam[j][1] + topk_probs[0][k]\n","\n","                # Create a new hypothesis\n","                hypothesis = (\n","                    torch.tensor([topk_indices[0][k]]).to(self.device),\n","                    score,\n","                    decoder_hidden\n","                )\n","\n","                # Add it to the new beam\n","                new_beam.append(hypothesis)\n","        outputs[t] = output\n","\n","        # Select the top-k hypotheses\n","        beam = sorted(new_beam, key=lambda x: x[1], reverse=True)[:beam_width]\n","\n","    return \n","\n","# importing pandas as pd  \n","import pandas as pd  \n","import os\n","\n","def save_outputs_to_csv(inputs,target_outputs, predicted_outputs):\n","    file_exists = os.path.exists('Output.csv')\n","    # dictionary of lists  \n","    dict = {'input':inputs,'target':target_outputs, 'predicted': predicted_outputs}  \n","    df = pd.DataFrame(dict) \n","    # saving the dataframe \n","    df.to_csv('Output.csv',mode='a',index=False,header=not file_exists) "]},{"cell_type":"markdown","metadata":{"id":"_cMJrYHe-oUe"},"source":["Model With Attention\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T08:44:37.501439Z","iopub.status.busy":"2024-05-06T08:44:37.500890Z","iopub.status.idle":"2024-05-06T08:44:37.592558Z","shell.execute_reply":"2024-05-06T08:44:37.591551Z","shell.execute_reply.started":"2024-05-06T08:44:37.501411Z"},"id":"6uWSEe9Y-oUf","trusted":true},"outputs":[],"source":["import pytorch_lightning as pl\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","class AttnEncoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, embedding_size,cell_type,drop_out,num_layers,bidirectional):\n","\n","        \"\"\"\n","        Initializes the Attention Encoder module.\n","\n","        Args:\n","            input_dim (int): Dimensionality of the input.\n","            hidden_dim (int): Dimensionality of the hidden state/output.\n","            embedding_size (int): Size of the embedding for input sequence.\n","            cell_type (str): Type of RNN cell to use (GRU, LSTM, RNN).\n","            drop_out (float): Dropout rate.\n","            num_layers (int): Number of layers in the RNN.\n","            bidirectional (bool): Flag indicating whether to use bidirectional RNN.\n","\n","        \"\"\"\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.bidirectional = bidirectional\n","        self.embedding = nn.Embedding(input_dim, embedding_size)\n","\n","        if(cell_type==\"GRU\"):\n","          self.rnn = nn.GRU(embedding_size, hidden_dim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        if(cell_type==\"LSTM\"):\n","          self.rnn = nn.LSTM(embedding_size, hidden_dim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        if(cell_type==\"RNN\"): \n","          self.rnn = nn.RNN(embedding_size, hidden_dim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Performs a forward pass of the Attention Encoder module.\n","\n","        Args:\n","            x (tensor): Input tensor of shape (seq_len, batch_size).\n","\n","        Returns:\n","            output (tensor): Output tensor from the RNN layer.\n","            hidden (tensor): Hidden state from the RNN layer.\n","\n","        \"\"\"\n","        embedded = self.embedding(x)\n","        output, hidden = self.rnn(embedded)\n","        return output, hidden\n","\n","class AttnDecoder(nn.Module):\n","    def __init__(self, output_dim, hidden_dim,embedding_size ,cell_type,drop_out,num_layers,bidirectional,max_length):\n","        \"\"\"\n","        Initializes the Attention Decoder module.\n","\n","        Args:\n","            output_dim (int): Dimensionality of the output.\n","            hidden_dim (int): Dimensionality of the hidden state/output.\n","            embedding_size (int): Size of the embedding for output sequence.\n","            cell_type (str): Type of RNN cell to use (GRU, LSTM, RNN).\n","            drop_out (float): Dropout rate.\n","            num_layers (int): Number of layers in the RNN.\n","            bidirectional (bool): Flag indicating whether to use bidirectional RNN.\n","            max_length (int): Maximum length of the input sequence.\n","\n","        \"\"\"\n","\n","        self.max_length=max_length+2\n","        super(AttnDecoder, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.embedding = nn.Embedding(output_dim, embedding_size)\n","        self.attn = nn.Linear(self.hidden_dim + embedding_size, self.max_length)\n","        self.bidirectional = bidirectional\n","        self.cell_type=cell_type\n","        D=1\n","        if self.bidirectional:\n","          D=2\n","        self.attn_combine = nn.Linear(self.hidden_dim*D + embedding_size, self.hidden_dim)\n","\n","        if(cell_type==\"GRU\"):\n","          self.rnn = nn.GRU(hidden_dim, hidden_dim,dropout=drop_out,num_layers=num_layers ,bidirectional=bidirectional)\n","        elif(cell_type==\"LSTM\"):\n","          self.rnn = nn.LSTM(hidden_dim, hidden_dim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","        elif(cell_type==\"RNN\"):\n","          self.rnn = nn.RNN(hidden_dim, hidden_dim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n","\n","        self.fc = nn.Linear(hidden_dim*D, output_dim)\n","\n","    def forward(self, x, hidden, encoder_outputs):\n","        \"\"\"\n","        Performs a forward pass of the Attention Decoder module.\n","\n","        Args:\n","            x (tensor): Input tensor of shape (batch_size).\n","            hidden (tensor): Hidden state from the previous time step.\n","            encoder_outputs (tensor): Encoder outputs of shape (seq_len, batch_size, hidden_dim).\n","\n","        Returns:\n","            prediction (tensor): Output tensor from the linear layer.\n","            hidden (tensor): Hidden state for the current time step.\n","            attn_weights (tensor): Attention weights for the current time step.\n","\n","        \"\"\"\n","        x = x.unsqueeze(1).transpose(0,1)\n","        embedded = self.embedding(x)\n","        # Calculate attention weights based on the cell type\n","        if(self.cell_type==\"LSTM\"):\n","          attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0][0]), 1)), dim=1)\n","        else:\n","          attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        # Calculate the attention applied to encoder outputs\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n","                                 encoder_outputs.permute(1,0,2))\n","        # Concatenate embedded input and attention applied tensor\n","        output = torch.cat((embedded[0], attn_applied.squeeze(1)), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        # Adjust hidden and cell variables based on the cell type\n","        if(self.cell_type==\"LSTM\"):\n","          (hidden,cell)=hidden\n","\n","        if(self.cell_type==\"LSTM\"):\n","          output, hidden = self.rnn(output, (hidden,cell))\n","        else:\n","          output, hidden = self.rnn(output, hidden)\n","\n","        prediction = self.fc(output.squeeze(0))\n","        # Return prediction, hidden state, and attention weights\n","        return prediction, hidden, attn_weights\n","\n","import torch.nn.functional as F\n","\n","class Seq2SeqAttn(pl.LightningModule):\n","    def __init__(self, input_dim, output_dim, hidden_dim,embedding_size, cell_type, drop_out,num_layers_encoders,num_layers_decoders,bidirectional,learning_rate,max_length_latin):\n","        \"\"\"\n","        Initializes the Seq2Seq model.\n","\n","        Args:\n","            input_dim (int): Dimensionality of the input sequence.\n","            output_dim (int): Dimensionality of the output sequence.\n","            hidden_dim (int): Dimensionality of the hidden state/output.\n","            embedding_size (int): Size of the embedding for input/output sequences.\n","            cell_type (str): Type of RNN cell to use (GRU, LSTM, RNN).\n","            drop_out (float): Dropout rate.\n","            num_layers (int): Number of layers in the RNN.\n","            bidirectional (bool): Flag indicating whether to use bidirectional RNN.\n","            max_length (int): Maximum length of the input sequence.\n","\n","        \"\"\"\n","        super().__init__()\n","\n","        self.val_loss=[]\n","        self.train_loss=[]\n","\n","        self.train_accuracy=[]\n","        self.val_accuracy=[]\n","\n","        self.test_accuracy=[]\n","        self.test_loss=[]\n","\n","        self.encoder = AttnEncoder(input_dim, hidden_dim, embedding_size,cell_type,drop_out,num_layers_encoders,bidirectional)\n","        self.decoder = AttnDecoder(output_dim, hidden_dim, embedding_size, cell_type,drop_out,num_layers_decoders,bidirectional,max_length_latin)\n","\n","        self.num_layers_encoders=num_layers_encoders\n","        self.num_layers_decoders=num_layers_decoders\n","\n","        self.learning_rate=learning_rate\n","        self.cell_type=cell_type\n","\n","        self.bidirectional = bidirectional\n","        self.D=1\n","        if self.bidirectional:\n","          self.D=2\n","        self.attn_weights=[]\n","        self.counter=0\n","\n","\n","    def forward(self, src, trg,teacher_forcing_ratio=0.5):\n","        \"\"\"\n","        Performs a forward pass of the Seq2Seq model.\n","\n","        Args:\n","            source (tensor): Input tensor of shape (seq_len, batch_size).\n","            target (tensor): Target tensor of shape (seq_len, batch_size).\n","            teacher_forcing_ratio (float): The probability of using teacher forcing.\n","\n","        Returns:\n","            outputs (tensor): Output tensor from the decoder of shape (seq_len, batch_size, output_dim).\n","\n","        \"\"\"\n","        batch_size = trg.shape[0]\n","        max_len = trg.shape[1]\n","        trg_vocab_size = self.decoder.fc.out_features\n","        # Transpose the source tensor\n","        src = src.transpose(0,1)\n","        # Initialize outputs tensor with zeros\n","        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n","        attentionV = torch.zeros(max_len, batch_size, max_length_latin+2).to(self.device)\n","\n","        encoder_output,hidden = self.encoder(src)\n","\n","        input = trg[:,0] #start character\n","        # Iterate over each timestep in the target sequence\n","        for t in range(1, max_len):\n","            # Pass the input, hidden state, and encoder output to the decoder\n","\n","            output, hidden,attentionV[t] = self.decoder(input, hidden,encoder_output)\n","            outputs[t] = output\n","            # Determine the next input based on teacher forcing ratio\n","            top1 = output.argmax(1)\n","            \n","            input = top1 if teacher_forcing_ratio < torch.rand(1).item() else trg[:,t]\n","            #if teacher_forcing_ratio > the random number generated then use the predicted character at the timestep t in timestamp t+1, else use the true value from the target \n","\n","        return outputs, attentionV\n","\n","    def training_step(self, batch, batch_idx):\n","        \"\"\"\n","        Trains the Seq2Seq model.\n","\n","        Args:\n","            model (nn.Module): The Seq2Seq model to train.\n","            iterator (DataLoader): The data iterator.\n","            optimizer (torch.optim.Optimizer): The optimizer to use for training.\n","            criterion (nn.Module): The loss function.\n","            clip (float): The value to clip the gradients.\n","\n","        Returns:\n","            epoch_loss (float): The average loss for the epoch.\n","\n","        \"\"\"\n","        # Get the source and target tensors from the batch\n","        src, trg = batch\n","        output, attentionV = self(src, trg)\n","        outputAcc, attentionVD = self(src, trg)\n","        trgAcc=trg \n","        # Permute the output for accuracy calculation\n","        outputAcc = outputAcc.permute(1, 0, 2)\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)        \n","        rows = torch.arange(output.shape[0])\n","        # Create a tensor for expected values and assign 1 to the corresponding indices\n","        expected = torch.zeros(size=output.shape)\n","        expected[rows, cols, trg.cpu()] = 1\n","\n","        output_dim = output.shape[-1]\n","        # Remove the start token from the output and reshape for loss calculation\n","        output = output[1:].view(-1, output_dim)\n","        expected = expected[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        train_loss = self.loss_fn(output.to(device), expected.to(device))\n","        train_accuracy =self.accuracy(outputAcc, trgAcc)    #trg is the true value\n","        # Append the training accuracy and loss to their respective lists\n","        self.train_accuracy.append(torch.tensor(train_accuracy))\n","        self.train_loss.append(torch.tensor(train_loss))\n","        # del src\n","        # del trg\n","        return {'loss': train_loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","        \"\"\"\n","        Perform a validation step.\n","        \"\"\"\n","        src, trg = batch\n","        output,attentionV = self(src, trg,0)\n","        outputAcc,attentionV = self(src, trg,0)\n","        trgAcc=trg\n","        # Permute the output for accuracy calculation\n","        outputAcc = outputAcc.permute(1, 0, 2)\n","        # Create indices for expected values\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)\n","        rows = torch.arange(output.shape[0])\n","        expected = torch.zeros(size=output.shape)\n","        expected[rows, cols, trg.cpu()] = 1\n","        output_dim = output.shape[-1]\n","        # Remove the start token from the output and reshape for loss calculation\n","        output = output[1:].view(-1, output_dim)\n","        expected = expected[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","\n","        val_loss = self.loss_fn(output.to(device), expected.to(device))\n","        val_accuracy =self.accuracy(outputAcc, trgAcc)    #trg is the true value\n","        # Append the training accuracy and loss to their respective lists\n","        self.val_accuracy.append(torch.tensor(val_accuracy))\n","        self.val_loss.append(torch.tensor(val_loss))\n","        return {'loss': val_loss}\n","\n","\n","    def configure_optimizers(self):\n","        \"\"\"\n","        Configure the optimizer.\n","        \"\"\"\n","        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate )\n","        return optimizer\n","\n","    def loss_fn(self, output, trg):\n","        \"\"\"\n","        Calculate the loss function.\n","        \"\"\"\n","        criterion = nn.CrossEntropyLoss()\n","        loss = criterion(output, trg)\n","        return loss.mean()\n","\n","    def accuracy(self, output, target):\n","      \"\"\"\n","      Calculate the loss function.\n","      \"\"\"\n","      predicted = output.argmax(dim=-1)  # shape: (sequence_length, batch_size)\n","      equal_rows = 0\n","      for i in range(target.size(0)):\n","          # Remove the first and last indices and check if the sliced tensors are equal\n","          if torch.all(torch.eq(target[i, 1:-1], predicted[i, 1:-1])):\n","              equal_rows += 1\n","      matches=equal_rows\n","\n","      # Compute the accuracy\n","      accuracy = matches / len(target) * 100\n","      return accuracy\n","\n","    def grid(self,input, output, target):\n","      \"\"\"\n","      Generate grids for target and expected outputs.\n","      \"\"\"\n","      grid_input=[]\n","      grid_target=[]\n","      grid_expected=[]\n","      predicted = output.argmax(dim=-1) \n","      for i in range(target.size(0)):\n","          # Remove the first and last indices and check if the sliced tensors are equal\n","          grid_target.append(target[i, 1:-1])\n","          grid_expected.append(predicted[i, 1:-1])\n","          grid_input.append(input[i, 1:-1])\n","      return grid_input,grid_target,grid_expected\n","\n","\n","    def on_train_epoch_end(self):\n","      \"\"\"\n","      Actions to perform at the end of each training epoch.\n","      \"\"\"\n","      train_loss=torch.stack(self.train_loss).mean()\n","      self.train_loss=[]\n","\n","      val_loss=torch.stack(self.val_loss).mean()\n","      self.val_loss=[]\n","\n","      train_accuracy=torch.stack(self.train_accuracy).mean()\n","      self.train_accuracy=[]\n","\n","      val_accuracy=torch.stack(self.val_accuracy).mean()\n","      self.val_accuracy=[]\n","#       print({\"train_loss\":train_loss,\"train_accuracy\":train_accuracy,\"val_loss\":val_loss,\"val_accuracy\":val_accuracy})\n","      wandb.log({\"train_loss\":train_loss,\"train_accuracy\":train_accuracy,\"val_loss\":val_loss,\"val_accuracy\":val_accuracy})\n","\n","\n","    def test_step(self, batch, batch_idx):\n","        \"\"\"\n","        Perform a test step.\n","        \"\"\"\n","        src, trg = batch\n","        output, attentionV = self(src, trg,0)\n","        outputAcc, attentionVD = self(src, trg,0)\n","        trgAcc=trg\n","        # Permute the output for accuracy calculation\n","        outputAcc = outputAcc.permute(1, 0, 2)\n","        cols = torch.arange(output.shape[1]).unsqueeze(1)\n","        rows = torch.arange(output.shape[0])\n","        # Create a tensor for expected values and assign 1 to the corresponding indices\n","        expected = torch.zeros(size=output.shape)\n","        expected[rows, cols, trg.cpu()] = 1\n","        output_dim = output.shape[-1]\n","        # Remove the start token from the output and reshape for loss calculation\n","        output = output[1:].view(-1, output_dim)\n","        expected = expected[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","\n","        test_loss = self.loss_fn(output.to(device), expected.to(device))\n","        test_accuracy =self.accuracy(outputAcc, trgAcc)    #trg is the true value\n","        grid_input,grid_target,grid_predicted=self.grid(src,outputAcc, trgAcc)\n","\n","        # Convert grid-based outputs to string representations\n","        target_outputs=[]\n","        str_target=\"\"\n","        for i in grid_target:\n","          for j in i:\n","            integer_value = j.item()\n","            str_target=str_target+get_key(j)\n","          target_outputs.append(str_target)\n","          str_target=\"\"\n","        predicted_outputs=[]\n","        str_predicted=\"\"\n","        for i in grid_predicted:\n","          for j in i:\n","            integer_value = j.item()\n","            str_predicted=str_predicted+get_keyAttn(j)\n","          predicted_outputs.append(str_predicted)\n","          str_predicted=\"\"\n","\n","        inputs=[]\n","        str_input=\"\"\n","        for i in grid_input:\n","          for j in i:\n","            integer_value = j.item()\n","            str_input=str_input+get_key_input(j)\n","          inputs.append(str_input)\n","          str_input=\"\"\n","\n","        # Append test accuracy and loss to their respective lists\n","        self.test_accuracy.append(torch.tensor(test_accuracy))\n","        self.test_loss.append(torch.tensor(test_loss))\n","#         print({\"test_loss\":test_loss,\"test_accuracy\":test_accuracy})\n","        wandb.log({\"test_loss\":test_loss,\"test_accuracy\":test_accuracy})\n","        # Save target and predicted outputs to a CSV file\n","        save_outputs_to_csvAttn(inputs,target_outputs, predicted_outputs)\n","        # plot_attention_weights(self.attn_weights)\n","        if(self.counter<1):\n","          s(inputs,predicted_outputs,attentionV)\n","          self.counter=self.counter+1\n","        return {'loss':test_loss}\n","\n","# function to return key for any value\n","def get_keyAttn(val):\n","    for key, value in char_to_idx_lang.items():\n","        if val == value:\n","            return key\n","    return \"\"\n","    \n","def get_key_inputAttn(val):\n","    for key, value in char_to_idx_latin.items():\n","        if val == value:\n","            return key\n","    return \"\"\n","\n","def beam_searchAttn(self, encoder_output, encoder_hidden, decoder_input, beam_width,batch_size,max_len,trg_vocab_size,output):\n","    # Set initial beam\n","    beam = [(decoder_input, 0, encoder_hidden)]\n","    outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n","\n","    # Iterate through the sequence\n","    for i in range(self.max_seq_len):\n","        new_beam = []\n","        for j in range(len(beam)):\n","            decoder_input = beam[j][0]\n","            decoder_hidden = beam[j][2]\n","\n","            # Run the decoder\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_output)\n","\n","            # Get the top-k most probable tokens\n","            topk_probs, topk_indices = torch.topk(decoder_output, beam_width)\n","\n","            for k in range(beam_width):\n","                # Calculate the new score\n","                score = beam[j][1] + topk_probs[0][k]\n","\n","                # Create a new hypothesis\n","                hypothesis = (\n","                    torch.tensor([topk_indices[0][k]]).to(self.device),\n","                    score,\n","                    decoder_hidden\n","                )\n","\n","                # Add it to the new beam\n","                new_beam.append(hypothesis)\n","        outputs[t] = output\n","\n","        # Select the top-k hypotheses\n","        beam = sorted(new_beam, key=lambda x: x[1], reverse=True)[:beam_width]\n","    return \n","\n","import pandas as pd  \n","      \n","def save_outputs_to_csvAttn(inputs,target_outputs, predicted_outputs):\n","    file_exists = os.path.exists('Output.csv')\n","    # dictionary of lists  \n","    dict = {'input':inputs,'target':target_outputs, 'predicted': predicted_outputs}  \n","    df = pd.DataFrame(dict) \n","    # saving the dataframe \n","    df.to_csv('Output.csv',mode='a',index=False,header=not file_exists) \n","\n","\n","def s(input_words, output_words, attn_weights):\n","    # Create a figure with a 3x3 grid and set the size to 10x10 inches\n","    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n","    \n","    # Adjust the spacing between subplots\n","    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n","    \n","    # Iterate over each index up to 9 and plot the attention weights\n","    for i, ax in enumerate(axes.flat):\n","        # Check if input and output words are provided\n","        if i < len(input_words) and i < len(output_words):\n","            # Get the attention weights for the corresponding input word\n","            attn_weight = attn_weights[i].cpu().detach().numpy()\n","            attn_weight = attn_weight[1:len(input_words[i]) + 1, :len(output_words[i])]\n","            \n","            # Plot the attention weights as a heatmap on the current axis\n","            sns.heatmap(attn_weight, ax=ax, cmap='Blues', cbar=False)\n","            \n","            # Set the y-axis tick positions and labels to the input words and rotate them vertically\n","            ax.set_yticks(range(len(input_words[i])))\n","            ax.set_yticklabels(reversed(input_words[i]), rotation='vertical')\n","            \n","            # Set the x-axis tick positions and labels to the output words and rotate them horizontally\n","            ax.set_xticks(range(len(output_words[i])))\n","#             fontproperties=hindi_font,\n","            ax.set_xticklabels(reversed(output_words[i]), rotation=45, ha='right')\n","            \n","            # Set the title of each subplot as the index number\n","            ax.set_title(f'Attention {i+1}', fontsize=12)\n","        else:\n","            # If input or output words are missing, display a message in the subplot\n","            ax.text(0.5, 0.5, 'Missing Data', horizontalalignment='center', verticalalignment='center', fontsize=12)\n","            ax.axis('off')\n","        \n","    # Remove any unused subplots\n","    for j in range(len(input_words), len(axes.flat)):\n","        fig.delaxes(axes.flat[j])\n","    \n","    # Log the plot to Weights & Biases\n","    wandb.log({\"Question 5\": wandb.Image(plt)})\n","    \n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8tsRCY4AK-wT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"vB4gwUdftBb6"},"source":["### Running the wandb sweep"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T08:44:37.594376Z","iopub.status.busy":"2024-05-06T08:44:37.594005Z","iopub.status.idle":"2024-05-06T08:44:37.605157Z","shell.execute_reply":"2024-05-06T08:44:37.604188Z","shell.execute_reply.started":"2024-05-06T08:44:37.594341Z"},"id":"4ETVcH-t-oUk","trusted":true},"outputs":[],"source":["# def sweep():\n","#     '''Perform hyperparameter sweep using WandB.\n","    \n","#     Initialize the experiment configuration, create the model, train the model,\n","#     and log the results using WandB.\n","\n","#     '''\n","#     wandb.init()\n","#     config = wandb.config\n","\n","#     if(config.attention==False):\n","#       model = Seq2Seq(len(char_to_idx_latin)+2, len(char_to_idx_lang)+2, config.hidden_layer_size, config.input_embedding_size, config.cell_type,config.drop_out,config.number_of_encoder_layers,config.number_of_decoder_layers,config.bidirectional,config.learning_rate)\n","\n","#     else:\n","#       model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(char_to_idx_lang)+2, config.hidden_layer_size, config.input_embedding_size, config.cell_type,config.drop_out,1,1,config.bidirectional,config.learning_rate, max_length_latin)\n","\n","#     model.to(device)\n","#     # Create a Trainer for training the model\n","#     trainer = pl.Trainer(max_epochs=config.epochs, accelerator=\"gpu\", devices=1)\n","#     trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n","\n","#     # Generate a unique run name based on the hyperparameters\n","#     run_name = \"lr_{}_hls_{}_es_{}_ct_{}_do_{}_bd_{}_lr_{}_att_{}\".format(config.learning_rate, config.hidden_layer_size,config.input_embedding_size,config.cell_type, config.drop_out,config.bidirectional,config.learning_rate,config.attention)\n","#     print(run_name)\n","#     wandb.run.name = run_name\n","\n","# # Initialize the WandB sweep\n","# # sweep_id = wandb.sweep(sweep_config,project=pName)\n","# # wandb.agent(sweep_id, sweep)"]},{"cell_type":"markdown","metadata":{"id":"j91TCDDhVvng"},"source":["##Training and Evaluating the model with best hyperparameters"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-06T08:44:37.607788Z","iopub.status.busy":"2024-05-06T08:44:37.606554Z","iopub.status.idle":"2024-05-06T08:44:37.613936Z","shell.execute_reply":"2024-05-06T08:44:37.612844Z","shell.execute_reply.started":"2024-05-06T08:44:37.607752Z"},"id":"M0cHWLbf-oUl","outputId":"a79a8f14-f23b-40de-d696-dfe5abc7131c","trusted":true},"outputs":[],"source":["# hidden_layer_size=256\n","# embedding_size= 256\n","# cell_type=\"LSTM\"\n","# drop_out=0.2\n","# num_layers_encoders=3\n","# num_layers_decoders=2\n","# bidirectional=True\n","# attention=False\n","# learning_rate=0.001\n","# epochs=15\n","# if(attention==False):\n","#   model = Seq2Seq(len(char_to_idx_latin)+2, len(char_to_idx_lang)+2, hidden_layer_size, embedding_size, cell_type,drop_out,num_layers_encoders,num_layers_decoders,bidirectional,learning_rate)\n","\n","# else:\n","#   model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(char_to_idx_lang)+2, hidden_layer_size, embedding_size, cell_type,drop_out,1,1,bidirectional,learning_rate, max_length_latin)\n","\n","# model.to(device)"]},{"cell_type":"code","execution_count":16,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-06T08:44:37.615448Z","iopub.status.busy":"2024-05-06T08:44:37.615062Z","iopub.status.idle":"2024-05-06T08:44:37.785864Z","shell.execute_reply":"2024-05-06T08:44:37.784832Z","shell.execute_reply.started":"2024-05-06T08:44:37.615425Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["Seq2SeqAttn(\n","  (encoder): AttnEncoder(\n","    (embedding): Embedding(29, 16)\n","    (rnn): LSTM(16, 256, dropout=0.2, bidirectional=True)\n","  )\n","  (decoder): AttnDecoder(\n","    (embedding): Embedding(67, 16)\n","    (attn): Linear(in_features=272, out_features=26, bias=True)\n","    (attn_combine): Linear(in_features=528, out_features=256, bias=True)\n","    (rnn): LSTM(256, 256, dropout=0.2, bidirectional=True)\n","    (fc): Linear(in_features=512, out_features=67, bias=True)\n","  )\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# hidden_layer_size=256\n","# embedding_size= 16\n","# cell_type=\"LSTM\"\n","# drop_out=0.2\n","# num_layers_encoders=3\n","# num_layers_decoders=3\n","# bidirectional=True\n","# attention=True\n","# learning_rate=0.001\n","# epochs=10\n","# if(attention==False):\n","#   model = Seq2Seq(len(char_to_idx_latin)+2, len(char_to_idx_lang)+2, hidden_layer_size, embedding_size, cell_type,drop_out,num_layers_encoders,num_layers_decoders,bidirectional,learning_rate)\n","\n","# else:\n","#   model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(char_to_idx_lang)+2, hidden_layer_size, embedding_size, cell_type,drop_out,1,1,bidirectional,learning_rate, max_length_latin)\n","\n","# model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hidden_layer_size=16\n","embedding_size= 16\n","cell_type=\"LSTM\"\n","drop_out=0.2\n","num_layers_encoders=2\n","num_layers_decoders=2\n","bidirectional=True\n","attention=True\n","learning_rate=0.001\n","epochs=1\n","if(attention==False):\n","  model = Seq2Seq(len(char_to_idx_latin)+2, len(char_to_idx_lang)+2, hidden_layer_size, embedding_size, cell_type,drop_out,num_layers_encoders,num_layers_decoders,bidirectional,learning_rate)\n","\n","else:\n","  model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(char_to_idx_lang)+2, hidden_layer_size, embedding_size, cell_type,drop_out,1,1,bidirectional,learning_rate, max_length_latin)\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":891,"referenced_widgets":["e2c6e0ffa3594104a22359e77e3ab090","f9c6934d3cb244f7b20f46ca19a2c7c5","026718ca95cb4435802143337cd8b70b","d52f6ff85f5644e5bd73feebb3f1300f","7f9a0235399d4985a8363fc799a7ea24","3fc597a1bb7c4badb1db05e2674b4cc9","c7cb187525684de6b61ffb01c934626c","3bd0841df2e14a05b8a687578134272c","0499e51a615043cc9da4f5c47dedf592","c67069c5834d48ea8e58ae901c111615","0b33d8b3437046cbba0b33a75f0702be","5164305beb4945a7b6f67f60b28b161f","e11eb1abd3614bcba0776962fa536be5","3b47694ffe1740bfb4afc89b3aec8b83","75f1bae28b104aa3a6b8376ce6e67b16","76f860bac31848088056ad2f41efd906","90363bd470494db7b33a89ab8693cf26","5e98b49124f5456d8be4c101474aea87","e0b8f94992eb47e397d14f82d2e89e90","ede0515ca11f420f9d2c04593d256113","ef35712b7ef745a0b3e7d8cfb0d91bc3","43ca68c849b14af19f87274e8b9b00e0","d40b59a3ad5d42ae9c4dde8c415d1eb5","e90f9274ac9545c3ae5459fea17fbe32","230cc3dd6a394d90bf1c0982b4928f89","7997debfbaeb45009a2bf4f2e7e487a8","4f50298c14b243409a0f54e2fb6588a7"]},"execution":{"iopub.execute_input":"2024-05-06T08:44:37.787373Z","iopub.status.busy":"2024-05-06T08:44:37.787081Z","iopub.status.idle":"2024-05-06T09:00:47.185012Z","shell.execute_reply":"2024-05-06T09:00:47.184145Z","shell.execute_reply.started":"2024-05-06T08:44:37.787346Z"},"id":"yv7qsz5d-oUn","outputId":"fcefa6ce-eb3a-49a8-a010-747e2b03be41","trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:cj3xvw0e) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.017 MB of 0.017 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">earthy-dream-14</strong> at: <a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/cj3xvw0e' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3/runs/cj3xvw0e</a><br/> View project at: <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240506_084416-cj3xvw0e/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:cj3xvw0e). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240506_084437-sccyxspy</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/cs23m032/uncategorized/runs/sccyxspy' target=\"_blank\">electric-glade-16</a></strong> to <a href='https://wandb.ai/cs23m032/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/cs23m032/uncategorized' target=\"_blank\">https://wandb.ai/cs23m032/uncategorized</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/cs23m032/uncategorized/runs/sccyxspy' target=\"_blank\">https://wandb.ai/cs23m032/uncategorized/runs/sccyxspy</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2024-05-06 08:45:01.242541: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-06 08:45:01.242646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-06 08:45:01.344962: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"157cac66472842cd89d5b5b3043e220b","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"358edc55e9744e489487ea34ee0943fb","version_major":2,"version_minor":0},"text/plain":["Testing: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 1000x1000 with 9 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.036 MB of 0.036 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_accuracy</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>53.125</td></tr><tr><td>test_loss</td><td>0.42325</td></tr><tr><td>train_accuracy</td><td>55.45703</td></tr><tr><td>train_loss</td><td>0.14424</td></tr><tr><td>val_accuracy</td><td>41.38184</td></tr><tr><td>val_loss</td><td>0.36352</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">electric-glade-16</strong> at: <a href='https://wandb.ai/cs23m032/uncategorized/runs/sccyxspy' target=\"_blank\">https://wandb.ai/cs23m032/uncategorized/runs/sccyxspy</a><br/> View project at: <a href='https://wandb.ai/cs23m032/uncategorized' target=\"_blank\">https://wandb.ai/cs23m032/uncategorized</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240506_084437-sccyxspy/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.init()\n","# Create a Trainer for training the model\n","trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n","# Set the run name in WandB\n","trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n","# Evaluate the trained model on the test dataset\n","trainer.test(model, test_dataloader)\n","wandb.finish()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:00:47.186488Z","iopub.status.busy":"2024-05-06T09:00:47.186218Z","iopub.status.idle":"2024-05-06T09:00:47.193624Z","shell.execute_reply":"2024-05-06T09:00:47.192729Z","shell.execute_reply.started":"2024-05-06T09:00:47.186463Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['input', 'target', 'predicted']\n","[['thermax', '', ''], ['sikhaaega', '', ''], ['learn', '', ''], ['twitters', '', ''], ['tirunelveli', '', ''], ['independence', '', ''], ['speshiyon', '', ''], ['shurooh', '', ''], ['kolhapur', '', ''], ['ajhar', '', ''], ['karaar', '', ''], ['anka', '', ''], ['wpd', '', ''], ['haashie', '', ''], ['glendale', '', '']]\n"]}],"source":["# import csv\n","# rows = []\n","# count=0\n","# with open(\"/kaggle/working/Output.csv\", 'r') as file:\n","#     csvreader = csv.reader(file)\n","#     header = next(csvreader)\n","#     for row in csvreader:\n","#         rows.append(row)\n","#         count=count+1\n","#         if(count==15):\n","#             break\n","# print(header)\n","# print(rows)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4850432,"sourceId":8190591,"sourceType":"datasetVersion"},{"datasetId":4933099,"sourceId":8304151,"sourceType":"datasetVersion"},{"datasetId":4933272,"sourceId":8304593,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"026718ca95cb4435802143337cd8b70b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7cb187525684de6b61ffb01c934626c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bd0841df2e14a05b8a687578134272c","value":1}},"0499e51a615043cc9da4f5c47dedf592":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c67069c5834d48ea8e58ae901c111615","IPY_MODEL_0b33d8b3437046cbba0b33a75f0702be","IPY_MODEL_5164305beb4945a7b6f67f60b28b161f"],"layout":"IPY_MODEL_e11eb1abd3614bcba0776962fa536be5"}},"0b33d8b3437046cbba0b33a75f0702be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76f860bac31848088056ad2f41efd906","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90363bd470494db7b33a89ab8693cf26","value":1}},"230cc3dd6a394d90bf1c0982b4928f89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b47694ffe1740bfb4afc89b3aec8b83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bd0841df2e14a05b8a687578134272c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3fc597a1bb7c4badb1db05e2674b4cc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43ca68c849b14af19f87274e8b9b00e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7997debfbaeb45009a2bf4f2e7e487a8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f50298c14b243409a0f54e2fb6588a7","value":1}},"4f50298c14b243409a0f54e2fb6588a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5164305beb4945a7b6f67f60b28b161f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e98b49124f5456d8be4c101474aea87","placeholder":"","style":"IPY_MODEL_e0b8f94992eb47e397d14f82d2e89e90","value":" 440/? [05:07&lt;00:00,  1.43it/s]"}},"5e98b49124f5456d8be4c101474aea87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75f1bae28b104aa3a6b8376ce6e67b16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76f860bac31848088056ad2f41efd906":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7997debfbaeb45009a2bf4f2e7e487a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f9a0235399d4985a8363fc799a7ea24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90363bd470494db7b33a89ab8693cf26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c67069c5834d48ea8e58ae901c111615":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b47694ffe1740bfb4afc89b3aec8b83","placeholder":"","style":"IPY_MODEL_75f1bae28b104aa3a6b8376ce6e67b16","value":"Testing: "}},"c7cb187525684de6b61ffb01c934626c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d40b59a3ad5d42ae9c4dde8c415d1eb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d52f6ff85f5644e5bd73feebb3f1300f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0b8f94992eb47e397d14f82d2e89e90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e11eb1abd3614bcba0776962fa536be5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e2c6e0ffa3594104a22359e77e3ab090":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f9c6934d3cb244f7b20f46ca19a2c7c5","IPY_MODEL_026718ca95cb4435802143337cd8b70b"],"layout":"IPY_MODEL_d52f6ff85f5644e5bd73feebb3f1300f"}},"e90f9274ac9545c3ae5459fea17fbe32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ede0515ca11f420f9d2c04593d256113":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_ef35712b7ef745a0b3e7d8cfb0d91bc3","IPY_MODEL_43ca68c849b14af19f87274e8b9b00e0"],"layout":"IPY_MODEL_d40b59a3ad5d42ae9c4dde8c415d1eb5"}},"ef35712b7ef745a0b3e7d8cfb0d91bc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e90f9274ac9545c3ae5459fea17fbe32","placeholder":"","style":"IPY_MODEL_230cc3dd6a394d90bf1c0982b4928f89","value":"0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"}},"f9c6934d3cb244f7b20f46ca19a2c7c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f9a0235399d4985a8363fc799a7ea24","placeholder":"","style":"IPY_MODEL_3fc597a1bb7c4badb1db05e2674b4cc9","value":"0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"}}}}},"nbformat":4,"nbformat_minor":4}
