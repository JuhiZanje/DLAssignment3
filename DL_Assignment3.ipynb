{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VejTsKhNLm2A"
      },
      "source": [
        "# Import and login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:53.599179Z",
          "iopub.status.busy": "2024-05-16T06:53:53.598410Z",
          "iopub.status.idle": "2024-05-16T06:53:53.603174Z",
          "shell.execute_reply": "2024-05-16T06:53:53.602254Z",
          "shell.execute_reply.started": "2024-05-16T06:53:53.599139Z"
        },
        "id": "ea9Qw2XX03Tv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# !pip install pytorch_lightning\n",
        "# !pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:53.606035Z",
          "iopub.status.busy": "2024-05-16T06:53:53.605387Z",
          "iopub.status.idle": "2024-05-16T06:53:53.630291Z",
          "shell.execute_reply": "2024-05-16T06:53:53.629417Z",
          "shell.execute_reply.started": "2024-05-16T06:53:53.606003Z"
        },
        "id": "mUM6KgAM-oT1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "torch.cuda.empty_cache()\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:59.623038Z",
          "iopub.status.busy": "2024-05-16T06:53:59.622735Z",
          "iopub.status.idle": "2024-05-16T06:54:02.566820Z",
          "shell.execute_reply": "2024-05-16T06:54:02.565770Z",
          "shell.execute_reply.started": "2024-05-16T06:53:59.623014Z"
        },
        "id": "KZ1QyWsV-oUN",
        "outputId": "0fabf021-ae04-485c-b227-4938cbd538b7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "wandb.login(key=\"494428cc53b5c21da594f4fc75035d136c63a93c\")\n",
        "# wandb.init( project=\"CS6910_Assignment3\")\n",
        "# !wandb login 494428cc53b5c21da594f4fc75035d136c63a93c\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwQHFp9POlu8"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:53.631818Z",
          "iopub.status.busy": "2024-05-16T06:53:53.631545Z",
          "iopub.status.idle": "2024-05-16T06:53:53.646960Z",
          "shell.execute_reply": "2024-05-16T06:53:53.645909Z",
          "shell.execute_reply.started": "2024-05-16T06:53:53.631794Z"
        },
        "id": "R-OebR_K-oUE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:53.649587Z",
          "iopub.status.busy": "2024-05-16T06:53:53.649288Z",
          "iopub.status.idle": "2024-05-16T06:53:53.658410Z",
          "shell.execute_reply": "2024-05-16T06:53:53.657560Z",
          "shell.execute_reply.started": "2024-05-16T06:53:53.649561Z"
        },
        "id": "lL5546mp03Tw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Data Preprocessing\n",
        "# Load the CSV file and retrieve the character sequence\n",
        "\n",
        "def read_file_0(csvPath):\n",
        "    with open(csvPath, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        chars = []\n",
        "        for row in reader:\n",
        "            chars.extend(row[0])  # assuming that the text data is in the first column of the CSV file\n",
        "    return chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:53.659709Z",
          "iopub.status.busy": "2024-05-16T06:53:53.659445Z",
          "iopub.status.idle": "2024-05-16T06:53:53.735403Z",
          "shell.execute_reply": "2024-05-16T06:53:53.734498Z",
          "shell.execute_reply.started": "2024-05-16T06:53:53.659686Z"
        },
        "id": "MuY2sxX_03Tx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "'''Location of your CSV file (Extracted file)\n",
        "Location of your CSV file if on kaggle than zip file is fine'''\n",
        "csvPath = '/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv'\n",
        "\n",
        "\n",
        "chars = read_file_0(csvPath)\n",
        "setChar=set(chars)\n",
        "setChar.add('|')\n",
        "setOfchar = list(setChar)\n",
        "\n",
        "# Create the association between characters and their corresponding integer indices\n",
        "char_to_idx_latin= {char: i+1 for i, char in enumerate(setOfchar)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:53.736908Z",
          "iopub.status.busy": "2024-05-16T06:53:53.736543Z",
          "iopub.status.idle": "2024-05-16T06:53:53.742173Z",
          "shell.execute_reply": "2024-05-16T06:53:53.741221Z",
          "shell.execute_reply.started": "2024-05-16T06:53:53.736879Z"
        },
        "id": "_Fu5-CC603Tx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def read_file_1(csvPath):\n",
        "    with open(csvPath, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        chars = []\n",
        "\n",
        "        for r in reader:\n",
        "            chars.extend(r[1])\n",
        "    return chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:53.743833Z",
          "iopub.status.busy": "2024-05-16T06:53:53.743511Z",
          "iopub.status.idle": "2024-05-16T06:53:53.852669Z",
          "shell.execute_reply": "2024-05-16T06:53:53.851882Z",
          "shell.execute_reply.started": "2024-05-16T06:53:53.743800Z"
        },
        "id": "BsSPFp2f-oUF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "maxLenDev=0\n",
        "\n",
        "chars = read_file_1(csvPath)\n",
        "setChar=set(chars)\n",
        "setChar.add('|')\n",
        "setOfchar = list(setChar)\n",
        "\n",
        "charToIndLang ={char: i+1 for i, char in enumerate(setOfchar)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:53.854002Z",
          "iopub.status.busy": "2024-05-16T06:53:53.853700Z",
          "iopub.status.idle": "2024-05-16T06:53:53.929439Z",
          "shell.execute_reply": "2024-05-16T06:53:53.928412Z",
          "shell.execute_reply.started": "2024-05-16T06:53:53.853976Z"
        },
        "id": "YnH-KUwf-oUH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the CSV file and retrieve the maxlen of word\n",
        "with open(csvPath, 'r') as f:\n",
        "    fileReader = csv.reader(f)\n",
        "    chars = []\n",
        "\n",
        "    wordLen = 0\n",
        "    maxLenEng = 0\n",
        "    fileIterator = iter(fileReader)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            row = next(fileIterator)\n",
        "            wordLen = len(row[0])\n",
        "            if wordLen > maxLenEng:\n",
        "                maxLenEng = wordLen\n",
        "        except StopIteration:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:53.931415Z",
          "iopub.status.busy": "2024-05-16T06:53:53.930922Z",
          "iopub.status.idle": "2024-05-16T06:53:53.997488Z",
          "shell.execute_reply": "2024-05-16T06:53:53.996645Z",
          "shell.execute_reply.started": "2024-05-16T06:53:53.931369Z"
        },
        "id": "_CT0LTQL-oUI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the CSV file and retrieve the maxlen of word\n",
        "\n",
        "with open(csvPath, 'r') as f:\n",
        "    fileReader = csv.reader(f)\n",
        "    chars = []\n",
        "\n",
        "    wordLen = 0\n",
        "    maxLenDev = 0\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            row = next(fileReader)\n",
        "            wordLen = len(row[1])\n",
        "            if wordLen > maxLenDev:\n",
        "                maxLenDev = wordLen\n",
        "        except StopIteration:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j98Htn0kQTdn"
      },
      "source": [
        "Converting characters in words to indices\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.002561Z",
          "iopub.status.busy": "2024-05-16T06:53:54.002263Z",
          "iopub.status.idle": "2024-05-16T06:53:54.007947Z",
          "shell.execute_reply": "2024-05-16T06:53:54.006910Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.002536Z"
        },
        "id": "cwQAIQqZ03Tx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#func to use char-ind to map char to ind\n",
        "def convert_characters_to_indices(word, dictionary):\n",
        "    indices = [dictionary.get(c, -1) for c in word]\n",
        "    indices = [idx for idx in indices if idx >= 0]\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.009321Z",
          "iopub.status.busy": "2024-05-16T06:53:54.009031Z",
          "iopub.status.idle": "2024-05-16T06:53:54.019806Z",
          "shell.execute_reply": "2024-05-16T06:53:54.018862Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.009296Z"
        },
        "id": "FUM5H7Mg03Ty",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#function to make all words of same size\n",
        "def adjust_sequence_length(indices, maximumLength):\n",
        "    diff = maximumLength - len(indices)\n",
        "    if diff < 0:\n",
        "        indices = indices[:maximumLength]\n",
        "    # If needed, add padding to ensure the sequence length equals maximumLength\n",
        "    elif diff > 0:\n",
        "        indices += [0] * (maximumLength - len(indices))\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.021247Z",
          "iopub.status.busy": "2024-05-16T06:53:54.020971Z",
          "iopub.status.idle": "2024-05-16T06:53:54.031271Z",
          "shell.execute_reply": "2024-05-16T06:53:54.030402Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.021224Z"
        },
        "id": "KDbMqEz603Ty",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#fun to covert indices to tensor\n",
        "def convert_indices_to_tensor(indices, dictionary):\n",
        "    start_token = dictionary.get('|', 0)\n",
        "    end_token = dictionary.get('|', 0)\n",
        "    indices = [start_token] + indices + [end_token]\n",
        "    indTens = torch.tensor(indices)\n",
        "    indTens = indTens.to(device)\n",
        "    return indTens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.032832Z",
          "iopub.status.busy": "2024-05-16T06:53:54.032500Z",
          "iopub.status.idle": "2024-05-16T06:53:54.041869Z",
          "shell.execute_reply": "2024-05-16T06:53:54.040980Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.032802Z"
        },
        "id": "xiCpaoAS03Ty",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#fun to covert word to indices\n",
        "def convert_word_to_indices(word, maximumLength,dict):\n",
        "    indices = convert_characters_to_indices(word, dict)\n",
        "    indices = adjust_sequence_length(indices, maximumLength)\n",
        "    indTens = convert_indices_to_tensor(indices, dict)\n",
        "    return indTens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.043752Z",
          "iopub.status.busy": "2024-05-16T06:53:54.043173Z",
          "iopub.status.idle": "2024-05-16T06:53:54.053900Z",
          "shell.execute_reply": "2024-05-16T06:53:54.053070Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.043720Z"
        },
        "id": "kD_82yWR03Ty",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def assign_tensor_to_generated_sequences(sequence):\n",
        "    seq_list = sequence.split()\n",
        "    final_tensor = \"\"\n",
        "    for word in seq_list:\n",
        "        final_tensor+=word\n",
        "\n",
        "    final_length = 0\n",
        "    for word in seq_list:\n",
        "        final_length += len(word)\n",
        "\n",
        "    return final_tensor,final_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.055686Z",
          "iopub.status.busy": "2024-05-16T06:53:54.055139Z",
          "iopub.status.idle": "2024-05-16T06:53:54.068700Z",
          "shell.execute_reply": "2024-05-16T06:53:54.067750Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.055655Z"
        },
        "id": "l55xlEDd03Ty",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def assemble_tensor(final_tensor,partition_size=1):\n",
        "    if partition_size <= 0:\n",
        "        partition_size = 1\n",
        "    tensor_word_list = []\n",
        "    for i in range(0,len(final_tensor),partition_size):\n",
        "        tensor_word_list.append(final_tensor[i:i+partition_size])\n",
        "    return tensor_word_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.070117Z",
          "iopub.status.busy": "2024-05-16T06:53:54.069780Z",
          "iopub.status.idle": "2024-05-16T06:53:54.079240Z",
          "shell.execute_reply": "2024-05-16T06:53:54.078393Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.070090Z"
        },
        "id": "xP9SJjd703Ty",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def assemble_assigned_generated_seq(path):\n",
        "    final_tensor,final_length = assign_tensor_to_generated_sequences(path)\n",
        "    tensor_word_list = assemble_tensor(final_tensor,(int)(final_length/4))\n",
        "    return tensor_word_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.080517Z",
          "iopub.status.busy": "2024-05-16T06:53:54.080223Z",
          "iopub.status.idle": "2024-05-16T06:53:54.091275Z",
          "shell.execute_reply": "2024-05-16T06:53:54.090438Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.080493Z"
        },
        "id": "lJXojBZT03Ty",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def generate_indices(row):\n",
        "    latin_word = row[0]\n",
        "    devanagari_word = row[1]\n",
        "    engInd = convert_word_to_indices(latin_word, maxLenEng,char_to_idx_latin)\n",
        "    hindInd= convert_word_to_indices(devanagari_word,maxLenDev ,charToIndLang)\n",
        "    return engInd,hindInd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.092812Z",
          "iopub.status.busy": "2024-05-16T06:53:54.092444Z",
          "iopub.status.idle": "2024-05-16T06:53:54.445205Z",
          "shell.execute_reply": "2024-05-16T06:53:54.444317Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.092785Z"
        },
        "id": "ZSy6RABD03Ty",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#processing validation file\n",
        "pairs_v=[]\n",
        "with open('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv', 'r') as f_v:\n",
        "    reader_v = csv.reader(f_v)\n",
        "    for row in reader_v:\n",
        "        engInd,hindInd = generate_indices(row)\n",
        "        pairs_v.append([engInd,hindInd])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.446588Z",
          "iopub.status.busy": "2024-05-16T06:53:54.446296Z",
          "iopub.status.idle": "2024-05-16T06:53:54.798527Z",
          "shell.execute_reply": "2024-05-16T06:53:54.797495Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.446564Z"
        },
        "id": "u_JIj3nF03Ty",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#processing test file\n",
        "pairs_t=[]\n",
        "with open('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv', 'r') as f_t:\n",
        "    reader_t = csv.reader(f_t)\n",
        "    for row in reader_t:\n",
        "        engInd,hindInd = generate_indices(row)\n",
        "        pairs_t.append([engInd,hindInd])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:54.800019Z",
          "iopub.status.busy": "2024-05-16T06:53:54.799715Z",
          "iopub.status.idle": "2024-05-16T06:53:59.613375Z",
          "shell.execute_reply": "2024-05-16T06:53:59.612565Z",
          "shell.execute_reply.started": "2024-05-16T06:53:54.799993Z"
        },
        "id": "dGf4YZCT03Ty",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#processing train file\n",
        "pairs=[]\n",
        "with open('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        engInd,hindInd = generate_indices(row)\n",
        "        pairs.append([engInd,hindInd])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1gOOg0e10OM"
      },
      "source": [
        "# Get Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:53:59.615320Z",
          "iopub.status.busy": "2024-05-16T06:53:59.614778Z",
          "iopub.status.idle": "2024-05-16T06:53:59.621512Z",
          "shell.execute_reply": "2024-05-16T06:53:59.620491Z",
          "shell.execute_reply.started": "2024-05-16T06:53:59.615285Z"
        },
        "id": "_35IkD1e-oUM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#get data loaders\n",
        "batchSize=32\n",
        "shuffleValTest=False\n",
        "shuffleTrain=True\n",
        "dataloaderVal = torch.utils.data.DataLoader(pairs_v, batch_size=batchSize, shuffle=shuffleValTest)\n",
        "dataloaderTest = torch.utils.data.DataLoader(pairs_t, batch_size=batchSize, shuffle=shuffleValTest)\n",
        "dataloaderTrain = torch.utils.data.DataLoader(pairs, batch_size=batchSize, shuffle=shuffleTrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcm5RZtp7pxV"
      },
      "source": [
        "# Encoder/Decoder class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:54:02.568880Z",
          "iopub.status.busy": "2024-05-16T06:54:02.568567Z",
          "iopub.status.idle": "2024-05-16T06:54:02.583774Z",
          "shell.execute_reply": "2024-05-16T06:54:02.582764Z",
          "shell.execute_reply.started": "2024-05-16T06:54:02.568850Z"
        },
        "id": "hyflCGQh-oUU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Encoder class for without attention\n",
        "class Encoder(nn.Module):\n",
        "    #initialise the encoder class with given params\n",
        "    def __init__(self, inpDim, hiddenDim, embeddingSize,cellType,drop_out,num_layers,bidirectional):\n",
        "        super().__init__()\n",
        "        self.hiddenDim = hiddenDim\n",
        "        self.bidirectional = bidirectional\n",
        "        self.embedding = nn.Embedding(inpDim, embeddingSize)\n",
        "\n",
        "        if(cellType==\"GRU\"):\n",
        "          self.rnn = nn.GRU(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n",
        "        if(cellType==\"LSTM\"):\n",
        "          self.rnn = nn.LSTM(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n",
        "        if(cellType==\"RNN\"):\n",
        "          self.rnn = nn.RNN(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n",
        "\n",
        "    #performs forward pass on the Encoder.\n",
        "    def forward(self, x):\n",
        "        output, hidden = self.rnn(self.embedding(x))\n",
        "        return hidden\n",
        "\n",
        "#Decoder class for without attention\n",
        "class Decoder(nn.Module):\n",
        "    #initialise decoder with given params.\n",
        "    def __init__(self, opDim, hiddenDim,embeddingSize ,cellType,drop_out,num_layers,bidirectional):\n",
        "        super().__init__()\n",
        "        self.hiddenDim = hiddenDim\n",
        "        self.cellType=cellType\n",
        "        self.bidirectional = bidirectional\n",
        "        dimention=1\n",
        "        if self.bidirectional:\n",
        "          dimention=2\n",
        "\n",
        "        self.embedding = nn.Embedding(opDim, embeddingSize)\n",
        "        varCellTypeGRU=(cellType==\"GRU\")\n",
        "        varCellTypeLSTM=(cellType==\"LSTM\")\n",
        "        varCellTypeRNN=(cellType==\"RNN\")\n",
        "        if(varCellTypeGRU):\n",
        "          self.rnn = nn.GRU(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers ,bidirectional=bidirectional)\n",
        "        elif(varCellTypeRNN):\n",
        "          self.rnn = nn.RNN(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n",
        "        elif(varCellTypeLSTM):\n",
        "          self.rnn = nn.LSTM(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n",
        "\n",
        "        varToLiner3arg=hiddenDim*dimention\n",
        "        self.fc = nn.Linear(varToLiner3arg, opDim)\n",
        "\n",
        "    #forward pass for the decoder.\n",
        "    #To decode the encoded representation and generate the output sequence\n",
        "    def forward(self, x, hidden):\n",
        "        output, hidden = self.rnn(self.embedding(x.unsqueeze(0)), hidden)\n",
        "        outpuRE=output.squeeze(0)\n",
        "        prediction = self.fc(outpuRE)\n",
        "        return prediction, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP2TgKFa7zjA"
      },
      "source": [
        "# SEQ2SEQ class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:54:02.585900Z",
          "iopub.status.busy": "2024-05-16T06:54:02.585547Z",
          "iopub.status.idle": "2024-05-16T06:54:02.635473Z",
          "shell.execute_reply": "2024-05-16T06:54:02.634384Z",
          "shell.execute_reply.started": "2024-05-16T06:54:02.585867Z"
        },
        "id": "_Oq5i7o-03Tz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Sequence class for without attention\n",
        "class Seq2Seq(pl.LightningModule):\n",
        "    #initialise the Seq2Seq class with given params\n",
        "    def __init__(self, inpDim, opDim, hiddenDim,embeddingSize, cellType, drop_out,layersEncoder,layersDecoder,bidirectional,learningRate):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.learningRate=learningRate\n",
        "        self.cellType=cellType\n",
        "        self.layersEncoder=layersEncoder\n",
        "        self.layersDecoder=layersDecoder\n",
        "        self.bidirectional = bidirectional\n",
        "        self.dimention=1\n",
        "\n",
        "        self.valLoss=[]\n",
        "        self.valAccuracy=[]\n",
        "\n",
        "        self.test_loss=[]\n",
        "        self.testAccuracy=[]\n",
        "\n",
        "        self.trainLoss=[]\n",
        "        self.trainAccuracy=[]\n",
        "\n",
        "        if self.bidirectional:\n",
        "          self.dimention=2\n",
        "\n",
        "        self.encoder = Encoder(inpDim, hiddenDim, embeddingSize,cellType,drop_out,layersEncoder,bidirectional)\n",
        "        self.decoder = Decoder(opDim, hiddenDim, embeddingSize, cellType,drop_out,layersDecoder,bidirectional)\n",
        "\n",
        "    #forward pass for seq2seq. Encode the original sequence and then decode it to produce the target sequence.\n",
        "    def forward(self, src, trg,teacher_forcing_ratio=0.5):\n",
        "        batch_size = trg.shape[0]\n",
        "        max_len = trg.shape[1]\n",
        "\n",
        "        vocabSizeTrgt = self.decoder.fc.out_features\n",
        "        outputs = torch.zeros(max_len, batch_size, vocabSizeTrgt).to(self.device)\n",
        "\n",
        "        src = src.transpose(0,1)\n",
        "        hidden = self.encoder(src)\n",
        "\n",
        "        varToEncGrtDec= (self.layersEncoder>self.layersDecoder)\n",
        "        varTocellType= (self.cellType==\"LSTM\")\n",
        "        if(varToEncGrtDec):\n",
        "          diff1=self.layersEncoder*self.dimention\n",
        "          diff2=self.layersDecoder*self.dimention\n",
        "          difference=diff1-diff2\n",
        "          if(varTocellType):\n",
        "            (hidden,cell)=hidden\n",
        "            cell=cell[difference:]\n",
        "            hidden=hidden[difference:]\n",
        "            hidden=(hidden,cell)\n",
        "\n",
        "          else:\n",
        "            hidden=hidden[difference:]\n",
        "\n",
        "        varToEncLesDec=(self.layersEncoder<self.layersDecoder)\n",
        "        if(varToEncLesDec):\n",
        "          cell=[]\n",
        "          varTocellType= (self.cellType==\"LSTM\")\n",
        "          if(varTocellType):\n",
        "            (hidden,cell)=hidden\n",
        "\n",
        "            cellLast = cell[-self.dimention:]\n",
        "            hiddenLast = hidden[-self.dimention:]\n",
        "            i = self.layersEncoder\n",
        "            while i < self.layersDecoder:\n",
        "                hidden = torch.cat([hidden, hiddenLast], dim=0)\n",
        "                cell = torch.cat([cell, cellLast], dim=0)\n",
        "                i += 1\n",
        "            hidden=(hidden,cell)\n",
        "\n",
        "          else:\n",
        "\n",
        "            hiddenLast = hidden[-self.dimention:]\n",
        "            i = self.layersEncoder\n",
        "            while i < self.layersDecoder:\n",
        "                hidden = torch.cat([hidden, hiddenLast], dim=0)\n",
        "                i += 1\n",
        "\n",
        "\n",
        "        input = trg[:,0] #1st character\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "            outputs[t] = output\n",
        "            if teacher_forcing_ratio < torch.rand(1).item():\n",
        "                input = output.argmax(1)\n",
        "            else:\n",
        "                input = trg[:, t]\n",
        "        return outputs\n",
        "\n",
        "    def forward_pass(self, src, trg):\n",
        "        output = self(src, trg)\n",
        "        return output\n",
        "\n",
        "    #this function will compute expected values for given data\n",
        "    def compute_expected_values(self, output, trg):\n",
        "        row_indices = torch.arange(output.shape[0])\n",
        "        col_indices = torch.arange(output.shape[1]).unsqueeze(1)\n",
        "\n",
        "        expected = torch.zeros_like(output)\n",
        "\n",
        "        assemble_assigned_generated_seq('/kaggle/input/aksharantar-sampled-4/aksharantar_sampled/hin/hin_train.csv')\n",
        "        expected[row_indices, col_indices, trg.cpu()] = 1\n",
        "        return expected\n",
        "\n",
        "    #fun to compute loss given true val and predicted val\n",
        "    def calculate_loss(self, output, expected, trg):\n",
        "        #change the shapes of correctop and output\n",
        "        output_dimensions = output.shape[-1]\n",
        "        expected = expected[1:].view(-1, output_dimensions)\n",
        "        output = output[1:].view(-1, output_dimensions)\n",
        "        trg = trg[1:].view(-1)\n",
        "        trainLoss = self.loss_fn(output.to(device), expected.to(device)) # this will calculate the loss\n",
        "        return trainLoss\n",
        "\n",
        "    #fun to calculate accuracy\n",
        "    def calculate_accuracy(self, output, trg):\n",
        "\n",
        "        output_accuracy = output.permute(1, 0, 2)\n",
        "        trainAccuracy = self.accuracy(output_accuracy, trg)  # trg is the true value\n",
        "        return trainAccuracy\n",
        "\n",
        "    #fun to update trainAcc and trainloss mat\n",
        "    def update_metrics(self, trainLoss, trainAccuracy):\n",
        "        self.trainAccuracy.append(torch.tensor(trainAccuracy))\n",
        "        self.trainLoss.append(torch.tensor(trainLoss))\n",
        "\n",
        "    #This fun will be called at every training step. return the loss.\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, trg = batch\n",
        "        trg_accuracy=trg\n",
        "        output = self.forward_pass(src, trg)\n",
        "\n",
        "        trainAccuracy = self.calculate_accuracy(output, trg_accuracy)\n",
        "\n",
        "        expected = self.compute_expected_values(output, trg)\n",
        "\n",
        "        trainLoss = self.calculate_loss(output, expected, trg)\n",
        "\n",
        "        self.update_metrics(trainLoss, trainAccuracy)\n",
        "\n",
        "        return {'loss': trainLoss}\n",
        "\n",
        "\n",
        "    def forward_pass_validation(self, src, trg):\n",
        "        output = self(src, trg, 0)\n",
        "        return output\n",
        "\n",
        "    #this function will compute expected values for given validation data\n",
        "    def compute_expected_values_validation(self, output, trg):\n",
        "        cols = torch.arange(output.shape[1]).unsqueeze(1)\n",
        "        rows = torch.arange(output.shape[0])\n",
        "        expected = torch.zeros(size=output.shape)\n",
        "        expected[rows, cols, trg.cpu()] = 1\n",
        "        return expected\n",
        "\n",
        "    #this function will compute loss for given true and predicted val (validation data)\n",
        "    def calculate_loss_validation(self, output, expected, trg):\n",
        "        opDim = output.shape[-1]\n",
        "        output = output[1:].view(-1, opDim)\n",
        "        expected = expected[1:].view(-1, opDim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        valLoss = self.loss_fn(output.to(device), expected.to(device))\n",
        "        return valLoss\n",
        "\n",
        "    #this function is a helper function to compute accuracy for given (validation data)\n",
        "    def calculate_accuracy_validation(self, output_acc, trg_acc):\n",
        "        output_acc = output_acc.permute(1, 0, 2)\n",
        "        valAccuracy = self.accuracy(output_acc, trg_acc)\n",
        "        return valAccuracy\n",
        "\n",
        "    #fun to update valAcc and valloss mat\n",
        "    def update_metrics_validation(self, valLoss, valAccuracy):\n",
        "        self.valAccuracy.append(torch.tensor(valAccuracy))\n",
        "        self.valLoss.append(torch.tensor(valLoss))\n",
        "\n",
        "    #Operates on a single batch of data from the validation set.Return loss.\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, trg = batch\n",
        "        trg_accuracy = trg\n",
        "        output = self.forward_pass_validation(src, trg)\n",
        "        output_acc = self.forward_pass_validation(src, trg)\n",
        "\n",
        "        expected = self.compute_expected_values_validation(output, trg)\n",
        "\n",
        "        valLoss = self.calculate_loss_validation(output, expected, trg)\n",
        "\n",
        "        valAccuracy = self.calculate_accuracy_validation(output_acc, trg_accuracy)\n",
        "\n",
        "        self.update_metrics_validation(valLoss, valAccuracy)\n",
        "\n",
        "        return {'loss': valLoss}\n",
        "\n",
        "    '''\n",
        "      Operates on a single batch of data from the test set.\n",
        "      When the test_step() is called, the model has been put in eval mode and PyTorch gradients have been disabled\n",
        "    '''\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        src, trg = batch\n",
        "        outputAcc = self(src, trg,0)\n",
        "        output = self(src, trg,0)\n",
        "        trgAcc=trg\n",
        "        assemble_assigned_generated_seq('/kaggle/input/aksharantar-sampled-4/aksharantar_sampled/hin/hin_test.csv')\n",
        "        rows = torch.arange(output.shape[0])\n",
        "        cols = torch.arange(output.shape[1]).unsqueeze(1)\n",
        "        expected = torch.zeros(size=output.shape)\n",
        "        expected[rows, cols, trg.cpu()] = 1\n",
        "        opDim = output.shape[-1]\n",
        "        output = output[1:].view(-1, opDim)\n",
        "        expected = expected[1:].view(-1, opDim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        #output->predicted , expected->true val\n",
        "        test_loss = self.loss_fn(output.to(device), expected.to(device))\n",
        "\n",
        "        outputAcc = outputAcc.permute(1, 0, 2)\n",
        "        testAccuracy =self.accuracy(outputAcc, trgAcc)\n",
        "        target_outputs=[]\n",
        "\n",
        "        #now we will convert calculated grid to strings\n",
        "        inputGrid,trgGrid,grid_predicted=self.grid(src,outputAcc, trgAcc)\n",
        "        targetString=\"\"\n",
        "\n",
        "        for i in trgGrid:\n",
        "          for j in i:\n",
        "            integer_value = j.item()\n",
        "            targetString=targetString+keyForVal(j)\n",
        "          target_outputs.append(targetString)\n",
        "          str_cp = (targetString + '.')[:-1]\n",
        "          assemble_assigned_generated_seq(str_cp)\n",
        "          targetString=\"\"\n",
        "\n",
        "        predicted_outputs=[]\n",
        "        str_predicted=\"\"\n",
        "        for i in grid_predicted:\n",
        "          for j in i:\n",
        "            integer_value = j.item()\n",
        "            str_predicted=str_predicted+keyForVal(j)\n",
        "          predicted_outputs.append(str_predicted)\n",
        "          str_cp = (str_predicted + '.')[:-1]\n",
        "          assemble_assigned_generated_seq(str_cp)\n",
        "          str_predicted=\"\"\n",
        "\n",
        "        inpString=\"\"\n",
        "        inputs=[]\n",
        "        for i in inputGrid:\n",
        "          for j in i:\n",
        "            integer_value = j.item()\n",
        "            inpString=inpString+keyForInput(j)\n",
        "          inputs.append(inpString)\n",
        "          str_cp = (inpString + '.')[:-1]\n",
        "          assemble_assigned_generated_seq(str_cp)\n",
        "          inpString=\"\"\n",
        "\n",
        "        self.test_loss.append(torch.tensor(test_loss))\n",
        "        self.testAccuracy.append(torch.tensor(testAccuracy))\n",
        "        save_outputs_to_csv(inputs,target_outputs, predicted_outputs)#save the input word ,ouput word and predicted word to csv file\n",
        "\n",
        "#         print({\"test_loss\":test_loss,\"testAccuracy\":testAccuracy})\n",
        "        wandb.log({\"Test Accuracy\":testAccuracy,\"Test loss\":test_loss})\n",
        "\n",
        "        return {'loss':test_loss}\n",
        "\n",
        "    #func to config optimizer\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.learningRate )\n",
        "        return optimizer\n",
        "\n",
        "    #func to config loss fun\n",
        "    def loss_fn(self, output, trg):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(output, trg)\n",
        "        return loss.mean()\n",
        "\n",
        "    #function to find accuracy given ouput and true value (word wise)\n",
        "    def accuracy(self, output, target):\n",
        "      predicted = output.argmax(dim=-1)\n",
        "      equal_rows = 0\n",
        "      for i in range(target.size(0)):\n",
        "            assemble_assigned_generated_seq('calculate accuracy')\n",
        "\n",
        "            if torch.all(torch.eq(target[i, 1:-1], predicted[i, 1:-1])):\n",
        "                equal_rows += 1\n",
        "      matches=equal_rows\n",
        "\n",
        "      accuracy = matches / len(target) * 100\n",
        "      return accuracy\n",
        "\n",
        "    #fun to create grid given input word,ouput word and predicted word\n",
        "    def grid(self,input, output, target):\n",
        "      expectedGrid=[]\n",
        "      predOutput = output.argmax(dim=-1)\n",
        "      inputGrid=[]\n",
        "      trgGrid=[]\n",
        "      i = 0\n",
        "      while i < target.size(0):\n",
        "          trgGrid.append(target[i, 1:-1])\n",
        "          assemble_assigned_generated_seq(\"grids for target\" + str(i))\n",
        "          expectedGrid.append(predOutput[i, 1:-1])\n",
        "          inputGrid.append(input[i, 1:-1])\n",
        "          i += 1\n",
        "\n",
        "      return inputGrid,trgGrid,expectedGrid\n",
        "\n",
        "    '''\n",
        "      Train Epoch-level Operations.\n",
        "      Fun will be called after every epoch.\n",
        "    '''\n",
        "    def on_train_epoch_end(self):\n",
        "      trainLoss=torch.stack(self.trainLoss).mean()\n",
        "      self.trainLoss=[]\n",
        "\n",
        "      valLoss=torch.stack(self.valLoss).mean()\n",
        "      self.valLoss=[]\n",
        "\n",
        "      trainAccuracy=torch.stack(self.trainAccuracy).mean()\n",
        "      self.trainAccuracy=[]\n",
        "\n",
        "      valAccuracy=torch.stack(self.valAccuracy).mean()\n",
        "      self.valAccuracy=[]\n",
        "#       print({\"trainLoss\":trainLoss,\"trainAccuracy\":trainAccuracy,\"valLoss\":valLoss,\"valAccuracy\":valAccuracy})\n",
        "      wandb.log({\"Train Loss\":trainLoss,\"Train Accuracy\":trainAccuracy,\"Validation Loss\":valLoss,\"Validation Accuracy\":valAccuracy})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:54:02.638315Z",
          "iopub.status.busy": "2024-05-16T06:54:02.637844Z",
          "iopub.status.idle": "2024-05-16T06:54:02.650778Z",
          "shell.execute_reply": "2024-05-16T06:54:02.649957Z",
          "shell.execute_reply.started": "2024-05-16T06:54:02.638286Z"
        },
        "id": "Se-Z7LwU03T0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "#function will save ouput to the csv file(actual,predicted)\n",
        "def save_outputs_to_csv(inputs,target_outputs, predicted_outputs):\n",
        "    file_exists = os.path.exists('Output_no_Attn.csv')\n",
        "    dict = {'input':inputs,'target':target_outputs, 'predicted': predicted_outputs}\n",
        "    df = pd.DataFrame(dict)\n",
        "    df.to_csv('Output.csv',mode='a',index=False,header=not file_exists)\n",
        "\n",
        "# function will return key for given value\n",
        "def keyForInput(val):\n",
        "    for k, v in char_to_idx_latin.items():\n",
        "        if val == v:\n",
        "            return k\n",
        "    return \"\"\n",
        "\n",
        "def keyForVal(val):\n",
        "    for k, v in charToIndLang.items():\n",
        "        if val == v:\n",
        "            return k\n",
        "    return \"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srus1PiK78L8"
      },
      "source": [
        "# AttnEncoder/AttnDecoder class(with attention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-05-16T06:54:02.652381Z",
          "iopub.status.busy": "2024-05-16T06:54:02.652116Z",
          "iopub.status.idle": "2024-05-16T06:54:02.720902Z",
          "shell.execute_reply": "2024-05-16T06:54:02.719984Z",
          "shell.execute_reply.started": "2024-05-16T06:54:02.652359Z"
        },
        "id": "6uWSEe9Y-oUf",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3f5a2ab3-c9d1-4455-d8d6-93021005453e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#AttnEncoder class for with attention\n",
        "\n",
        "class AttnEncoder(nn.Module):\n",
        "  #initialise the Attnencoder class with given params\n",
        "    def __init__(self, inpDim, hiddenDim, embeddingSize,cellType,drop_out,num_layers,bidirectional):\n",
        "        super().__init__()\n",
        "        self.hiddenDim = hiddenDim\n",
        "        self.bidirectional = bidirectional\n",
        "        self.embedding = nn.Embedding(inpDim, embeddingSize)\n",
        "\n",
        "        if(cellType==\"GRU\"):\n",
        "          self.rnn = nn.GRU(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n",
        "        if(cellType==\"LSTM\"):\n",
        "          self.rnn = nn.LSTM(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n",
        "        if(cellType==\"RNN\"):\n",
        "          self.rnn = nn.RNN(embeddingSize, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n",
        "\n",
        "    #performs forward pass on the AttnEncoder.\n",
        "    def forward(self, x):\n",
        "        output, hidden = self.rnn(self.embedding(x))\n",
        "        return output, hidden\n",
        "\n",
        "#AttnDecoder class for without attention\n",
        "class AttnDecoder(nn.Module):\n",
        "    #initialise AttnDecoder with given params.\n",
        "    def __init__(self, opDim, hiddenDim,embeddingSize ,cellType,drop_out,num_layers,bidirectional,maximumLength):\n",
        "\n",
        "        self.maximumLength=maximumLength+2\n",
        "        super(AttnDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(opDim, embeddingSize)\n",
        "        self.hiddenDim = hiddenDim\n",
        "        self.bidirectional = bidirectional\n",
        "        varToLinerArg=(self.hiddenDim + embeddingSize)\n",
        "        self.attn = nn.Linear(varToLinerArg, self.maximumLength)\n",
        "        self.cellType=cellType\n",
        "        dimention=1\n",
        "        if self.bidirectional:\n",
        "          dimention=2\n",
        "\n",
        "        varToAttnCombineArg=(self.hiddenDim*dimention + embeddingSize)\n",
        "        self.attn_combine = nn.Linear(varToAttnCombineArg, self.hiddenDim)\n",
        "\n",
        "        varCellTypeGRU=(cellType==\"GRU\")\n",
        "        varCellTypeLSTM=(cellType==\"LSTM\")\n",
        "        varCellTypeRNN=(cellType==\"RNN\")\n",
        "\n",
        "        if(varCellTypeGRU):\n",
        "          self.rnn = nn.GRU(hiddenDim, hiddenDim,dropout=drop_out,num_layers=num_layers ,bidirectional=bidirectional)\n",
        "        elif(varCellTypeRNN):\n",
        "          self.rnn = nn.RNN(hiddenDim, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n",
        "        elif(varCellTypeLSTM):\n",
        "          self.rnn = nn.LSTM(hiddenDim, hiddenDim,dropout=drop_out,num_layers=num_layers,bidirectional=bidirectional)\n",
        "\n",
        "        varToLiner2Arg=hiddenDim*dimention\n",
        "        self.fc = nn.Linear(varToLiner2Arg, opDim)\n",
        "\n",
        "    '''\n",
        "    forward pass for the decoder.\n",
        "    To decode the encoded representation and generate the output sequence\n",
        "    we will also calculate Attention weights\n",
        "    '''\n",
        "    def forward(self, x, hidden, encoderOutput):\n",
        "        x = x.unsqueeze(1)\n",
        "        x=x.transpose(0,1)\n",
        "\n",
        "        varTocellType= (self.cellType==\"LSTM\")\n",
        "        embedded = self.embedding(x)\n",
        "        if(varTocellType):\n",
        "          selfAttn=self.attn(torch.cat((embedded[0], hidden[0][0]), 1))\n",
        "          attentionWeights = F.softmax(selfAttn, dim=1)\n",
        "        else:\n",
        "          selfAttn=self.attn(torch.cat((embedded[0], hidden[0]), 1))\n",
        "          attentionWeights = F.softmax(selfAttn, dim=1)\n",
        "\n",
        "        #resize attentionWeights and  encoderOutput\n",
        "        attentionApplied = torch.bmm(attentionWeights.unsqueeze(1),\n",
        "                                 encoderOutput.permute(1,0,2))\n",
        "        output = torch.cat((embedded[0], attentionApplied.squeeze(1)), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        varTocellType= (self.cellType==\"LSTM\")\n",
        "        #as LSTM return 2 things hidden and cell\n",
        "        if(varTocellType):\n",
        "          (hidden,cell)=hidden\n",
        "\n",
        "        if(varTocellType):\n",
        "          output, hidden = self.rnn(output, (hidden,cell))\n",
        "        else:\n",
        "          output, hidden = self.rnn(output, hidden)\n",
        "\n",
        "        prediction = self.fc(output.squeeze(0))\n",
        "        return prediction, hidden, attentionWeights\n",
        "\n",
        "#Sequence class for with attention\n",
        "class Seq2SeqAttn(pl.LightningModule):\n",
        "    #initialise the Seq2SeqAttn class with given params\n",
        "    def __init__(self, inpDim, opDim, hiddenDim,embeddingSize, cellType, drop_out,layersEncoder,layersDecoder,bidirectional,learningRate,maxLenEng):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.layersEncoder=layersEncoder\n",
        "        self.learningRate=learningRate\n",
        "        self.layersDecoder=layersDecoder\n",
        "        self.cellType=cellType\n",
        "\n",
        "        self.valLoss=[]\n",
        "        self.valAccuracy=[]\n",
        "\n",
        "        self.trainLoss=[]\n",
        "        self.trainAccuracy=[]\n",
        "\n",
        "        self.test_loss=[]\n",
        "        self.testAccuracy=[]\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.encoder = AttnEncoder(inpDim, hiddenDim, embeddingSize,cellType,drop_out,layersEncoder,bidirectional)\n",
        "        self.decoder = AttnDecoder(opDim, hiddenDim, embeddingSize, cellType,drop_out,layersDecoder,bidirectional,maxLenEng)\n",
        "        self.dimention=1\n",
        "        varTobidir=self.bidirectional\n",
        "        if varTobidir:\n",
        "          self.dimention=2\n",
        "\n",
        "        self.counter=0\n",
        "        self.attentionWeights=[]\n",
        "\n",
        "    #forward pass for seq2seqAttn. Encode the original sequence and then decode it to produce the target sequence.\n",
        "    #return output and attention weights\n",
        "    def forward(self, src, trg,teacher_forcing_ratio=0.5):\n",
        "        batch_size = trg.shape[0]\n",
        "        max_len = trg.shape[1]\n",
        "        src = src.transpose(0,1)\n",
        "        attentionV = torch.zeros(max_len, batch_size, maxLenEng+2).to(self.device)\n",
        "\n",
        "        vocabSizeTrgt = self.decoder.fc.out_features\n",
        "        encoder_output,hidden = self.encoder(src)\n",
        "        outputs = torch.zeros(max_len, batch_size, vocabSizeTrgt).to(self.device)\n",
        "\n",
        "        input = trg[:,0]\n",
        "        t = 1\n",
        "        while t < max_len:\n",
        "            output, hidden, attentionV[t] = self.decoder(input, hidden, encoder_output)\n",
        "            outputs[t] = output\n",
        "            if teacher_forcing_ratio < torch.rand(1).item():\n",
        "                input = output.argmax(1)\n",
        "            else:\n",
        "                input = trg[:, t]\n",
        "            t += 1\n",
        "        return outputs, attentionV\n",
        "\n",
        "    #fun to get model output\n",
        "    def get_model_output(self, src, trg):\n",
        "        output, attentionV = self(src, trg)\n",
        "        output_acc, _ = self(src, trg)\n",
        "        return output, output_acc.permute(1, 0, 2)\n",
        "\n",
        "    #fun will return expected values tensor\n",
        "    def prepare_expected_tensor(self, output, trg):\n",
        "        rows = torch.arange(output.shape[0])\n",
        "        cols = torch.arange(output.shape[1]).unsqueeze(1)\n",
        "        expected = torch.zeros(size=output.shape)\n",
        "        expected[rows, cols, trg.cpu()] = 1\n",
        "        return expected\n",
        "\n",
        "    def prepare_output_expected_tensors(self, output, trg):\n",
        "        opDim = output.shape[-1]\n",
        "        output = output[1:].view(-1, opDim)\n",
        "        expected = self.prepare_expected_tensor(output, trg)[1:].view(-1, opDim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        return output, expected, trg\n",
        "\n",
        "    #helper func to find loss\n",
        "    def calculate_loss(self, output, expected):\n",
        "        return self.loss_fn(output.to(device), expected.to(device))\n",
        "\n",
        "    #helper fun to find accuracy\n",
        "    def calculate_accuracy(self, output, trg):\n",
        "        return self.accuracy(output, trg)\n",
        "\n",
        "    def append_metrics(self, trainLoss, trainAccuracy):\n",
        "        self.trainAccuracy.append(torch.tensor(trainAccuracy))\n",
        "        self.trainLoss.append(torch.tensor(trainLoss))\n",
        "\n",
        "    #This fun will be called at every training step. return the loss.\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, trg = batch\n",
        "\n",
        "        trg_accuracy = trg\n",
        "        output, output_acc = self.get_model_output(src, trg)\n",
        "\n",
        "        output, expected, trg = self.prepare_output_expected_tensors(output, trg)\n",
        "\n",
        "        trainAccuracy = self.calculate_accuracy(output_acc, trg_accuracy)\n",
        "\n",
        "        trainLoss = self.calculate_loss(output, expected)\n",
        "\n",
        "        self.append_metrics(trainLoss, trainAccuracy)\n",
        "\n",
        "        return {'loss': trainLoss}\n",
        "\n",
        "\n",
        "    def get_output(self, src, trg):\n",
        "        output, attentionV = self(src, trg, 0)\n",
        "        output_acc, attentionV = self(src, trg, 0)\n",
        "        return output, output_acc.permute(1, 0, 2)\n",
        "\n",
        "    def prepare_output_expected_tensors(self, output, trg):\n",
        "        rows = torch.arange(output.shape[0])\n",
        "        cols = torch.arange(output.shape[1]).unsqueeze(1)\n",
        "        expected = torch.zeros(size=output.shape)\n",
        "        path = '/kaggle/input/aksharantar-sampled-5/aksharantar_sampled/hin/hin_val.csv'\n",
        "        expected[rows, cols, trg.cpu()] = 1\n",
        "        opDim = output.shape[-1]\n",
        "        return output[1:].view(-1, opDim), expected[1:].view(-1, opDim), trg[1:].view(-1)\n",
        "\n",
        "    def calculate_loss(self, output, expected):\n",
        "        return self.loss_fn(output.to(device), expected.to(device))\n",
        "\n",
        "    def calculate_accuracy(self, output, trg):\n",
        "        return self.accuracy(output, trg)\n",
        "\n",
        "    def assemble_and_save_sequences(self, path):\n",
        "        assemble_assigned_generated_seq(path)\n",
        "\n",
        "    #Operates on a single batch of data from the validation set.Return validationLoss.\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, trg = batch\n",
        "        trg_accuracy = trg\n",
        "\n",
        "        output, output_accuracy = self.get_output(src, trg)\n",
        "\n",
        "        output, expected, trg = self.prepare_output_expected_tensors(output, trg)\n",
        "\n",
        "        valLoss = self.calculate_loss(output, expected)\n",
        "\n",
        "        valAccuracy = self.calculate_accuracy(output_accuracy, trg_accuracy)\n",
        "\n",
        "        path = '/kaggle/input/aksharantar-sampled-5/aksharantar_sampled/hin/hin_val.csv'\n",
        "        self.assemble_and_save_sequences(path)\n",
        "\n",
        "        self.valAccuracy.append(torch.tensor(valAccuracy))\n",
        "        self.valLoss.append(torch.tensor(valLoss))\n",
        "\n",
        "        return {'loss': valLoss}\n",
        "\n",
        "\n",
        "    #func to config optimizer\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.learningRate )\n",
        "        return optimizer\n",
        "\n",
        "    #func to config loss fun\n",
        "    def loss_fn(self, output, trg):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(output, trg)\n",
        "        return loss.mean()\n",
        "\n",
        "    #function to find accuracy given ouput and true value (word wise)\n",
        "    def accuracy(self, output, target):\n",
        "      predicted = output.argmax(dim=-1)\n",
        "      equal_rows = 0\n",
        "      i = 0\n",
        "      while i < target.size(0):\n",
        "          if torch.all(torch.eq(target[i, 1:-1], predicted[i, 1:-1])):\n",
        "              equal_rows += 1\n",
        "          i += 1\n",
        "      matches=equal_rows\n",
        "\n",
        "      accuracy = matches / len(target) * 100\n",
        "      return accuracy\n",
        "\n",
        "    #fun to create grid given input word,ouput word and predicted word\n",
        "    def grid(self,input, output, target):\n",
        "      inputGrid=[]\n",
        "      trgGrid=[]\n",
        "      expectedGrid=[]\n",
        "      predicted = output.argmax(dim=-1)\n",
        "      i = 0\n",
        "      while i < target.size(0):\n",
        "          trgGrid.append(target[i, 1:-1])\n",
        "          expectedGrid.append(predicted[i, 1:-1])\n",
        "          inputGrid.append(input[i, 1:-1])\n",
        "          i += 1\n",
        "      return inputGrid,trgGrid,expectedGrid\n",
        "\n",
        "    '''\n",
        "      Train Epoch-level Operations.\n",
        "      Fun will be called after every epoch.\n",
        "    '''\n",
        "    def on_train_epoch_end(self):\n",
        "      trainLoss=torch.stack(self.trainLoss).mean()\n",
        "      self.trainLoss=[]\n",
        "\n",
        "      valLoss=torch.stack(self.valLoss).mean()\n",
        "      self.valLoss=[]\n",
        "\n",
        "      trainAccuracy=torch.stack(self.trainAccuracy).mean()\n",
        "      self.trainAccuracy=[]\n",
        "\n",
        "      valAccuracy=torch.stack(self.valAccuracy).mean()\n",
        "      self.valAccuracy=[]\n",
        "#       print({\"trainLoss\":trainLoss,\"trainAccuracy\":trainAccuracy,\"valLoss\":valLoss,\"valAccuracy\":valAccuracy})\n",
        "      wandb.log({\"Train Loss\":trainLoss,\"Train Accuracy\":trainAccuracy,\"Validation Loss\":valLoss,\"Validation Accuracy\":valAccuracy})\n",
        "\n",
        "\n",
        "    def get_out_attention(self,src,trg):\n",
        "        output, attentionV = self(src, trg,0)\n",
        "        outputAcc, attentionVD = self(src, trg,0)\n",
        "        return output,attentionV,outputAcc.permute(1,0,2)\n",
        "\n",
        "    def get_expected(self,output, trg):\n",
        "        cols = torch.arange(output.shape[1]).unsqueeze(1)\n",
        "        rows = torch.arange(output.shape[0])\n",
        "        expected = torch.zeros(size=output.shape)\n",
        "        expected[rows, cols, trg.cpu()] = 1\n",
        "        return expected\n",
        "\n",
        "    '''\n",
        "      Operates on a single batch of data from the test set.\n",
        "      When the test_step() is called, the model has been put in eval mode and PyTorch gradients have been disabled\n",
        "    '''\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        test_path = '/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_val.csv'\n",
        "        assemble_assigned_generated_seq(test_path)\n",
        "        src, trg = batch\n",
        "        trgAcc=trg\n",
        "\n",
        "        output, attentionV, outputAcc = self.get_out_attention(src, trg)\n",
        "\n",
        "        expected = self.get_expected(output, trg)\n",
        "        opDim = output.shape[-1]\n",
        "\n",
        "        output = output[1:].view(-1, opDim)\n",
        "        expected = expected[1:].view(-1, opDim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        test_loss = self.loss_fn(output.to(device), expected.to(device))\n",
        "        testAccuracy =self.accuracy(outputAcc, trgAcc)\n",
        "        inputGrid,trgGrid,grid_predicted=self.grid(src,outputAcc, trgAcc)\n",
        "\n",
        "        assemble_assigned_generated_seq(\"string representations\")\n",
        "        #convert grid representation to string\n",
        "        #for target string\n",
        "        target_outputs=[]\n",
        "        targetString=\"\"\n",
        "        for i in trgGrid:\n",
        "          for j in i:\n",
        "            integer_value = j.item()\n",
        "            targetString=targetString+keyForVal(j)\n",
        "          target_outputs.append(targetString)\n",
        "          str_cp = (targetString + '.')[:-1]\n",
        "          assemble_assigned_generated_seq(str_cp)\n",
        "          targetString=\"\"\n",
        "\n",
        "        #for predicted string\n",
        "        predicted_outputs=[]\n",
        "        str_predicted=\"\"\n",
        "        for i in grid_predicted:\n",
        "          for j in i:\n",
        "            integer_value = j.item()\n",
        "            str_predicted=str_predicted+get_keyAttn(j)\n",
        "          predicted_outputs.append(str_predicted)\n",
        "          str_cp = (str_predicted + '.')[:-1]\n",
        "          assemble_assigned_generated_seq(str_cp)\n",
        "          str_predicted=\"\"\n",
        "\n",
        "        #for input string\n",
        "        inputs=[]\n",
        "        inpString=\"\"\n",
        "        for i in inputGrid:\n",
        "          for j in i:\n",
        "            integer_value = j.item()\n",
        "            inpString=inpString+keyForInput(j)\n",
        "          inputs.append(inpString)\n",
        "          inpString=\"\"\n",
        "\n",
        "        str_cp = (inpString + '.')[:-1]\n",
        "        assemble_assigned_generated_seq(str_cp)\n",
        "        self.testAccuracy.append(torch.tensor(testAccuracy))\n",
        "        self.test_loss.append(torch.tensor(test_loss))\n",
        "        # print({\"for batch test_loss\":test_loss,\"testAccuracy\":testAccuracy})\n",
        "        wandb.log({\"Test Loss\":test_loss,\"Test Accuracy\":testAccuracy})\n",
        "        # Save target and predicted outputs to a CSV file\n",
        "        save_outputs_to_csvAttn(inputs,target_outputs, predicted_outputs)\n",
        "        # if(self.counter<1):\n",
        "        #   s(inputs,predicted_outputs,attentionV)\n",
        "        #   self.counter=self.counter+1\n",
        "        return {'loss':test_loss}\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        testAccuracy=torch.stack(self.testAccuracy).mean()\n",
        "        self.testAccuracy=[]\n",
        "\n",
        "        test_loss=torch.stack(self.test_loss).mean()\n",
        "        self.test_loss=[]\n",
        "        print({\"test_loss\":test_loss,\"testAccuracy\":testAccuracy})\n",
        "        # wandb.log({\"Train Loss\":trainLoss,\"Train Accuracy\":trainAccuracy,\"Validation Loss\":valLoss,\"Validation Accuracy\":valAccuracy})\n",
        "\n",
        "\n",
        "# function to return key for any value\n",
        "def get_keyAttn(val):\n",
        "    keys = list(charToIndLang.keys())\n",
        "    values = list(charToIndLang.values())\n",
        "    index = 0\n",
        "    key = \"\"\n",
        "\n",
        "    while index < len(values):\n",
        "        if val == values[index]:\n",
        "            key = keys[index]\n",
        "            break\n",
        "        index += 1\n",
        "\n",
        "    return key\n",
        "\n",
        "\n",
        "def get_key_inputAttn(val):\n",
        "    keys = list(char_to_idx_latin.keys())\n",
        "    values = list(char_to_idx_latin.values())\n",
        "    index = 0\n",
        "    key = \"\"\n",
        "\n",
        "    while index < len(values):\n",
        "        if val == values[index]:\n",
        "            key = keys[index]\n",
        "            break\n",
        "        index += 1\n",
        "\n",
        "    return key\n",
        "\n",
        "#function will save the input word ,ouput word and predicted word to csv file for attention module\n",
        "def save_outputs_to_csvAttn(inputs,target_outputs, predicted_outputs):\n",
        "    file_exists = os.path.exists('Output_Attn.csv')\n",
        "    dict = {'input':inputs,'target':target_outputs, 'predicted': predicted_outputs}\n",
        "    df = pd.DataFrame(dict)\n",
        "    df.to_csv('Output.csv',mode='a',index=False,header=not file_exists)\n",
        "\n",
        "#function to create 3*3 grid of heatMap\n",
        "def s(input_words, output_words, attentionWeights):\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "\n",
        "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # Check if input and output words are provided\n",
        "        if i < len(input_words) and i < len(output_words):\n",
        "            # Get the attention weights for the corresponding input word\n",
        "            attn_weight = attentionWeights[i].cpu().detach().numpy()\n",
        "            attn_weight = attn_weight[1:len(input_words[i]) + 1, :len(output_words[i])]\n",
        "\n",
        "            # Plot the attention weights as a heatmap on the current axis\n",
        "            sns.heatmap(attn_weight, ax=ax, cmap='Blues', cbar=False)\n",
        "\n",
        "            # Set the y-axis tick positions and labels to the input words and rotate them vertically\n",
        "            ax.set_yticks(range(len(input_words[i])))\n",
        "            ax.set_yticklabels(reversed(input_words[i]), rotation='vertical')\n",
        "\n",
        "            # Set the x-axis tick positions and labels to the output words and rotate them horizontally\n",
        "            ax.set_xticks(range(len(output_words[i])))\n",
        "#             fontproperties=hindi_font,\n",
        "            ax.set_xticklabels(reversed(output_words[i]), rotation=45, ha='right')\n",
        "\n",
        "            # Set the title of each subplot as the index number\n",
        "            ax.set_title(f'Attention {i+1}', fontsize=12)\n",
        "        else:\n",
        "            # If input or output words are missing, display a message in the subplot\n",
        "            ax.text(0.5, 0.5, 'Missing Data', horizontalalignment='center', verticalalignment='center', fontsize=12)\n",
        "            ax.axis('off')\n",
        "\n",
        "    for j in range(len(input_words), len(axes.flat)):\n",
        "        fig.delaxes(axes.flat[j])\n",
        "\n",
        "    wandb.log({\"Question 5\": wandb.Image(plt)})\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tsRCY4AK-wT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB4gwUdftBb6"
      },
      "source": [
        "# Sweep for Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:54:02.722461Z",
          "iopub.status.busy": "2024-05-16T06:54:02.722193Z",
          "iopub.status.idle": "2024-05-16T06:54:02.738350Z",
          "shell.execute_reply": "2024-05-16T06:54:02.737241Z",
          "shell.execute_reply.started": "2024-05-16T06:54:02.722439Z"
        },
        "id": "P3Mbgj3-03T1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    # Bayesian Search for hyperparameters\n",
        "    \"name\" : \"Bayesian Sweep_Attn\",\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"goal\": \"maximize\", \"name\": \"Validation Accuracy\"},\n",
        "    \"parameters\": {'drop_out': {\"values\": [0.3,0.5]},\n",
        "                   'embeddingSize': {\"values\": [64,128,256]},\n",
        "                   'hidden_layer_size': {\"values\": [128,256,512]},\n",
        "                   'layersEncoder': {\"values\": [2, 3]},\n",
        "                   'layersDecoder': {\"values\": [2, 3]},\n",
        "                   \"cellType\": {\"values\": [ \"RNN\", \"GRU\", \"LSTM\"]},\n",
        "                   \"learningRate\": {\"values\": [1e-3, 0.005]},\n",
        "                   \"bidirectional\":{\"values\":[True, False]},\n",
        "                   \"epochs\": {\"values\": [10, 15]}\n",
        "                }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T06:54:02.744939Z",
          "iopub.status.busy": "2024-05-16T06:54:02.744590Z",
          "iopub.status.idle": "2024-05-16T06:54:02.754982Z",
          "shell.execute_reply": "2024-05-16T06:54:02.754251Z",
          "shell.execute_reply.started": "2024-05-16T06:54:02.744896Z"
        },
        "id": "ArDWAV0S03T1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "   init_sweep =  wandb.init(project=\"CS6910_Assignment3\", name=\"Question2_bayes_NoAttn\")\n",
        "   sweep_params = init_sweep.config\n",
        "\n",
        "   wandb.run.name = \"_cell_\" + sweep_params.cellType + \"_dr_\" + str(sweep_params.drop_out) +\"_em_\" + str(sweep_params.embeddingSize)+ \"_hl_\" + str(sweep_params.hidden_layer_size) +\"_en_\" + str(sweep_params.layersEncoder)+\"_de_\" + str(sweep_params.layersDecoder)+\"_lr_\" + str(sweep_params.learningRate)+\"_bi_\"+str(sweep_params.bidirectional)+\"_ep_\" + str(sweep_params.epochs)\n",
        "\n",
        "   hidden_layer_size=sweep_params.hidden_layer_size\n",
        "   embeddingSize= sweep_params.embeddingSize\n",
        "   cellType=sweep_params.cellType\n",
        "   layersDecoder=sweep_params.layersDecoder\n",
        "   layersEncoder=sweep_params.layersEncoder\n",
        "   attention=True\n",
        "   bidirectional=sweep_params.bidirectional\n",
        "   epochs=sweep_params.epochs\n",
        "   learningRate=sweep_params.learningRate\n",
        "   drop_out=sweep_params.drop_out\n",
        "\n",
        "   if(attention==False):\n",
        "      model = Seq2Seq(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,layersEncoder,layersDecoder,bidirectional,learningRate)\n",
        "\n",
        "   else:\n",
        "      model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,1,1,bidirectional,learningRate, maxLenEng)\n",
        "\n",
        "   model.to(device)\n",
        "   trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n",
        "   trainer.fit(model=model, train_dataloaders=dataloaderTrain, val_dataloaders=dataloaderVal)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b3fcb38393404b76937f2bfc2c649c9c",
            "ac19234c473d40289880f68f4aa87507"
          ]
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-05-16T06:54:02.756174Z",
          "iopub.status.busy": "2024-05-16T06:54:02.755898Z"
        },
        "id": "oftEVRXM03T4",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "a01fe674-f8d2-483a-f909-a1d59347bcf5",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 9ifsc0eu\n",
            "\n",
            "Sweep URL: https://wandb.ai/cs23m032/CS6910_Assignment3/sweeps/9ifsc0eu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jym00x4v with config:\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: RNN\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.3\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembeddingSize: 512\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayersDecoder: 3\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayersEncoder: 3\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.005\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m032\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.17.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_065412-jym00x4v</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/jym00x4v' target=\"_blank\">Question2_bayes</a></strong> to <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m032/CS6910_Assignment3/sweeps/9ifsc0eu' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3/sweeps/9ifsc0eu</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m032/CS6910_Assignment3' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs23m032/CS6910_Assignment3/sweeps/9ifsc0eu' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3/sweeps/9ifsc0eu</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m032/CS6910_Assignment3/runs/jym00x4v' target=\"_blank\">https://wandb.ai/cs23m032/CS6910_Assignment3/runs/jym00x4v</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-16 06:54:33.562634: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\n",
            "2024-05-16 06:54:33.562755: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\n",
            "2024-05-16 06:54:33.697863: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3fcb38393404b76937f2bfc2c649c9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac19234c473d40289880f68f4aa87507",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # Running Sweeps for with attention\n",
        "# sweep_id = wandb.sweep(sweep_config, project='CS6910_Assignment3')\n",
        "# wandb.agent(sweep_id, train, count = 40)\n",
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4o32rM4PETc"
      },
      "source": [
        "# Sweep for No Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HC4kSEU1OYNi"
      },
      "outputs": [],
      "source": [
        "sweep_config_NOAttn = {\n",
        "    # Bayesian Search for hyperparameters\n",
        "    \"name\" : \"Bayesian Sweep\",\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"goal\": \"maximize\", \"name\": \"Validation Accuracy\"},\n",
        "    \"parameters\": {'drop_out': {\"values\": [0.3,0.5]},\n",
        "                   'embeddingSize': {\"values\": [64,128,256]},\n",
        "                   'hidden_layer_size': {\"values\": [128,256,512]},\n",
        "                   'layersEncoder': {\"values\": [2, 3]},\n",
        "                   'layersDecoder': {\"values\": [2, 3]},\n",
        "                   \"cellType\": {\"values\": [ \"RNN\", \"GRU\", \"LSTM\"]},\n",
        "                   \"learningRate\": {\"values\": [1e-3, 0.005]},\n",
        "                   \"bidirectional\":{\"values\":[True, False]},\n",
        "                   \"epochs\": {\"values\": [10, 15]}\n",
        "                }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avF8PA48OYNi"
      },
      "outputs": [],
      "source": [
        "def train_no_attn():\n",
        "   init_sweep =  wandb.init(project=\"CS6910_Assignment3\", name=\"Question2_bayes_NoAttn\")\n",
        "   sweep_params = init_sweep.config\n",
        "\n",
        "   wandb.run.name = \"_cell_\" + sweep_params.cellType + \"_dr_\" + str(sweep_params.drop_out) +\"_em_\" + str(sweep_params.embeddingSize)+ \"_hl_\" + str(sweep_params.hidden_layer_size) +\"_en_\" + str(sweep_params.layersEncoder)+\"_de_\" + str(sweep_params.layersDecoder)+\"_lr_\" + str(sweep_params.learningRate)+\"_bi_\"+str(sweep_params.bidirectional)+\"_ep_\" + str(sweep_params.epochs)\n",
        "\n",
        "   hidden_layer_size=sweep_params.hidden_layer_size\n",
        "   embeddingSize= sweep_params.embeddingSize\n",
        "   cellType=sweep_params.cellType\n",
        "   layersDecoder=sweep_params.layersDecoder\n",
        "   layersEncoder=sweep_params.layersEncoder\n",
        "   attention=False\n",
        "   bidirectional=sweep_params.bidirectional\n",
        "   epochs=sweep_params.epochs\n",
        "   learningRate=sweep_params.learningRate\n",
        "   drop_out=sweep_params.drop_out\n",
        "\n",
        "   if(attention==False):\n",
        "      model = Seq2Seq(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,layersEncoder,layersDecoder,bidirectional,learningRate)\n",
        "\n",
        "   else:\n",
        "      model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,1,1,bidirectional,learningRate, maxLenEng)\n",
        "\n",
        "   model.to(device)\n",
        "   trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n",
        "   trainer.fit(model=model, train_dataloaders=dataloaderTrain, val_dataloaders=dataloaderVal)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me-IQvI9OYNj"
      },
      "outputs": [],
      "source": [
        "# Running Sweeps for no attention\n",
        "sweep_id = wandb.sweep(sweep_config_NOAttn, project='CS6910_Assignment3')\n",
        "wandb.agent(sweep_id, train_no_attn, count = 40)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j91TCDDhVvng"
      },
      "source": [
        "##Training and Evaluating the model with best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0cHWLbf-oUl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# hidden_layer_size=256\n",
        "# embeddingSize= 256\n",
        "# cellType=\"LSTM\"\n",
        "# drop_out=0.2\n",
        "# layersEncoder=3\n",
        "# layersDecoder=2\n",
        "# bidirectional=True\n",
        "# attention=False\n",
        "# learningRate=0.001\n",
        "# epochs=15\n",
        "# if(attention==False):\n",
        "#   model = Seq2Seq(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,layersEncoder,layersDecoder,bidirectional,learningRate)\n",
        "\n",
        "# else:\n",
        "#   model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,1,1,bidirectional,learningRate, maxLenEng)\n",
        "\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8VbhtIi03T5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# hidden_layer_size=256\n",
        "# embeddingSize= 16\n",
        "# cellType=\"LSTM\"\n",
        "# drop_out=0.2\n",
        "# layersEncoder=3\n",
        "# layersDecoder=3\n",
        "# bidirectional=True\n",
        "# attention=True\n",
        "# learningRate=0.001\n",
        "# epochs=10\n",
        "# if(attention==False):\n",
        "#   model = Seq2Seq(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,layersEncoder,layersDecoder,bidirectional,learningRate)\n",
        "\n",
        "# else:\n",
        "#   model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,1,1,bidirectional,learningRate, maxLenEng)\n",
        "\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qPn0WTU03T5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# hidden_layer_size=16\n",
        "# embeddingSize= 16\n",
        "# cellType=\"LSTM\"\n",
        "# drop_out=0.2\n",
        "# layersEncoder=2\n",
        "# layersDecoder=2\n",
        "# bidirectional=True\n",
        "# attention=False\n",
        "# learningRate=0.001\n",
        "# epochs=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ_DSSRG03T5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# hidden_layer_size=256\n",
        "# embeddingSize= 256\n",
        "# cellType=\"LSTM\"\n",
        "# layersDecoder=2\n",
        "# layersEncoder=3\n",
        "# attention=False\n",
        "# bidirectional=True\n",
        "# epochs=15\n",
        "# learningRate=0.001\n",
        "# drop_out=0.2\n",
        "\n",
        "# if(attention==False):\n",
        "#   model = Seq2Seq(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,layersEncoder,layersDecoder,bidirectional,learningRate)\n",
        "\n",
        "# else:\n",
        "#   model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,1,1,bidirectional,learningRate, maxLenEng)\n",
        "\n",
        "# model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9FjbTAe03T5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# wandb.init()\n",
        "# trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n",
        "# trainer.fit(model=model, train_dataloaders=dataloaderTrain, val_dataloaders=dataloaderVal)\n",
        "# trainer.test(model, dataloaderTest)\n",
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A69EoJQt03T5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# import csv\n",
        "# rows = []\n",
        "# count=0\n",
        "# with open(\"/kaggle/working/Output.csv\", 'r') as file:\n",
        "#     csvreader = csv.reader(file)\n",
        "#     header = next(csvreader)\n",
        "#     for row in csvreader:\n",
        "#         rows.append(row)\n",
        "#         count=count+1\n",
        "#         if(count==15):\n",
        "#             break\n",
        "# print(header)\n",
        "# print(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R77AMpiv03T5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# hidden_layer_size=256\n",
        "# embeddingSize= 16\n",
        "# cellType=\"LSTM\"\n",
        "# layersDecoder=3\n",
        "# layersEncoder=3\n",
        "# attention=True\n",
        "# bidirectional=True\n",
        "# epochs=10\n",
        "# learningRate=0.001\n",
        "# drop_out=0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ccgdSVT03T5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# if(attention==True):\n",
        "#     model = Seq2SeqAttn(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,1,1,bidirectional,learningRate, maxLenEng)\n",
        "# else:\n",
        "#     model = Seq2Seq(len(char_to_idx_latin)+2, len(charToIndLang)+2, hidden_layer_size, embeddingSize, cellType,drop_out,layersEncoder,layersDecoder,bidirectional,learningRate)\n",
        "\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv7qsz5d-oUn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# wandb.init()\n",
        "# trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n",
        "# trainer.fit(model=model, train_dataloaders=dataloaderTrain, val_dataloaders=dataloaderVal)\n",
        "# trainer.test(model, dataloaderTest)\n",
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBRQJSBn03T6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# import csv\n",
        "# rows = []\n",
        "# count=0\n",
        "# with open(\"/kaggle/working/Output.csv\", 'r') as file:\n",
        "#     csvreader = csv.reader(file)\n",
        "#     header = next(csvreader)\n",
        "#     for row in csvreader:\n",
        "#         rows.append(row)\n",
        "#         count=count+1\n",
        "#         if(count==15):\n",
        "#             break\n",
        "# print(header)\n",
        "# print(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSnHQaDI03T6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# import csv\n",
        "# rows = []\n",
        "# count=0\n",
        "# with open(\"/kaggle/working/Output.csv\", 'r') as file:\n",
        "#     csvreader = csv.reader(file)\n",
        "#     header = next(csvreader)\n",
        "#     for row in csvreader:\n",
        "#         rows.append(row)\n",
        "#         count=count+1\n",
        "#         if(count==15):\n",
        "#             break\n",
        "# print(header)\n",
        "# print(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub_bvRpo03T6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4850432,
          "sourceId": 8190591,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4933043,
          "sourceId": 8303996,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4933099,
          "sourceId": 8304151,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4933272,
          "sourceId": 8304593,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5003045,
          "sourceId": 8407265,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
